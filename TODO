
I Am Legend:

Items are sorted by priority (highest on top).
o a pending  TODO item (for the current release)
. a pending  TODO item (for future releases)
x a finished TODO item

-----------------------------------------------------------------------------
This Branch Is About Integrating The hamsterdb2 Functionality!!!!!
-----------------------------------------------------------------------------
The big headline is:
As a user i want to run many Transactions in parallel with high performance.
I'm using multiple threads b/c my CPU has multiple cores, and expect hamsterdb
to scale with the number of cores.
==============================================================================

o need a launchpad project; start with 12.04 for 64bit
    sudo apt-get install packaging-dev dh-make
    <migrate gpg key>
    <migrate ssh key>
    pbuilder-dist precise create
    pbuilder-dist quantal create
    bzr whoami "Christoph Rupp <chris@crupp.de>"
    bzr launchpad-login 9e9o1ko8b2f5xpiibgscjzlhug6x9-chris
  add to ~/.bashrc:
    export DEBFULLNAME="Christoph Rupp"
    export DEBEMAIL="chris@crupp.de"
    http://www.quietearth.us/articles/2006/08/16/Building-deb-package-from-source
    http://www.webupd8.org/2010/01/how-to-create-deb-package-ubuntu-debian.html
    http://developer.ubuntu.com/packaging/html/packaging-new-software.html

o freelist re-implementation
    o header page stores head of freelist 
    o adding pages in a linked list
    o also cache page-IDs in memory
    o when a page is requested: get the next highest page in the freelist
    o blob pages: track number of free bytes
    o blob pages: if free bytes are down to 0: add to freelist
    o also test with blobs that span multiple pages
    o make sure that 2.1.0 and older cannot open files created with 2.1.1
    o in-memory environment: immediately free the memory

o pre-allocate index

o update node structure - prevent fileformat incompatibilities in future
    versions

o AES encryption

o cache improvements
    o sort pages by ID/offset (and use writev?)
    o give priority to index pages

. can we perform better with O_DIRECT? run some benchmarks

. continue refactoring of txn.h/txn.cc
    o try to cleanup the flow; move more code from db.cc to txn.cc,
        reorg TransactionIndex similar to BtreeIndex
    o try to replace some of the linked lists with boost::intrusive_list
    o document the tree structure in the header file
    o TransactionIndex: use std::set<OperationNode> instead of rb.h

------------------- release 2.1.1 -----------------------------------------













o HAM_PARAM_MAX_DATABASES: only use as getter, not as setter
    -> also, the default size should be much higher now

o preallocate file space
    pages should be optimized in a way that the growing index will be written
    sequentially

o should database names still be reserved?

. also remove locking from C# and Java APIs

. write a custom memory allocator, based on 4kb pages
    if memory is allocated: pick the current page; if it has enough free space
    then return a pointer and decrease the amount of free space.
    If memory is freed than increase the amount of freed memory. If this amount
    == 4kb then the page is stored in a lookaside-list and will be used later.
    If the page does not have enough memory for alloc then either fetch
    another free page from the lookaside-list or allocate a new one.
    o use this in the TransactionTree to avoid small allocations

o continue with refacoring - indention, coding style, better design etc...
    o unittests
        x code formatting
        o reduce bfc to a single header file, or use boost unittest framework
            http://www.boost.org/doc/libs/1_35_0/libs/test/doc/components/utf/index.html
            http://www.beroux.com/english/articles/boost_unit_testing/
            http://www.alittlemadness.com/2009/03/31/c-unit-testing-with-boosttest/

    o get rid of ham_bool_t, replace with bool whenever possible

o split Transaction into local and remote class
    o hamsterdb.cc directly calls into Transaction class instead of Environment
    o then continue with db.cc and move txn-related functions to LocalDatabase
    o try to get the methods/design analoguous to the Btree
    o TransactionIndex:
        x check how/if std::multimap can replace rb.h - yes, seems to work
        o replaces the TransactionTree
        o one TransactionIndex per Database (always created)
        o remove rb.h
        o txn_opnode_t -> TransactionOperation
        o txn_node_t is no longer required
        o try to move code from db.cc into TransactionIndex, i.e. to check
            conflicts etc
        o is a std::multimap<ham_key_t, operation)
        . use a custom allocator for all TransactionOperations of a single
            Transaction
        . use a custom allocator for std::multimap

o split Cursor into local and remote class
    o hamsterdb: directly call into Cursor class (instead of Database)

o fix usage of DB_NEW_PAGE_DOES_THRASH_CACHE

o changeset: instead of simply adding pages to the changeset, the caller
    could already specify whether this page needs logging or not;
    i.e. after freelist rewrite, the blob pages do not need logging if a
    blob is deleted  

o is there a way to group all changeset flushes of a Transaction into one
    changeset? that way we would avoid the frequent syncs
    o would have to remove all of assert(changeset.is_empty())
    o but we can use that assert prior to txn_begin

o is the recovery working if there's a crash during ham_close?

o BtreeFindAction: always use a cursor, and when doing approx matching
    then simply move left or right with that cursor

. track additional metrics
    o cache misses
    o cache hits
    o ...

o flush in background (asynchronously)
    o need new flag file HAM_DISABLE_ASYNCHRONOUS_FLUSH
    o if in-memory database: disable async flush
    o if transactions are disabled: disable async flush
    o if enabled: create background thread, wait for signal
    o ham_env_flush: if txn are enabled then try to flush them to disk
    o how to deal with an error in the background thread???
        o store in Environment, then return in every exported function
    o default: async flush is OFF!

    o extend monster tests
        o with async flush
        o without async flush
        o extend/run performance test
        o run monster tests

    o documentation
        o tutorial
        o faq

o btree_cursor.h/btree_cursor.cc
    o use memory arena for uncoupling the key

o python API - update and integrate
    o rewrite with boost::python??
    o also add to win32 package

o need a function to get the txn of a conflict (same as in v2)
    ham_status_t ham_txn_get_conflicting_txn(ham_txn_t *txn, ham_txn_t **other);
        oder: txn-id zurÃ¼ckgeben?
    o also add to c++ API
    o add documentation (header file)
    o add documentation (wiki)

o recovery: re-create pending transactions (if required)
    o needs a function to enumerate them

o allow transactions in-memory

o allow transactions w/o journal

o allow transactions w/o recovery

. android port (needs new java api) in /contrib directory (it's on a separate
    branch)

. new test case for cursors
    insert (1, a)
    insert (1, b) (duplicate of 1)
    move (last) (-> 1, b)
    insert (1, c)
    move (last) (-> 1, c)? is the dupecache updated correctly?

. look for someone who can write a PHP or Perl or Ruby wrapper

. implement support for partial keys

. test with tcmalloc; if it works then also use it in the master branch, but
    make sure that memory consumption does not increase significantly

. there are a couple of areas where a btree cursor is uncoupled, just to
    retrieve the key and to couple the txn-key. that's not efficient
        db.c:__btree_cursor_points_to
        db.c:__compare_cursors
        txn_cursor.c:cursor_sync
        txn_cursor.c:cursor_overwrite
    o move to a separate function
    o try to optimize

. hash-table.h: the foreach/remove_if/visitor pattern is clumsy. use
    functor or class w/ operator() instead
. changeset: use a generic hash table for fast lookup (but leave list in place
    for everything else)
. cache: use a generic hash table

. add tests to verify that the cursor is not modified if an operation fails!
    (in cursor.cpp:LongTxnCursorTest are some wrapper functions to move or
    insert the cursor; that's a good starting point)

. the whole c++ protocol should be c++-ified

. move the whole configuration (key sizes, parameters, page size, etc) into a
    separate class which is instantiated by the env

. c++-ify the btree node representation;
    o include duplicates as well! disentangle duplicates from blob-handling

. c++-ify the blob handling and split off the duplicates

. cleanup db.h/db.cc - move functions into Database or
    DatabaseImplementationLocal namespace - but take care b/c these functions
    are also used by Cursor or other modules which don't necessarily have
    access to the Local stuff
    o db_get_key_count
    o db_alloc_page
    o db_fetch_page
    o db_insert_txn
    o db_erase_txn
    o db_find_txn
    o db_check_insert_conflicts
    o db_check_erase_conflicts
    o __increment_dupe_index

. c++-ify everything else

. device, page and os shold no longer return errors but throw exceptions

XXXXXXXXXXXXXXXXXXXXX release 2.0.0 STABLE !!! XXXXXXXXXXXXXXXXXXXXXXXXXXXXX

. new flag for transactions: HAM_TXN_WILL_COMMIT
    if this flag is set, then write all records directly to the blob, not
    to the log. the log will only contain the rid.
    o document this (and also the drawback - that an abort will lose the
        blobs and they cannot be reused
    -> this affects all temporary ham_insert-transactions
    (not sure if this should get high priority)

o hamsterdb.com
    x add twitter feed
    o API documentation: don't link to "modules" but to startup page, update
        with newest version
    o crupp.de: do a backup of the database
    . google +1 button
    . can we use something like Aller.font?

o update documentation
    x in header file
    o in the wiki
        o don't forget to list all functions that are currently disabled
            w/ txn's -> sorting dupes, approx. matching, ...
        o transactional behavior/conflicts of duplicate keys
    o in the wiki: start with internal documentation
        o transactions
        o architecture
        o btree
        o journal/log
        o cache
        o I/O
        o unittests
        o cursor(s)
        o monstertests - how to use them?

o fully (!) automize the whole release process for unix; the result (on
    success) are the following files:
    o tar-ball
    o the README
    o the documentation as a tar
    o the Changelog
    o the release notes (a template)
    o the output (xml) of the monster tests

. port to WinCE

o how can we extend the monster-tests to have reliable tests for transactions?

. if memory consumption in the txn-tree is too high: flush records to disk
    (not sure if this should get high priority)

o when recovering, give users the choice if active transactions should be
    aborted (default behavior) or re-created

o extkeys: don't use txn_id for the 'age', use lsn instead

o the DatabaseImplementation subclass is not neccessary; all subclasses
    can directly derive from Database.

. allow use of transactions without a log/journal

. allow use of transactions for in-memory databases

o ham_get_count: could be atomically updated with every journal entry

o when flushing a changeset: sort by offset, use writev()

o add concurrency (on a high level)

o flush transactions in background

. have a flag to disable flushing of logfiles/journal files (or flush them
    async.)

o continue as described in integrate-ham2.txt...

