o logo!!

o webseite
    http://nitrosecurity.com/
    http://www.opf3.com/Opf3/Default.aspx
    http://www.pixelmedia.com/

-----------------------------------------------------

x db.c: zeile 1413 hat viel auskommentiert. reinnehmen und nochmal testen!

x alle copyright-strings mit 2007 updaten!

x automake: mit -Wall compilieren!

x default-cachesize auf 256kb ausbauen; das ist auch die default-grösse bei 
    berkeleydb (dann auch die cache-hashtable vergrössern)

x vorsicht - in /usr/local/include liegt eine Makefile.am aus der hamsterdb-
    installation. nur ein versehen, oder wird sie bei jedem 'make install'
    reinkopiert? ausprobieren. 
    --> wird nicht reinkopiert

x bei cursor_move über die "grenzen" (also z.b. previous von erstem element)
    nicht IS_NIL zurückgeben sondern KEY_NOT_FOUND

x tests laufen nicht. das problem ist dass bdb-cursor die keys 
    nicht sortiert durchläuft.
    x nachfragen, wie man das ändern kann
    x neue db installieren!
    x vorsicht - momentan ist sehr viel gehackt und umgeschrieben...

    x momentan ist alles sehr instabil - wieder zum laufen kriegen
        x --test-cursors=0 crasht oft
        x --test-cursors=1 passt nicht - beim erase schlägt hamster fehl
            mit KEY_NOT_FOUND (evtl aber auch schon beim insert - 
            rausfinden, indem der cursor-erase mit ham_erase ausgetauscht 
            wird)
        x my_compare_cursors ist gerade auskommentiert
        x viele tests schlagen fehl
        x test 220 schlägt fehl
        x test ext_51, ext_60, ext_61 schlägt fehl

    x bei erase ist der my_compare_cursor auskommentiert; problem: der bdb-
        cursor ist NIL nach dem erase; also erst c_get(key), dann c_get(NEXT),
        dann erase (ohne cursor). ODER (besser): auch hamster-cursor
        nach dem erase auf NIL setzen

    x Testen bei test-cursors=1:
        Beim insert erst ham_cursor_find/ham_cursor_replace machen, wenn
        ham_cursor_find fehlschlägt: ham_cursor_insert machen

    x ./run-tests.sh 1 --test-cursors=1
    x ./run-tests.sh 1 --test-cursors=1 --overwrite=1
    x ./run-tests.sh 1 --test-cursors=1
    x valgrind-tests durchlaufen lassen

x O_DIRECT ausprobieren; benchmarken - bringt nix, wird langsamer

x HAM_READ_ONLY: liefert fehler zurück wenn man ham_insert und ham_erase
    aufruft; muss auch fehler bei den cursor-funktionen (insert, erase,
    replace) zurückgeben!

x ein neues sample: use hamsterdb for sorting big amounts of data
    x liesst eine textdatei ein
    x jedes wort wird eingefügt, HAM_DUPLICATE_KEY wird ignoriert
    x danach mit einem cursor sortiert ausgeben

x HAM_OPEN_CREATE
    funktioniert derzeit nicht, rausschmeissen

x ham_strerror überprüfen - ist es vollständig?

o nächsten release machen!
    x monster.sh erweitern für --test-cursors=1
    x monster.sh testen
    x kurz testen mit --fullcheck-find=1
    x kurz testen mit --useralloc
    o kurz testen mit valgrind

    o release machen (entsprechend checkliste)
    o upload des tarballs
    o blog-eintrag
    o freshmeat-eintrag

x monster.sh und valgrind.sh erweitern
    x monster.sh erweitern für --fullcheck-find=1
    x monster.sh erweitern für --fullcheck-find=1 --useralloc=1
    x monster.sh erweitern für --useralloc=1
    x valgrind.sh erweitern für --fullcheck-find=1
    x valgrind.sh erweitern für --fullcheck-find=1 --useralloc=1
    x valgrind.sh erweitern für --useralloc=1

-----------------------------------------------------
-----------------------------------------------------

o endianness testen

o port to ms windows
    x win32: sourcen portieren - mmap fehlt noch!
    o mit mingw, bcc, watcom, msvc, icc...
    o projekt-umgebungen für visual studio 6 und .NET
    o define HAM_EXPORT DECLSPEC _dllexport for DLLs und .so
    o kein makefile, aber einfache batch-files zum compilieren
    o monster.sh!

o können wir problemlos 32bit-filepointer nehmen?

o 1 writer, multiple reader - wie lässt sich das machen?
    alle ohne caching, alle mit read-through/write-through?
    testen, evtl brauchen wir noch ein exclusive locking
    
o es ist noch ein kleiner valgrind-bug drin:
    valgrind --tool=memcheck --leak-check=full --show-reachable=yes
    .libs/lt-test --file ../../../hamsterdb-tests/trunk/testfiles/1/ext_060.tst
    --inmemorydb=1 --verbose=1

o nächsten release machen

-----------------------------------------------------
-----------------------------------------------------

o tools
    o ham_dump
        erzeugt einen cursor auf den ersten eintrag, dumpt den 
        key und die daten (zumindest einen teil davon)
        --key-format=char|short|long|longlong|string|binary
        --key-length=<n>
        --data-format=char|short|long|longlong|string|binary
        --data-length=<n>
    o ham_info
        gibt alle infos aus dem header aus, sowie die anzahl der elemente,
        average key size, average data size, min/max etc
    o ham_recover
        holt die header-page, dann die root-page, und geht runter zum 
        ersten leaf. läuft dann alle index-pages ab, schreibt die keys 
        und die daten raus 
    o ham_check
        macht einen check_integrity auf die datenbank
    o ham_reorg
        macht eine reorg (im grunde nur ein neues schreiben der datenbank
        mit gleichzeitigem minimieren der freelist-entries)

-----------------------------------------------------
-----------------------------------------------------

o komplettes review
    werden fehlerwerte korrekt propagiert?
    machen fehlerwerte immer sinn? z.b. in flush_all()
    was passiert mit fehlern beim flushen?
    was passiert mit fehlern in ham_close()?
    o ein paar sachen müssten umbenannt werden:
        o alle statischen funktionen bekommen statt "my_" ein 
            prefix, das ihrem modul entspricht (z.b. "bt_" für btree etc)
        o keys.h/keys.c aufteilen in generische keys (zusammenlegen mit extkeys)
            und btree-spezifischen keys
        o db hat 2 funktionen, die die extended keys löschen - das gehört
            ins backend
    o nochmal schaun ob die ganzen flags so sinn machen
    o TODOs durchgehen

-----------------------------------------------------
-----------------------------------------------------

o doku
    o tutorial/sample in die online-hilfe einbeziehen
    o FAQ mit häufig gestellten fragen, tips zu optimierungen
    o Dokumentation in den header-dateien überarbeiten
    o webseite
    o mailing list
    o überarbeiten
    o interne doku schreiben
        o db-handle, pageverwaltung
        o backend-aufbau
        o freelist
        o cache
        o cursors
    o header-file überarbeiten

-----------------------------------------------------

x bbaum fehlerfrei
x TXN raus (wir können die txn's auch komplett
    für diesen release abschalten... man soll dafür ja ne spezielle version
    kaufen müssen)
x caching
x memory-mapped access
x in memory-datenbanken
x overwrite keys
x extended keys
x mal nachschauen was man nach den GPL-Codingrules noch für 
    dateien braucht -> nix mehr
x performance vergleichbar mit berkeley-db
x erzeugt .dll/.so
x umsteigen auf autoconf/automake
x cursors
x stress-test-tool(s), das ALLE optionen durchprobiert
    mmap
    r/w
    in-memory
    verschiedene pagesizes
    grosse keys
    grosse blobs
o compiliert unter linux, windows, darwin, 32bit und 64bit, läuft auf 
    little- und bigendian
o logo
o legal issues
o dokumentation: tutorial, interface, FAQ (auch zu unittests)
o webseite
    about (home)
    features
    download
    documentation (faq, tutorial)
    support (mailingliste)
    contact
o admin-tool(s) fuer dump, stats, repair, update, reorg
    o db_dump: 
        o key/daten dumpen
        o header dumpen
o KEINE valgrind-fehler!

-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------

o duplicate keys
    jeder key bekommt einen dupcounter; der wird mit unsigned(-1) initialisiert
    beim einfuegen wird rekursiv abgestiegen. im leaf wird dann ein neuer key
    eingefuegt, mit dem dupcounter=existierender ("kleinster") key minus 1.

-----------------------------------------------------
-----------------------------------------------------

o mehrere datenbanken in einer datei
    (siehe eintrag im notizbuch)

    -> database-environment (ein file fuer mehrere datenbanken, 
        gesharter cache, geshartes file-handle, freelist etc)

-----------------------------------------------------
-----------------------------------------------------

o c++-api

-----------------------------------------------------
-----------------------------------------------------

o statistics
    will wissen wie viele freelist-hits/misses und cache-hits/misses es gab,
    auch im extkey-cache

o statistics
    get generic getter/setter for statistical value, i.e. 
        enum { CACHEHITS, CACHEMISSES, PAGES, FREEPAGES, ... };
        ham_u64_t statistics[8];
    set_stats_value(db, which, value): db->statistics[which]=ham_h2db32(value)
    ATTENTION: some of those values are specific for each backend, others
        are global; therefore we need two functions: 
        ham_get_global_statistics(stat)
        ham_get_index_statistics(index, stat)
    max elements in einer datenbank

-----------------------------------------------------
-----------------------------------------------------

o filter
    generische filter, sowie 2 implementationen davon: ein encryption-codec 
    und ein zlib-codec
    arbeiten sie page- oder blob-basiert? evtl waere page-basiert besser, 
    denn dann koennten auch index-pages (bzw NUR index-pages) gefiltert 
    werden.
    (my_result_t) (*filter)(my_key_t *key, my_data_t *data, int direction);

-----------------------------------------------------
-----------------------------------------------------

o super-COMPRESSED-mode: keine headerpage, und pagesize auf 128 byte ->
    super-mini-datenbanken (für embedded) - möglich ohne Aufwand? wird tricky, 
    weil die page-alloc-funktionen davon ausgehen dass eine adresse 0 ein
    fehler ist

-----------------------------------------------------

o datenbank mit O_EXCL öffnen, bzw mit flock() (und nem wait, falls die 
    Datenbank gelockt ist) -> Möglichkeit für pseudo-concurrent access bei
    kurzen, schnellen Zugriffen (z.b. webseite)

-----------------------------------------------------

o debug
    o im debug-modus output wie gehabt; bei non-debug: statt file- und line
        nur "hamsterdb: " ausgeben

o hash-tabelle
    @@@

-----------------------------------------------------
-----------------------------------------------------

o bindings 
    python (auch für python-shelf!)
    perl
    php
    java
    COM
    .NET (Sample)
    C# (Sample)
    VB.NET (Sample)

-----------------------------------------------------
-----------------------------------------------------

o asset-tool
    GUI und library für computerspiele

-----------------------------------------------------
-----------------------------------------------------

o live reorganisation???

-------------------------- literature -----------------------
pB+ Trees prefetching B+ Trees 
[CGM01] Improving Index Performance through Prefetching. S. Chen, P.B. 
Gibbons, and T.C. Mowry. ACM International Conference on Management
of Data (SIGMOD), Santa Barbara, California, May 2001
[GL01] B-Tree Indexes and CPU Caches. G Graefe and P. Larson. International
Conference on Data Engineering (ICDE), Heidelberg, Germany, April 2001.
[RR00] Making B+ Trees Cache Conscious in Main Memory. J. Rao 
and K.A. Ross. ACM International Conference on Management of Data (SIGMOD),
Dallas, Texas, May 2000.

