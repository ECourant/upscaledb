
o logo!!

o webseite
    http://nitrosecurity.com/
    http://www.opf3.com/Opf3/Default.aspx
    http://www.pixelmedia.com/
    x grund-layout und php-framework erstellen
    x doxygen in webseite integrieren
    o hamsterdb.h ueberarbeiten, dokumentieren
    o inhalte
        x frontseite
        x features
        x download
        x legal/impressum
        x sitemap
        x GPL/Verweise auf GPL
        x sidebars
        o frontseite: hamster-bild einbetten (oder so lassen?)
        o roadmap
        o doku bzgl installation, compilieren, portieren
        o sidebars ueberpruefen
        o startseite: "News"-Bereich
    o korrigieren lassen

x was ist bei --optimizesize und --inmemorydb? das flag duerfte doch gar
    nix bewirken, weil es bei inmemorydb keine freelist gibt, oder?
    -> ja, wird ignoriert

x vor jeder operation den last-error auf 0 setzen

x Autoconf sollte mit -O3 bauen!

x keine optimization bei --enable-debug

x optimisieren für minimum-size

o neuer configure-modus zum disablen von internen funktionen - z.b. dump
    und check_integrity etc
    -> ist blöd - da muss auch die ham/hamsterdb_int.h geändert werden!
    vielleicht sollten wir diese funktionen einfach nicht exportieren?
    dann kann man sie mit loadlibrary/getprocaddress laden, wenn man
    sie braucht. ist aber auch doof...

o 2 mal linken: einmal ohne hamsterdb, einmal mit. Wie gross wird die
    executable? -> footprint (wie bei itzam)

o portieren auf linux/ppc

o portieren auf MacOS/Darwin

o sicherstellen dass die datenbanken endian-agnostic sind

o sicherstellen dass die datenbanken wordsize-agnostic sind

o koennen wir problemlos 32bit-filepointer nehmen?

o 1 writer, multiple reader - wie lässt sich das machen?
    alle ohne caching, alle mit read-through/write-through?
    testen, evtl brauchen wir noch ein exclusive locking
    
o es ist noch ein kleiner valgrind-bug drin:
    valgrind --tool=memcheck --leak-check=full --show-reachable=yes
    .libs/lt-test --file ../../../hamsterdb-tests/trunk/testfiles/1/ext_060.tst
    --inmemorydb=1 --verbose=1

o ham_flush: sollte os_flush aufrufen
    BOOL FlushFileBuffers(HANDLE hFile);
    bzw fflush oder so in linux

o os_tell durch os_get_filesize erweitern

o nächsten release machen

-----------------------------------------------------
-----------------------------------------------------

o doku
    o tutorial/sample in die online-hilfe einbeziehen
    o FAQ mit häufig gestellten fragen, tips zu optimierungen
    o mailing list
    o interne doku schreiben
        o db-handle, pageverwaltung
        o backend-aufbau
        o freelist
        o cache
        o cursors

-----------------------------------------------------
-----------------------------------------------------

o tools
    o ham_dump
        erzeugt einen cursor auf den ersten eintrag, dumpt den 
        key und die daten (zumindest einen teil davon)
        --key-format=char|short|long|longlong|string|binary
        --key-length=<n>
        --data-format=char|short|long|longlong|string|binary
        --data-length=<n>
    o ham_info
        gibt alle infos aus dem header aus, sowie die anzahl der elemente,
        average key size, average data size, min/max etc
    o ham_recover
        holt die header-page, dann die root-page, und geht runter zum 
        ersten leaf. läuft dann alle index-pages ab, schreibt die keys 
        und die daten raus 
    o ham_check
        macht einen check_integrity auf die datenbank
    o ham_reorg
        macht eine reorg (im grunde nur ein neues schreiben der datenbank
        mit gleichzeitigem minimieren der freelist-entries)

-----------------------------------------------------
-----------------------------------------------------

o komplettes review
    werden fehlerwerte korrekt propagiert?
    machen fehlerwerte immer sinn? z.b. in flush_all()
    was passiert mit fehlern beim flushen?
    was passiert mit fehlern in ham_close()?
    o ein paar sachen müssten umbenannt werden:
        o alle statischen funktionen bekommen statt "my_" ein 
            prefix, das ihrem modul entspricht (z.b. "bt_" für btree etc)
        o keys.h/keys.c aufteilen in generische keys (zusammenlegen mit extkeys)
            und btree-spezifischen keys
        o db hat 2 funktionen, die die extended keys löschen - das gehört
            ins backend
    o nochmal schaun ob die ganzen flags so sinn machen
    o TODOs durchgehen

-----------------------------------------------------
-----------------------------------------------------

x bbaum fehlerfrei
x TXN raus (wir können die txn's auch komplett
    für diesen release abschalten... man soll dafür ja ne spezielle version
    kaufen müssen)
x caching
x memory-mapped access
x in memory-datenbanken
x overwrite keys
x extended keys
x mal nachschauen was man nach den GPL-Codingrules noch für 
    dateien braucht -> nix mehr
x performance vergleichbar mit berkeley-db
x erzeugt .dll/.so
x umsteigen auf autoconf/automake
x cursors
x stress-test-tool(s), das ALLE optionen durchprobiert
    mmap
    r/w
    in-memory
    verschiedene pagesizes
    grosse keys
    grosse blobs
o compiliert unter linux, windows, darwin, 32bit und 64bit, läuft auf 
    little- und bigendian
o dokumentation: tutorial, interface, FAQ
o webseite
o admin-tool(s) fuer dump, stats, repair, update, reorg
    o db_dump: 
        o key/daten dumpen
        o header dumpen
o KEINE valgrind-fehler!
o logo
o legal issues

-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------

o c++-api

-----------------------------------------------------
-----------------------------------------------------

o duplicate keys
    jeder key bekommt einen dupcounter; der wird mit unsigned(-1) initialisiert
    beim einfuegen wird rekursiv abgestiegen. im leaf wird dann ein neuer key
    eingefuegt, mit dem dupcounter=existierender ("kleinster") key minus 1.

    ist blöd, weil im key dann 2 (oder 4) byte für jeden key verloren gehen!

-----------------------------------------------------
-----------------------------------------------------

o mehrere datenbanken in einer datei
    (siehe eintrag im notizbuch)

    -> database-environment (ein file fuer mehrere datenbanken, 
        gesharter cache, geshartes file-handle, freelist etc)

-----------------------------------------------------
-----------------------------------------------------

o filter
    generische filter, sowie 2 implementationen davon: ein encryption-codec 
    und ein zlib-codec
    arbeiten sie page- oder blob-basiert? evtl waere page-basiert besser, 
    denn dann koennten auch index-pages (bzw NUR index-pages) gefiltert 
    werden.

    vielleicht müsste man unterscheiden zwischen page- und blob-basierten
    filtern...

    (my_result_t) (*filter)(my_key_t *key, my_data_t *data, int direction);

-----------------------------------------------------
-----------------------------------------------------

o bindings 
    python (auch für python-shelf!)
    perl
    php
    java
    COM
    .NET (Sample)
    C# (Sample)
    VB.NET (Sample)

-----------------------------------------------------
-----------------------------------------------------

o super-COMPRESSED-mode: keine headerpage, und pagesize auf 128 byte ->
    super-mini-datenbanken (für embedded) - möglich ohne Aufwand? wird tricky, 
    weil die page-alloc-funktionen davon ausgehen dass eine adresse 0 ein
    fehler ist

-----------------------------------------------------

o datenbank mit O_EXCL öffnen, bzw mit flock() (und nem wait, falls die 
    Datenbank gelockt ist) -> Möglichkeit für pseudo-concurrent access bei
    kurzen, schnellen Zugriffen (z.b. webseite)

-----------------------------------------------------

o hash-tabelle
    @@@

-----------------------------------------------------
-----------------------------------------------------

o asset-tool
    GUI und library für computerspiele

-----------------------------------------------------
-----------------------------------------------------

o live reorganisation???

-------------------------- literature -----------------------
pB+ Trees prefetching B+ Trees 

[CGM01] Improving Index Performance through Prefetching. S. Chen, P.B. 
Gibbons, and T.C. Mowry. ACM International Conference on Management
of Data (SIGMOD), Santa Barbara, California, May 2001

[GL01] B-Tree Indexes and CPU Caches. G Graefe and P. Larson. International
Conference on Data Engineering (ICDE), Heidelberg, Germany, April 2001.

[RR00] Making B+ Trees Cache Conscious in Main Memory. J. Rao 
and K.A. Ross. ACM International Conference on Management of Data (SIGMOD),
Dallas, Texas, May 2000.

