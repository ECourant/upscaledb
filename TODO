
x release 0.4.5

x support GPL3
    x change all source headers -> GPL 2.0 *or later*
    x rename COPYING to COPYING.GPL2
    x add GPL3 license file (COPYING.GPL3)

x create a new repository for hamsterdb-meta

x unittests - check for leaks!
    x replace big record with tiny
    x replace big record with null
    x replace tiny record with null
    x replace tiny record with big

x recno: keys lassen sich nicht überschreiben
    x für ham_insert fixen
        x unittest
    x für ham_cursor_insert fixen
        x unittest

x rename ham_cursor_replace to ham_cursor_overwrite (and all other instances
    of "replace" with "overwrite")
    x hamsterdb.h 
    x replace sources
    x fix unittests
    x tutorial

o support for duplicate keys
    x make sure that EXTENDED_BLOB flag is always set if blob>=8 byte 
        (check unittests!)
        -> not needed - TINY_BLOB or SMALL_BLOB are enough
    x test if everything runs fine if blobs are always allocated

    x ham_create needs flag HAM_ENABLE_DUPLICATES
        x persistent flag -> unittest

    x don't allow insert(HAM_DUPLICATE|HAM_OVERWRITE)
        x fix in code
        x documentation!
        x unittest

    x modify db_free_page; also delete the duplicates
    x modify my_free_cb

    x need a list of all cursors
        x add cursor_next, cursor_previous
        x add cursor *ham_db_t::_cursor_list
        x btree_cursor_create: prepend new cursor to the list
        x btree_cursor_destroy: delete cursor from the list
        x unittest: check if links are correct
            x also with cloned cursors!

    x when freeing in-memory pages/blobs: also free the duplicates (otherwise
        we have memory leaks)
        x unittest

    x remove the old crap
        x and the unittests!

    x new flag KEY_DUPLICATE (alternatively to TINY, NULL)
        x must not appear in internal keys

    x cursor: dupe_id is the offset in the dupe_table
        x type is ham_size_t
        x always starts with zero

    x create a blob_duplicate_t structure
        x the structures
        x getters
        x setters
        x unittest for the structure

    x a new function
        key_set_record(int_key_t *key, ham_record_t *record, 
            flags=0|OVERWRITE|DUPLICATE[_position]);
        -> remove duplicated code in btree_cursor.c and btree_insert.c

        x blob_duplicate_insert(dupe_table_id, position, flags, 
            [flags, rid]+);
            -> returns the new rid; only inserts at the end of the table

        x ham_find: returns the first item
            x unittest

        x ham_insert(OVERWRITE) overwrites the first dupe
            x unittest

    x enhance cursor_move for next/previous/first/last
        x unittest for first/next
        x unittest for last/previous

    x key_erase_record
        x blob_duplicate_erase(dupe_table_id, position)
            (does not yet shrink the duplicate table)
        x ham_erase: delete all duplicates
            x unittest
        x ham_cursor_erase: only delete the item at the duplicate position
            x unittest
        x both functions must update all cursors which are coupled 
            to this item/duplicate
            x unittests

    x blob_duplicate_overwrite(dupe_table_id, position, [flags, rid]);
        x unittests

    x cursor_overwrite
        -> must replace all cursors which are coupled to this duplicate!
        x unittest

    x insert
        x new dupes are appended at the END of the list (add documentation!)
        x change the unittests

    x unittest for cursor_erase: insert 5 duplicate, delete them all 
        with cursor_erase

    x cursor_insert
        x don't allow these flags in ham_insert 
            x unittest
        x duplicate_insert_after
            x unittest
        x duplicate_insert_before
            x unittest
        x duplicate_insert_first
            x unittest
        x duplicate_insert_last (default)
            x unittest
        x cursor is placed on inserted dupe - unittest
            -> ham_insert: set dupe_id, delete dupe_entry_t!

    x fix TODO items in blob.c

    o tests are failing:
        --duplicate=1 --use-cursors=1 [--reopen=1|--inmemorydb=1]
          x ../../testfiles/1/15.tst
          x ../../testfiles/1/17.tst
          x ../../testfiles/1/18.tst
          x ../../testfiles/1/46.tst
          o ../../testfiles/1/220.tst
            ...

    x update documentation
    x extend valgrind.sh
    x new sample, read all words from stdin, insert them with line information;
        also, insert the same word in a second db, with a word-counter
        then dump all words with the line information, and how often they
        were used
    o update tutorial
    o modify acceptance test for --duplicate=1 (berkdb and hamster)
        x fullcheck-backwards=1 - uses back-to-front order for fullcheck
        o new acceptance tests with many, many duplicates
        o --duplicate-position="before"|"after"|"first"|"last"(default)
            o add to monster.sh
            o add to valgrind.sh

    o endian-tests
        x create unittest
        x check-in le-database (created by the new sample)
        o check-in be-database (created by the new sample)
        o enhance endian-create.sh and endian-check.sh

o webpage
    o update web page about license change (GPL2 or GPL3)
    o rename "Features" to "About"
    o update roadmap

o release 0.4.6

--------------------------------------------------------------------------

o check ham_txn_abort in btree_cursor.c
    this call never appears in hamsterdb.c, but quite frequently in the
    cursor routines; is this a problem?

o be more careful when uncoupling cursors - especially when inserting 
    or deleting items, uncoupling is often not necessary
    o definitely no need to uncouple if overwriting or adding a duplicate

o more ideas for unittests
    o unittests: insert NULL/TINY/SMALL blobs, then create linked lists
    o unittests: insert NULL/TINY/SMALL as duplicates
    o unittests: insert NULL, then replace with TINY, then with SMALL, 
        then with big, then SMALL, TINY, NULL
    o unittests: 
        o create cursor -> must be NIL
        o insert item   -> must be NIL
        o move cursor to item
        o insert item2 < item -> cursor is uncoupled
        o move cursor to item
        o insert duplicate of item -> cursor is still coupled
        o insert item2 > item -> cursor is still coupled

o ham_close with flag HAM_AUTO_CLOSE_CURSORS
    o unittests

o ham_env_close with flag HAM_AUTO_CLOSE_DATABASES
    o unittests

o btree_insert:421 - why is the extkey deleted??

o protect users against uninitialized ham_key_t and ham_record_t structures
    o check if key->flags is 0 or USER_ALLOC
    o check if key->_rid is 0
    o check if record->flags is 0 or USER_ALLOC
    o check all other private flags
    o unittests!

o create a new repository for hamsterdb-alien for all dependencies 
    in source and precompiled (static/non-debug - cppunit and berkeleydb)
    x linux64-le
    x linux32-le
    o cygwin32
    o win32
    o win64
    o wince-x86
    o ppc32-be

o record numbers should not be reused
    currently, if the last record is deleted, and then the database is
    reopened, this record number is reused
    persistently cache the number of elements in the database - we need 
    this information anyway.
    o insert: set record->_rid to 0, to make things easier
    o add a new function ham_get_count()

o record numbers don't check endianess in ham_find/ham_cursor_find:
    the key parameter coming from the user must be endian-translated!
    
o optimization idea: could use lookaside-list for the last 5/10 
    duplicate tables

o extkey_cache: merge extkey_cache_remove() and blob_free()

o key_set_record does not always need to dirty the page (i.e. when
    appending duplicates) -> don't set page dirty in the caller

o cursor_overwrite/cursor_insert: 
    currently, the cursor_dupe_cache is deleted, but we don't have to
    also, in cursor_move there are some optimizations regarding the
    cache (search for TODO)

o ham_get_duplicate_count (???)
    x blob_duplicate_get_count(dupe_table_id);
    o unittests

o new sample for duplicate keys
    modify sample env1, to create a 1:n relationship between orders
    and customers (or create a new sample)

. webpage
    o move to cakephp framework
    o frontpage: resize hamster picture; remove text -> more space below
        (for 3 colums: news, main features, articles/testimonials/link cloud)

