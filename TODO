


x 220.tst: schlägt fehl im release-build!

    Lese Spezifikationen von /usr/lib/gcc/x86_64-pc-linux-gnu/3.4.5/specs
    Konfiguriert mit: /var/tmp/portage/gcc-3.4.5/work/gcc-3.4.5/configure
    --prefix=/usr --bindir=/usr/x86_64-pc-linux-gnu/gcc-bin/3.4.5
    --includedir=/usr/lib/gcc/x86_64-pc-linux-gnu/3.4.5/include
    --datadir=/usr/share/gcc-data/x86_64-pc-linux-gnu/3.4.5
    --mandir=/usr/share/gcc-data/x86_64-pc-linux-gnu/3.4.5/man
    --infodir=/usr/share/gcc-data/x86_64-pc-linux-gnu/3.4.5/info
    --with-gxx-include-dir=/usr/lib/gcc/x86_64-pc-linux-gnu/3.4.5/include/g++-v3
    --host=x86_64-pc-linux-gnu --build=x86_64-pc-linux-gnu --disable-altivec
    --enable-nls --without-included-gettext --with-system-zlib --disable-checking
    --disable-werror --disable-libunwind-exceptions --enable-multilib
    --disable-libgcj --enable-languages=c,c++,f77 --enable-shared
    --enable-threads=posix --enable-__cxa_atexit --enable-clocale=gnu
    Thread-Modell: posix
    gcc-Version 3.4.5 (Gentoo 3.4.5, ssp-3.4.5-1.0, pie-8.7.9)
    
-----------------------------------------------------
-----------------------------------------------------

x profiling! aber mit der release-version...

        x viele valgrind-fehler

        x test 220 schlägt fehl, bei --reopen=1 und --pagesize=1024

        x monster.sh

        x die wichtigsten tests in den wichtigsten konfigurationen mit 
            valgrind prüfen

        x eine neue option, mit der man die freelist schneller machen kann
            -> die dateien werden halt etwas grösser
            x tests/db.c anpassen
            x monster.sh anpassen
            x testen!

        x valgrind-tests schlagen fehl:
            x ../../../hamsterdb-tests/trunk/testfiles/1/45.tst --reopen=1
            x ../../../hamsterdb-tests/trunk/testfiles/1/45.tst --mmap=0
                    --overwrite=1 --reopen=1
            x ../../../hamsterdb-tests/trunk/testfiles/1/ext_060.tst
                    --inmemorydb=1
            x ../../../hamsterdb-tests/trunk/testfiles/1/ext_020.tst --keysize=8
                    --overwrite=1 --reopen=1
                    --> invalid keysize??
            x ../../../hamsterdb-tests/trunk/testfiles/1/ext_060.tst --keysize=8
                    --overwrite=1 --reopen=1
                    --> invalid keysize??

-----------------------------------------------------

o neue profile-runde, damit wir zahlen haben
    (auch die dateigrössen vergleichen!)

o vergleiche mit den bisherigen zahlen
    (blog-artikel! interessant auch, dass time(2) zeigt, dass der grösste
    teil im usermode abläuft; d.h. der zugriff auf die platte ist wirklich
    nicht der limitierende faktor!)

-----------------------------------------------------

o auf autoconf/automake umstellen
    x in blog-artikel dokumentieren

-----------------------------------------------------

o nächsten release machen!

o VORSICHT! am besten ein skript schreiben - make-release.sh
    1. version.h hochzählen
    2. einchecken
    3. taggen bzw. copy in release-trunk in hamsterdb-v.v.v
    4. einchecken
    5. export vom release-verzeichnis
    6. tar/gzip
    7. upload

o Regelwerk für releases schreiben, z.b.
    1. alle tests (auch 2-4) durchlaufen (monster.sh)
    2. ausgewählte tests mit valgrind (valgrind.sh)
    3. sicherstellen dass alles eingecheckt ist
    4. changelog updaten
    5. make-release.sh

-----------------------------------------------------
-----------------------------------------------------

o das test-tool umschreiben - nur noch die db.c, die anderen
    optionen (-c etc) können raus

o verschieben in das test-verzeichnis?

-----------------------------------------------------

o prefix comparison hinzufügen (schon vorhanden?)

o prefix comparison testen

o stress test mit zufällig fehlschlagenden io-funktionen und zufälligen
    OUT_OF_MEMORYs

o endianness testen

o port to ms windows
    o mit mingw, bcc, watcom, msvc, icc...
    o projekt-umgebungen für visual studio 6 und .NET
    o define HAM_EXPORT DECLSPEC _dllexport for DLLs und .so

o nächsten release machen!

-----------------------------------------------------
-----------------------------------------------------

o iteratoren 
    o sind schon designt (siehe iterators.txt im rechner auf arbeit)

    o in-memory-db: finden wir ne möglichkeit, normale datenbanken in 
        in-memory zu importieren und umgekehrt wieder zu exportieren? 
        das wäre genial
        --> geht mit iteratoren (erst release 2.0!):
            iterator from=db1.begin()
            while (from)
                db2.append(from)
                from.next()
        --> geht auch mit der enum-funktion, die jetzt schon drin ist

o nächsten release machen!

-----------------------------------------------------
-----------------------------------------------------

o duplicate keys (nicht in version 0.1.0, sondern 0.1.1)
    jeder key bekommt einen dupcounter; der wird mit unsigned(-1) initialisiert
    beim einfuegen wird rekursiv abgestiegen. im leaf wird dann ein neuer key
    eingefuegt, mit dem dupcounter=existierender ("kleinster") key minus 1.

-----------------------------------------------------

o mehrere datenbanken in einer datei
    (siehe eintrag im notizbuch)

    -> database-environment (ein file fuer mehrere datenbanken, 
        gesharter cache, geshartes file-handle, freelist etc)

-----------------------------------------------------
-----------------------------------------------------

o doku
    o tutorial/sample in die online-hilfe einbeziehen
    o FAQ mit häufig gestellten fragen, tips zu optimierungen
    o Dokumentation in den header-dateien überarbeiten
    o überarbeiten

-----------------------------------------------------

o statistics
    will wissen wie viele freelist-hits/misses und cache-hits/misses es gab,
    auch im extkey-cache

o statistics
    get generic getter/setter for statistical value, i.e. 
        enum { CACHEHITS, CACHEMISSES, PAGES, FREEPAGES, ... };
        ham_u64_t statistics[8];
    set_stats_value(db, which, value): db->statistics[which]=ham_h2db32(value)
    ATTENTION: some of those values are specific for each backend, others
        are global; therefore we need two functions: 
        ham_get_global_statistics(stat)
        ham_get_index_statistics(index, stat)

-----------------------------------------------------
-----------------------------------------------------

o tools
    o ham_dump
    o ham_info
    o ham_recover

-----------------------------------------------------

o super-COMPRESSED-mode: keine headerpage, und pagesize auf 128 byte ->
    super-mini-datenbanken (für embedded) - möglich ohne Aufwand? wird tricky, 
    weil die page-alloc-funktionen davon ausgehen dass eine adresse 0 ein
    fehler ist

-----------------------------------------------------

o datenbank mit O_EXCL öffnen, bzw mit flock() (und nem wait, falls die 
    Datenbank gelockt ist) -> Möglichkeit für pseudo-concurrent access bei
    kurzen, schnellen Zugriffen (z.b. webseite)

-----------------------------------------------------

o cache: bucketgrösse in ham_config.h verschieben, eine #define-konstante
    draus machen

-----------------------------------------------------
-----------------------------------------------------

Version 0.1.0 - first release!!

o komplettes review
    werden fehlerwerte korrekt propagiert?
    machen fehlerwerte immer sinn? z.b. in flush_all()
    was passiert mit fehlern beim flushen?
    was passiert mit fehlern in ham_close()?
    o ein paar sachen müssten umbenannt werden:
        o alle statischen funktionen bekommen statt "my_" ein 
            prefix, das ihrem modul entspricht (z.b. "bt_" für btree etc)
        o keys.h/keys.c aufteilen in generische keys (zusammenlegen mit extkeys)
            und btree-spezifischen keys
        o db hat 2 funktionen, die die extended keys löschen - das gehört
            ins backend
    o nochmal schaun ob die ganzen flags so sinn machen

-----------------------------------------------------
-----------------------------------------------------


x bbaum fehlerfrei
x TXN raus (wir können die txn's auch komplett
    für diesen release abschalten... man soll dafür ja ne spezielle version
    kaufen müssen)
x caching
x memory-mapped access
x in memory-datenbanken
x overwrite keys
x extended keys
x erzeugt .dll/.so
x mal nachschauen was man nach den GPL-Codingrules noch für 
    dateien braucht -> nix mehr
x performance vergleichbar mit berkeley-db
o iteratoren
o mehrere db in einer datei
o compiliert unter linux, windows, darwin, 32bit und 64bit, unter windows
    mit mingw, icc, msvc, borland, watcom
o legal issues
o dokumentation: tutorial, interface, FAQ (auch zu unittests)
o webseite
    news
    releases
    download
    faq
    documentation
    tutorial
    mailingliste
o stress-test-tool(s), das ALLE optionen durchprobiert
    mmap
    r/w
    in-memory
    verschiedene pagesizes
    grosse keys
    grosse blobs
o admin-tool(s) fuer dump, stats, repair
    o db_dump: 
        o key/daten dumpen
        o header dumpen
o KEINE valgrind-fehler!

    freshmeat
    alle anderen linklisten
    blog-eintrag (pingen!)

-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------

o backend
    o darauf hinarbeiten dass später mal mehrere backends in einer datei
        sind, nicht nur eines

o blob
    o neu: header in jeder page mit blobid
    o header auch im verify prüfen

o debug
    o im debug-modus output wie gehabt; bei non-debug: statt file- und line
        nur "hamsterdb: " ausgeben

o filter
    generische filter, sowie 2 implementationen davon: ein encryption-codec 
    und ein zlib-codec
    arbeiten sie page- oder blob-basiert? evtl waere page-basiert besser, 
    denn dann koennten auch index-pages (bzw NUR index-pages) gefiltert 
    werden.
    (my_result_t) (*filter)(my_key_t *key, my_data_t *data, int direction);

o hash-tabelle
    @@@

o bindings 
    c++-wrapper (ähnlich stl? müsste möglich sein, aber
    schwer), python-db-modul, perl, java (alle swig?)

o asset-tool
    GUI und library für computerspiele

-----------------------------------------------------
-----------------------------------------------------

Version 0.2.0

o duplicate keys
o iteratoren
o bindings: C++, Python, Perl, PHP (mit online-demo!)
o filter: encryption
o filter: compression

-----------------------------------------------------

Version 0.3.0

o database-environment (ein file fuer mehrere datenbanken, gesharter cache,
    geshartes file-handle, freelist etc)
    etc)
o hash-tabelle
o live reorganisation???

-------------------------- literature -----------------------
pB+ Trees prefetching B+ Trees 
[CGM01] Improving Index Performance through Prefetching. S. Chen, P.B. 
Gibbons, and T.C. Mowry. ACM International Conference on Management
of Data (SIGMOD), Santa Barbara, California, May 2001
[GL01] B-Tree Indexes and CPU Caches. G Graefe and P. Larson. International
Conference on Data Engineering (ICDE), Heidelberg, Germany, April 2001.
[RR00] Making B+ Trees Cache Conscious in Main Memory. J. Rao 
and K.A. Ross. ACM International Conference on Management of Data (SIGMOD),
Dallas, Texas, May 2000.

