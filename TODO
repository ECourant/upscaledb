
x improve unittests

x erlang does not build because ./configure overwrites CFLAGS

x cleanup cursor code
    x clean up the public interface
    x BtreeCursor: use intrusive_list for linked list
    x BtreeCursor: do not expose parent pointer
    x LocalDb: cleanup the whole code
    x LocalCursor: cleanup private functions
    x create cursors on the stack
    x avoid frequent cloning of cursors
    x the LocalCursor should have 3 states:
        - nil
        - coupled to btree
        - coupled to txn
        x is_nil()
        x is_btree_active()
        x is_txn_active() 
        x set_to_nil()
        x activate_btree(bool exclusive = false)
        x activate_txn(bool exclusive = false)

x cleanup transactions
    x hide refcount in base class ("ReferenceCounted")
    x use intrusive_list.h for transactions in TxnManager

x get rid of the Context object (see trello comments)
    x remove context.env

x improve journal performance
    The journal only needs to be updated if a transaction is committed, but
    not if it's aborted or for each separate operation.
    x no need to have buffers in the journal - flush them after each
        transaction was committed
    x append to log only when txn is committed
        In txn->commit: foreach (TxnOperation *op)
          journal->append(op);
        journal->append_commit(txn); // flush journal buffer
        x fix Journal/recoverAfterChangesetAndCommit2Test
    x refactor the code flow
        x flush_transaction_to_journal();
        x flush_transaction_to_changeset();
        x flush_changeset_to_journal();
        x flush_changeset_to_file();
    x batch-flush multiple transactions
    x manual test: make sure that the file sizes do not explode!
    x make sure that the recovery tests are running stable
    x run perftests/benchmarks

o improve MaskedVbyte
    o review the current sources
    o use an interface similar to libfor
    o scalar version should not use ANY SIMD!
    o use MaskedVbyte if SIMD is available
    o make sure to use the newest version of MaskedVbyte
    o use lookup table for select()? run benchmarks

o more Btree refactoring
    o common base class for KeyList and RecordList
    o move range size, range pointer, LocalDb*, BtreeNode* to this base class
    o remove support for the GroupVarbyte and StreamVbyte codecs
    o VARBYTE and MASKEDVBYTE become synonyms, use libvbyte for both
    o document pro/cons for each codec in the header file

o recovering "erase": the duplicate ID is lost!? - verify and fix

o uint32 record compression
    o SIMD FOR
    o libfor
    o libvbyte

o new API for bulk operations
    o use from .NET
    o use from remote

o improve Java API wrapper (see trello)
    o use new bulk api for Java

o BlobManager: move to Database
    o the Environment maybe also needs one? not sure
    o move record compressor to BlobManager
    o each database keeps its "last known blob page"
    o blob pages are not shared between databases
    o can we remove the "db" pointer from the Context structure?

o new test case for cursors
    insert (1, a)
    insert (1, b) (duplicate of 1)
    move (last) (-> 1, b)
    insert (1, c)
    move (last) (-> 1, c)? is the dupecache updated correctly?

o recovery tests are brittle and sometimes fail
    (enable core files and wait for segfault)

. add built-in predicate "greater", "greater-than", "lower",
    "lower-than", "equals"?
    -> how to pass the parameters?
    -> not as plugin but as built-in operators? - no...
    o make sure that they are not used as a function
    o only for numeric data

. add built-in predicate "starts-with" for strings/binary data
. add built-in predicate "like" for regex on strings/binary data


------------------- idea soup ---------------------------------------------

- compilation for ARM:
    sudo apt-get install g++-arm-linux-gnueabihf
    ./configure --host=arm-linux-gnueabihf --disable-simd --enable-debug

o remove dependency to libuv 1.0, use boost::async instead (makes the build
    process a lot smoother)

o add tests to verify that the cursor is not modified if an operation fails!
    (in cursor.cpp:LongTxnCursorTest are some wrapper functions to move or
    insert the cursor; that's a good starting point)


o More things to refactor in the btree
    o EraseAction uses duplicate_index + 1, InsertAction uses duplicate_index
        -> use a common behaviour/indexing
    o EraseAction line 71: if the node is empty then it should be merged and
        moved to the freelist!

o when splitting and HAM_HINT_APPEND is set, the new page is appended.
    do the same for prepend!

o The PageManager state is currently stored in a compressed encoding, but
    it is less efficient than the standard varbyte encoding because
    pages > 15 * page_size have to be split. Use a standard vbyte encoding
    instead (it will anyway be required later on).

o Implement record compression - a few notes
    ByteSlice: Pushing the Envelop of Main Memory Data
    Processing with a New Storage Layout
    http://delivery.acm.org/10.1145/2750000/2747642/p31-feng.pdf

    1) the user defines the record structure.
    2) an optimization stage reorders the record columns to optimize storage
        (i.e. with dynamic programming)
    3) SIMD code is generated on the fly to pack, unpack records and single
        elements (see http://stackoverflow.com/questions/4911993/how-to-generate-and-run-native-code-dynamically or ask Ben/Andi...)
    4) Pack like PAX (group all column values together) or each record
        standalone?

o look for a better compression for DefaultRecordList, i.e.
    - Each group is a GroupedVarInt w/ 4 bits per entry; a 64bit
        number can then hold flags for 16 numbers
        -> (but maybe increase this to hold at least 32 or 64 numbers, to
            reduce the overhead ratio)
    o create a GroupedVarInt<Max, T> class, where |Max| is the maximum number
        of elements that are grouped, and T is the type of these elements
        (i.e. uint64_t)
        -> memory is managed by the caller
        -> the state (i.e. used block size etc) is stored externally, and
            managed by the caller
        o append a key
        o prepend a key
        o insert a key in the middle
        o grow blocks
        o split blocks
        o can perform copies w/o re-compressing

    o try to move the Zint32 index to a base class
    o Use small index which stores offset + bits for each group
    o a separate bit is used to signal whether the (compressed) number is
        a record id
    o avoid ripple effects by growing/splitting the block

o use compression also for duplicate records
    i.e. use GroupedVarint for inline duplicates

o Concurrency: merge BtreeUpdates in the background

o when recovering, give users the choice if active transactions should be
    aborted (default behavior) or re-created
    o needs a function to enumerate them

o A new transactional mode: read-only transactions can run "in the past" - only
    on committed transactions. therefore they avoid conflicts and will always
    succeed.

o need a function to get the txn of a conflict (same as in v2)
    ups_status_t ups_txn_get_conflicting_txn(ups_txn_t *txn, ups_txn_t **other);
        oder: txn-id zur√ºckgeben? sonst gibt's ne race condition wenn ein anderer
        thread "other" committed/aborted
    o also add to c++ API
    o add documentation (header file)
    o add documentation (wiki)

