
x release 0.4.6

o tests are failing:
    --duplicate=1 --pagesize=65536
      o ../../testfiles/1/201.tst - freelist goes berzerk
      o ../../testfiles/1/202.tst - freelist goes berzerk
    --duplicate=1 --use-cursors=1
      o ../../testfiles/1/100.tst - status mismatch
      o ../../testfiles/1/202.tst - status mismatch
      o ../../testfiles/1/220.tst - status mismatch

o recno on big endian
    x ham_find/ham_erase/ham_cursor_find: make sure that the parameter size 
        is ok
    x ham_find/ham_erase/ham_cursor_find: translate key to db-endian
        (currently, unittest fails on big endian)
    x other unittests are failing
    o check acceptance tests!
    o enhance endian-create.sh and endian-check.sh

o duplicate items on big endian
    x create unittest
    x check-in le-database (created by the new sample)
    x check-in be-database (created by the new sample)
    o enhance endian-create.sh and endian-check.sh

o update tutorial - it's missing information about duplicate items

o check ham_txn_abort in btree_cursor.c
    this call never appears in hamsterdb.c, but quite frequently in the
    cursor routines; is this a problem?

o be more careful when uncoupling cursors - especially when inserting 
    or deleting items, uncoupling is often not necessary
    o definitely no need to uncouple if overwriting or adding a duplicate

o more ideas for unittests
    o unittests: insert NULL/TINY/SMALL blobs, then create linked lists
    o unittests: insert NULL/TINY/SMALL as duplicates
    o unittests: insert NULL, then replace with TINY, then with SMALL, 
        then with big, then SMALL, TINY, NULL
    o unittests: 
        o create cursor -> must be NIL
        o insert item   -> must be NIL
        o move cursor to item
        o insert item2 < item -> cursor is uncoupled
        o move cursor to item
        o insert duplicate of item -> cursor is still coupled
        o insert item2 > item -> cursor is still coupled

o ham_close with flag HAM_AUTO_CLOSE_CURSORS
    o unittests

o ham_env_close with flag HAM_AUTO_CLOSE_DATABASES
    o unittests

o btree_insert:421 - why is the extkey deleted??

o protect users against uninitialized ham_key_t and ham_record_t structures
    o check if key->flags is 0 or USER_ALLOC
    o check if key->_rid is 0
    o check if record->flags is 0 or USER_ALLOC
    o check all other private flags
    o unittests!

o create a new repository for hamsterdb-alien for all dependencies 
    in source and precompiled (static/non-debug - cppunit and berkeleydb)
    x linux64-le
    x linux32-le
    o cygwin32
    o win32
    o win64
    o wince-x86
    o ppc32-be

o record numbers should not be reused
    currently, if the last record is deleted, and then the database is
    reopened, this record number is reused
    persistently cache the number of elements in the database - we need 
    this information anyway.
    o do NOT add a new function ham_get_count(), because this information
        is risky - if keys are inserted, but the application crashes, 
        the information is wrong
    o if the database is opened and the first recno item is appended AND
        the key already exists: re-read the largest key and set the counter
        again  

o optimization idea: could use lookaside-list for the last 5/10 
    duplicate tables

o optimization idea: could use lookaside-list for the last 5/10 
    freelist pages

o extkey_cache: merge extkey_cache_remove() and blob_free()

o key_set_record does not always need to dirty the page (i.e. when
    appending duplicates) -> don't set page dirty in the caller

o cursor_overwrite/cursor_insert: 
    currently, the cursor_dupe_cache is deleted, but we don't have to
    also, in cursor_move there are some optimizations regarding the
    cache (search for TODO)

o ham_get_duplicate_count (???)
    x blob_duplicate_get_count(dupe_table_id);
    o unittests

o new sample for duplicate keys
    modify sample env1, to create a 1:n relationship between orders
    and customers (or create a new sample)

. webpage
    o move to cakephp framework
    o frontpage: resize hamster picture; remove text -> more space below
        (for 3 colums: news, main features, articles/testimonials/link cloud)

o btree_node_search_by_key uses linear search, no binary search
    -> optimize this!!

o new option HAM_DISABLE_AUTO_REORG -> adds empty chunks to freelist, but
    never uses freelist for allocation

o new option HAM_DISABLE_FREELIST -> completely disables the freelist (needs
    cmd line reorg-tool!)

o modify acceptance test for --duplicate=1 (berkdb and hamster)
    o new acceptance tests with many, many duplicates
    o --duplicate-position="before"|"after"|"first"|"last"(default)
        o add to monster.sh
        o add to valgrind.sh

o recno-unittest always overwrites the existing database; change the
    test so the original database is copied, and not modified
    o also test ham_find
    o also test ham_cursor_find
    o also test ham_erase
    o also test ham_cursor_erase
    o also test ham_insert
    o also test ham_cursor_insert

o win32: project for sample db5 is missing
    maybe restructure the solution file? one sln for win32, another for win64?
    i don't like it as it is right now

