 
I Am Legend:

Items are sorted by priority (highest on top).
o a pending  TODO item (for the current release)
. a pending  TODO item (for future releases)
x a finished TODO item

-----------------------------------------------------------------------------
This Branch Is About Integrating The hamsterdb2 Functionality!!!!!
-----------------------------------------------------------------------------

As a user i want to run many Transactions in parallel with high performance.
I'm not interested in multiple threads (yet), although i may use several 
threads (but then i'll use synchronization in my own code).
==============================================================================

x new code is only active if HAM_ENABLE_TRANSACTIONS is specified; 
    otherwise everything stays as is
    x allow more than one txn in parallel
    x don't need DO_NOT_NUKE_PAGE_STATS as flag for txn_abort/commit
    x env_flush_committed_txns() - must clear txn from list
    x rewrite auto-abort/auto-commit

x manage all transactions
    x integrate existing rb-tree code from hamsterdb2
        x rb.h
        x txns are linked lists (chronological) 
        x this tree stores operations for each key
            x create txn_op structure
            x create insert(update) and erase operations
            x each op is stored chronologically in the txn AND in the rb-node
        x each database has such a tree
    x remove the whole transaction handling from the low-level page
        i/o routines
        x also remove refcounts in the pages, replace with
            page_lock
            page_unlock
            page_is_locked
        x remove PAGE_LIST_TXN
    x remove env_get_txn, env_get_txn_id
        distinguish: on high level, we have multiple txns
        on low level, we use the lsn for file-io routines
            x extkeys.c - extkey_set_txn_id: replace with lsn
            x keys.c: move page_get_btree_node functions to btree.c; can we
                move everything else into util.c?
            x make sure that page_get_btree_node() is only called in
                btree_*.c 
                key_compare_pub_to_int
                key_compare_int_to_int
            x btree_close_cursors - actually in use? - yes
            x db.h - cleanup high level i/o interface
            x util.h - cleanup 
            x blob.h - cleanup interface if possible
            x page.h - cleanup 
            x rename int_key_t to btree_key_t
            x rename statistics.c to btree_stats.c (and rename the functions)

    x rewrite ham_insert
        x need functions to create trees/nodes/ops
                tree=txn_tree_get_or_create(db)
                node=txn_node_get_or_create(tree, key)
                op=txn_op_create(node, flags, record) -> store the full record!
                    -> all ops are in two linked lists!
        x if transactions are disabled: immediately write to disk, no
            temp transactions are needed
        x each modified database gets its own txn tree when its modified
            in a transaction
        x for now do not write the blob to disk but keep it in memory
        x otherwise insert into transaction tree
        x need a new error code HAM_TXN_CONFLICT
        x check for transaction conflicts (similar to ham2)

    x txn_free: discard the tree and everything that's allocated

    x implement env_flush_committed_txns()

    x add unittests for all the stuff I did so far
        x structure test: txn
        x structure test: txn_tree
        x structure test: txn_node
        x structure test: txn_op
        x allow multiple txn's in parallel and make sure that they
            are linked correctly
        x create a txn-tree for a txn/db twice and make sure that it's
            only created once
        x create multiple trees and make sure that they 
            are linked correctly
        x create a txn-node for a txn/db/key twice and make sure that it's
            only created once
        x create multiple nodes and make sure that they 
            are linked correctly
        x create an op for a txn-node
        x create multiple ops and make sure that they 
            are linked correctly in the node
        x test all potential conflict scenarios

    x tree is property of db, not of env (-> O(1))
        optree->_next really needed? - no
    x when op is deleted: update the node structure (op_next_in_node)
    x when op is deleted and node is empty: remove node from tree
    x when node is removed and tree is empty: remove tree from db
        or better: remove tree when db is closed
    x fix all unittests/memleaks
    x some structural changes -> need unittests
        txn_op_t previous_in_txn
        txn_op_t previous_in_node
        txn_op_t node
        txn_optree_node_t tree
    x who allocs/frees the key in the node? - streamline

    x rename txn_optree_node_t to txn_opnode_t (consistent with txn_optree_t)

    x rewrite ham_find
        x if transactions are disabled: immediately read from disk
        x otherwise go through transaction trees
        x add unittests

    x do not conflict if the same transaction already modified the key!

    x rewrite ham_erase
        x each modified database gets its own txn tree when its modified
            in a transaction
        x if transactions are disabled: immediately write to disk, no
            temp transactions are needed
        x otherwise go through transaction trees
        x add unittests

    x add new unittests

    x review page.h - anything that we do not need? (i.e. dirty_txn?) - no

    x ham_find: when retrieving a record, do not copy the original 
        record-pointer; we need a deep copy instead because this record
        pointer may be flushed and become invalid.
        -> db.c:1953

    x more pending cleanups
        x rename env_get_txn to env_get_flushed_txn, and set the 
            pointer in env.c(flush_txn)

    x txn.cpp 1171 - why does ham_insert succeed? it's inserting a duplicate!
        -> currently, HighLevelTxnTest::getKeyCountTest() crashes
        seems that the problem is in the rb enumeration (txn_tree_enumerate)
        where tree and tree->root are ok, but the first/next functions
        return bogus pointers

    x rewrite enumeration code
        x some just need to enumerate over btree
            x _fun_enumerate(free_inmemory_blobs_cb)
        x but others need to enumerate over txns as well
            x _fun_enumerate(my_calc_keys_cb)
                x implement db.c:db_get_key_count_txn(); needs to iterate
                    over all nodes in the tree!
                x need unittest: without txn's
                x need unittest: with txn's (aborted)
                x need unittest: with txn's (committed)
                x need unittest: with txn's (erased key)
                x need unittest: with txn's (dupes, with/without DUPE flag)
                x need unittest: with txn's (overwritten keys)

x db.c: all functions which begin a local_txn should be reviewed;
    a local_txn should only be started if transactions are enabled!

    x db.c:_local_fun_get_key_count: is local_txn really needed?
    x db.c:_local_fun_check_integrity: is local_txn really needed?
    x db.c:_get_incremented_lsn: fix TODO

x ham_get_key_count does not return correct results if there are duplicate
   keys (or overwritten keys) in a txn AND in the btree. In these cases, bite
   the sour apple and check if the keys also exist in the btree. Incorrect
   results have to be avoided!
    x when overwriting keys - 1 key in btree, the other in txn
        x add unittest
        x fix them
    x with duplicate keys - 1 key in btree, the other in txn
        x add unittest w/ duplicate counting
        x add unittest w/o duplicate counting
        x fix them

x make sure all unittests are running (with exception of logging)

x rewrite cache purging/page locking
    x do we still need to distinguish between env_fetch_page 
        and db_fetch_page? - not really, but it looks nicer
    x purge: move function to cache.h/.c, remove from db.c
    x whenever a function allocates/fetches: purge cache before backend
        function is called
    x unittest HamsterdbTest should run fine now
    x remove page locking - not required anymore
    x CacheTest::strictTest fails

x merge bugfixes of 1.1.8

o logging: currently, logging for txn_begin and txn_commit/abort 
    is not implemented
    -> we have to distinguish between txn logging (the WAL journal which
    records everything transactional) and the physical logging of the modified
    database pages (when flushing a txn). both can not be mixed; the latter
    we want to remove as soon as possible.
    -> how to continue? Use the journal from v2, and reduce the physical log
    for the single operations. we only have to store the last single operation,
    and we do not need undo information.
    
    x disable all broken tests in log.cpp
    x introduce a logical journal (based on same routines as before)
        with log-file switching
        x implement in journal.h/journal.c
        x unittest for switching back/forth and everything else
    x env: create journal
        x unittest
    x env: close journal
        x unittest
    x logical journal: add txn begin/commit/abort/insert/erase
        x remove the -prewrite logging, since we do not need undo information
            (be careful with allocated pages - they need special treatment
            when they're "redone")
        x write the functions in journal.c
        x need unittests for each operation
            x txn_begin
            x txn_commit
            x txn_abort
            x insert
            x erase
            x erase for cursors (different duplicate behavior!)
    o db.c/env.c: (logical) log begin/commit/abort/insert/erase
        x use the functions from journal.c
            x ham_txn_begin
            x ham_txn_commit
            x ham_txn_abort
            x ham_insert
            x ham_cursor_insert
            x ham_erase (delete ALL duplicates!)
            x ham_cursor_erase (duplicate handling!)
        o need unittests
            o ham_txn_begin
            o ham_txn_commit
            o ham_txn_abort
            o ham_insert
            o ham_cursor_insert
            o ham_erase (delete ALL duplicates!)
            o ham_cursor_erase (duplicate handling!)

    x new flag for ham_erase: HAM_ERASE_ALL_DUPLICATES
        x replace old BLOB_FREE_ALL_DUPES
        x unittest!

    o refactor log.h, rename ham_log_t to log_t (and others as well)
        x open/create functions similar to journal.h
        x log_flush needed externally? fileops are flushed automatically
        x disable log-file switching for physical log
        x remove all unrequired functions - txn_abort, commit, checkpoint etc
        x do not need undo information and undo functions
            x remove log_add_page_before
            x remove log_append_flush_page
            x rename log_add_page_after to log_append_page
        o ham_log_get_entry() currently reads from back to front, but we 
            need it vice versa!
        o always store only the last operation
            o assert that the log is empty (only debug!)
            o afterwards: write ALL modified pages to the log, THEN flush them
                with WRITE_THROUGH
            o afterwards: clear the log
    o decrease default journal threshhold (16?)
    o remove page_set_before_img_lsn()?

    o os_close: assert that fd>=3 (on linux)

    o we have to flush pages after they're modified (search for db_fetch_page
        and db_alloc_page); however, what if multiple pages are modified (i.e.
        during an SMO)? - we have to first physlog all modified pages, and then
        flush them all together; this way we minimize chances for corruption.
        same regarding SMOs - first wait till all modifications are done (in
        the cache), then flush the pages (or discard them if the operation
        failed for whatever reason)
        o re-introduce a structure similar to the old transaction list
            ("changeset"); don't forget to update my_verify_page()!
            o need unittests
        o when fetching a page, first check this list
            o need unittests
        o when fetching or allocating, insert page in this list
            o need unittests
        o when purging cache - do not delete this page (but i think this 
            anyway cannot happen since we never purge while an operation is
            in progress)
        o before each backend-related operation: assert that the list is clear
            o need unittests
        o after each backend-related operation: flush the list (or discard
            the cached pages if there was an error)
            o need unittests
        o after a changeset was successfully applied/flushed: clear the logfile
            o need unittests

    o who manages the lsn? currently, the journal and env.h manage both their
        own lsn; and it's not propagated down to the physlog
    o if recovery is enabled: after flushing the changeset, update the 
        lsn in the header file and flush this page
        o need unittests
    o recovery: how do we know with which lsn to continue?
        o use WRITETHROUGH (and make sure that it still works!) if recovery
            is enabled (would like to avoid this, but otherwise we need to write
            more information to the log, so it doesn't make a difference)
            o is it faster if we only flush the header of the page??
            o need unittests
        o if there's a physical log entry: apply it, take last lsn from this
            log entry. What to do if one lsn is mapped to several before/after 
            operations, i.e. because of a SMO? - after each single flush,
            we could update an index in the header structure of the log. This
            index will then tell us where to restart in the physlog. we can
            fix this later when moving to the journal
            o need unittests
        o if there's no physical log: read lsn from header page (which means
            that we have to flush the lsn in the header page after each 
            operation)
            o need unittests
        o then iterate through the logfile and re-apply all missing operations,
            abort all open transactions and commit all committed ones
            o need unittests
    o recovery: auto-aborts all non-committed transactions (same behavior 
            as now)
        o need unittests
    o recovery: re-apply all committed (but not fully flushed) transactions
        o need unittests
    o journal and log: flush file after it's written (at least in log AND
        in journal after abort/commit)
        o need unittests
    o re-enable logging tests in log.cpp

    o the journal and the log are now in use - create more unittests 
        (HighLevelJournalTests) which verify that both are used correctly


o implement partial reads through transaction tree - will have to 
    consolidate them

o implement approx. matching through transaction tree - will have to 
    consolidate rb-tree and btree to look for the "closest" key

o implement direct access - how, if the transaction tree is flushed??
    (but in-memory access w/ transactions is anyway not yet supported -
    write unittest to assert that it doesn't work)
    later: return error if DIRECT_ACCESS && IN_MEMORY && ENABLE_TXN

o support cursors!!!
    o separate cursor logic into btree and txn; in db.c, consolidate the
        two cursors
    o move first: use the cursor which is smaller
    o move right: use the cursor which is larger
    o move prev: use the cursor which is closer to the current one
    o move next: use the cursor which is closer to the current one
    o when flushing a transaction, and a cursor is pointing into the txn
        node: uncouple the cursor! (or delete it?)
    o db.c: do we need local_txn in the cursor functions?

o run monster tests

XXXXXXXXXXXXXXXXXXXXX release first version, merge with master XXXXXXXXXXXXXXX

o each operation writes a journal entry (however, we still keep the logical
        journal in parallel, otherwise the unittests will fail completely)
        o write entry for db_find
        o write entry for db_insert
        o write entry for db_erase
    o api function to get a list of pending transactions
    o recovery: recreate all pending transactions (if requested)
    o unittests

o ham_txn_begin receives Environment handle, not Database handle
    o need a new parameter (reserved) for parent txn
    o need a new parameter for txn name (string)
    o update unittests/add new tests
    o update C++ API
    o rewrite auto-abort/auto-commit -> move to env
    o what happens if a database is closed, but it's modified by a txn
        that is still active? -> error (verify this!)

o new API to retrieve the currently active transactions
    o already exists in v2
    o needs unittests

. extkeys: don't use txn_id for the 'age', use lsn instead

. opnode: use key instead of key* (pointer) - this saves one allocation 
    per node

. rename ham_bt_cursor_t to btree_cursor_t

. cache-garbagelist no longer used - remove it?

o continue as described in integrate-ham2.txt...
