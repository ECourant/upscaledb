I Am Legend:

Items are sorted by priority (highest on top).
o a pending  TODO item (for the current release)
. a pending  TODO item (for future releases)
x a finished TODO item

-----------------------------------------------------------------------------
This Branch Is About Integrating The hamsterdb2 Functionality!!!!!
-----------------------------------------------------------------------------
The big headline is:
As a user i want to run many Transactions in parallel with high performance.
I'm using multiple threads b/c my CPU has multiple cores, and expect hamsterdb
to scale with the number of cores.
==============================================================================

high-level plan for 2.2.0-pre1 (in decreasing priority)
x refactoring of configure.ac -> topic/next
x refactoring of the file format -> topic/next
x make freelist statistics endian clean -> topic/next
o btree understands fixed-size PODs -> topic/next
    o support existing callbacks - everything should work as advertised
    o support binary search only
    o support POD types: int32, uint32, int64, uint64, float, double,
        fixed length blobs, fixed length strings (?)
        (w/o duplicates and extended keys - they always enforce the
        default type based on the callback)
o cache oblivious btree layout (if it makes sense!) -> COMM
o specify timeout for remote client
o monster test can create graphs

-----------------------------------------------------------------------------

x rewrite configure.in; look at libuv for a good sample
    -> see topic/next

x collect file format incompatibilities
    -> see topic/next

o specify timeout for remote client
    o add new option HAM_PARAM_NETWORK_TIMEOUT_SEC
    o for unix
        struct timeval tv;
        tv.tv_sec = sec;  // 30 Secs Timeout
        tv.tv_usec = 0;
        setsockopt(sockfd, SOL_SOCKET, SO_RCVTIMEO, (char *)&tv, sizeof(tv));
    o for Windows
        http://msdn.microsoft.com/en-us/library/windows/desktop/ms740476%28v=vs.85%29.aspx
    o needs a unittest
    o for java
    o for dotnet

o use cache-oblivious b-tree layout
    o see roadmap document for more information
    o run a performance test/prototype if this is worth the effort
        o allocate a fixed number of pages (20) for the index
        o PageManager: when allocating a new page then use the distribution
            function to fetch a page from the reserved storage
    o this feature is *per database*
    o calculate number of reqd pages based on estimated keys from the user
    o make sure that this is not reverted when "reduce file size" feature
        (above) is enabled
    o the new pages are not managed by the freelist! therefore the freelist
        will not need any modifications
    . try to batch allocations; when new pages are required then don't just
        allocate one but multiple pages (if the database is big enough)

o new btree format for fixed-sized PODs
    -> see topic/next

o win32: a few unimportant unittests are failing (2.1.2)
o win32: generate protobuf-files in separate directories for each build

o monster tests must create performance graphs, namely
    o insert latency
    o erase latency
    o lookup latency
    o also for bdb!
    o also be able to include information from a previous release
    o use an embedded server in perftest.pl
        (i.e. http://search.cpan.org/~jesse/HTTP-Server-Simple-0.44/lib/HTTP/Server/Simple.pm)
    use https://developers.google.com/chart/interactive/docs/gallery/linechart
    and generate a small html file with the graphs, then open it in the browser
    (if possible).
    The Y axis is the latency (the lower the better), the X axis is a time
    indicator (not a timestamp, but a chronologically increasing counter).
    Also, there should be tooltips with the key size and record size
    of this particular insert or erase or lookup.

o increase libtool version
o increase API version in header file (if there are any incompatibilities)

. win32: need a release-v2.pl which fully automates the various release steps

. it would be interesting to know the distribution of changelog "sizes" during
    a test (i.e. how many operations result in changelogs of size 1, 2, 3 etc)
    and how many operations actually require the WAL

. review/rewrite/refactor Transaction class
    keep in mind that sooner or later the BtreeNode will expect template
    arguments; can we do something similar with the TransactionNode?
    x try to get the methods/design analoguous to the Btree - no, that
        does not make too much sense
    x document the tree structure in the header file
    x refactor the code
    o split into multiple files
    o try to cleanup the flow; move more code from db.cc to txn.cc
    . each Transaction should have its own PoolAllocator (based on ByteArray);
        when deleting the whole structure, only the PoolAllocator is freed
        o only do this if memory allocations cost performance
        o problem: a realloc() will not always work because it might move
            the allocated memory, and all existing pointers would be invalid 

. BtreeCursor: use memory arena for uncoupling the key
    -> better wait till extended keys are gone

. also remove locking from C# and Java APIs






------------------- idea soup ---------------------------------------------

o asynchronous prefetching of pages
    -> see posix_fadvice, libprefetch

o flush transactions in background (when the btree is concurrent)

. remove libjson, use boost::property_tree instead!
    o also on Windows!

o allow transactions w/o journal

o allow transactions w/o recovery

o when recovering, give users the choice if active transactions should be
    aborted (default behavior) or re-created
    o needs a function to enumerate them

o when flushing the Changeset: batch ALL changes for the WHOLE transaction,
    then flush all of them together. This way we can "merge" multiple changes
    for the same page.
    Also review the whole flush process - when not to log etc.
    - only 1 page affected: no need to log it because it is idempotent
    - freelist pages are always idempotent
    - more than 1 index page? not idempotent (most likely)
    - more than 1 blob page? not idempotent (maybe)
    o define a few benchmarks
    o be careful: if N operations are modifying the same changelog, and
        then #N+1 aborts then the aborting operation must NOT clear the
        changelog!

o A new transactional mode: read-only transactions can run "in the past" - only
    on committed transactions. therefore they avoid conflicts and will always
    succeed.

o changeset: instead of simply adding pages to the changeset, the caller
    could already specify whether this page needs logging or not;
    i.e. after freelist rewrite, the blob pages do not need logging if a
    blob is deleted  

o is there a way to group all changeset flushes of a Transaction into one
    changeset, and batch-commit multiple commits? that way we would avoid the
    frequent syncs and performance would be improved
    o would have to remove all of assert(changeset.is_empty())
    o but we can use that assert prior to txn_begin

o BtreeFindAction: always use a cursor, and when doing approx matching
    then simply move left or right with that cursor

o flush in background (asynchronously)
    o need new flag file HAM_DISABLE_ASYNCHRONOUS_FLUSH
    o if in-memory database: disable async flush
    o if transactions are disabled: disable async flush
    o if enabled: create background thread, wait for signal
    o ham_env_flush: if txn are enabled then try to flush them to disk
    o how to deal with an error in the background thread???
        o store in Environment, then return in every exported function
    o default: async flush is OFF!

    o extend monster tests
        o with async flush
        o without async flush
        o extend/run performance test
        o run monster tests

    o documentation
        o tutorial
        o faq

o need a function to get the txn of a conflict (same as in v2)
    ham_status_t ham_txn_get_conflicting_txn(ham_txn_t *txn, ham_txn_t **other);
        oder: txn-id zurÃ¼ckgeben? sonst gibt's ne race condition wenn ein anderer
        thread "other" committed/aborted
    o also add to c++ API
    o add documentation (header file)
    o add documentation (wiki)

. new test case for cursors
    insert (1, a)
    insert (1, b) (duplicate of 1)
    move (last) (-> 1, b)
    insert (1, c)
    move (last) (-> 1, c)? is the dupecache updated correctly?

. there are a couple of areas where a btree cursor is uncoupled, just to
    retrieve the key and to couple the txn-key. that's not efficient
        db.c:__btree_cursor_points_to
        db.c:__compare_cursors
        txn_cursor.c:cursor_sync
        txn_cursor.c:cursor_overwrite
    o move to a separate function
    o try to optimize

. add tests to verify that the cursor is not modified if an operation fails!
    (in cursor.cpp:LongTxnCursorTest are some wrapper functions to move or
    insert the cursor; that's a good starting point)

. new flag for transactions: HAM_TXN_WILL_COMMIT
    if this flag is set, then write all records directly to the file, not
    to the log. the log will only contain the rid.
    -> or: make this the default; call the new flag HAM_TXN_MAYBE_WILL_ABORT
    o in case of an abort: move the record to the freelist
    -> this affects all temporary ham_insert-transactions
    (not sure if this should get high priority)

. if memory consumption in the txn-tree is too high: flush records to disk
    (not sure if this should get high priority)

o ham_get_count: could be atomically updated with every journal entry

