
o logo!!

o webseite
    http://nitrosecurity.com/
    http://www.opf3.com/Opf3/Default.aspx
    http://www.pixelmedia.com/
    x grund-layout und php-framework erstellen
    x doxygen in webseite integrieren
    x hamsterdb.h ueberarbeiten, dokumentieren
    o tutorial
    o inhalte
        x frontseite
        x features
        x download
        x legal/impressum
        x sitemap
        x GPL/Verweise auf GPL
        x sidebars
        x roadmap
        x sidebars ueberpruefen
        o frontseite: hamster-bild einbetten (oder so lassen?)
        o doku bzgl installation, compilieren, portieren
        o startseite: "News"-Bereich
    o tutorial
    o api-doku und tutorial als PDF zum download
    o korrigieren lassen

x sicherstellen dass die folgenden flags nicht abgespeichert werden
    (beim open und create)
    HAM_DISABLE_VAR_KEYLEN 
    HAM_CACHE_STRICT
    HAM_DISABLE_MMAP
    HAM_OPEN_EXCLUSIVELY
    HAM_WRITE_THROUGH
    HAM_READ_ONLY
    HAM_OPTIMIZE_SIZE
    HAM_DISABLE_FREELIST_FLUSH
    x db_get_flags kommt raus; stattdessen: db_get_pers_flags() und 
        db_get_all_flags()
    x beim create wird in den pers. flags nur die "richtigen" flags 
        gespeichert
    x db_get_all_flags() gibt die flags vom caller (beim open oder create)
        verodert mit den persistent flags zurück
    x testen

x wenn die pagesize!=os_getpagesize ist, wird kein mmap genommen. aber
    zumindest unter posix (evtl nicht win32 und cygwin!) kann mmap immer 
    dann genommen werden, wenn die pagesize ein *vielfaches* von der 
    os-pagesize ist! coden, dann testen, auch unter cygwin und windows

x was passiert wenn ein cursor null ist, und man key/record holt, ohne 
    einen move zu machen? Muss CURSOR_IS_NIL zurückgeben

x HAM_OPEN_EXCLUSIVELY raus - das muss mal durch gescheites file-locking 
    ersetzt werden

o portieren auf linux/ppc

o portieren auf MacOS/Darwin

o sicherstellen dass die datenbanken endian-agnostic sind

o sicherstellen dass die datenbanken wordsize-agnostic sind

o release machen!

-----------------------------------------------------
-----------------------------------------------------

o es ist noch ein kleiner valgrind-bug drin:
    valgrind --tool=memcheck --leak-check=full --show-reachable=yes
    .libs/lt-test --file ../../../hamsterdb-tests/trunk/testfiles/1/ext_060.tst
    --inmemorydb=1 --verbose=1

o ham_flush: sollte os_flush aufrufen
    BOOL FlushFileBuffers(HANDLE hFile);
    bzw fflush oder so in linux

o os_tell durch os_get_filesize erweitern

o nächsten release machen

-----------------------------------------------------
-----------------------------------------------------

o gescheite roadmap schreiben (internes dokument), die TODO-liste
    behandelt dann immer nur den obersten/aktuellen eintrag der roadmap!

-----------------------------------------------------
-----------------------------------------------------

o file locking:
    o alles exclusive
    o on demand (locked_shared bei read, lock_ex bei write)

o 1 writer, multiple reader - wie lässt sich das machen?
    alle ohne caching, alle mit read-through/write-through?
    testen, evtl brauchen wir noch ein exclusive locking
    
-----------------------------------------------------
-----------------------------------------------------

o doku
    o tutorial/sample in die online-hilfe einbeziehen
    o FAQ mit häufig gestellten fragen, tips zu optimierungen
    o mailing list
    o interne doku schreiben
        o db-handle, pageverwaltung
        o backend-aufbau
        o freelist
        o cache
        o cursors

-----------------------------------------------------
-----------------------------------------------------

o tools
    o ham_dump
        erzeugt einen cursor auf den ersten eintrag, dumpt den 
        key und die daten (zumindest einen teil davon)
        --key-format=char|short|long|longlong|string|binary
        --key-length=<n>
        --data-format=char|short|long|longlong|string|binary
        --data-length=<n>
    o ham_info
        gibt alle infos aus dem header aus, sowie die anzahl der elemente,
        average key size, average data size, min/max etc
    o ham_recover
        holt die header-page, dann die root-page, und geht runter zum 
        ersten leaf. läuft dann alle index-pages ab, schreibt die keys 
        und die daten raus 
    o ham_check
        macht einen check_integrity auf die datenbank
    o ham_reorg
        macht eine reorg (im grunde nur ein neues schreiben der datenbank
        mit gleichzeitigem minimieren der freelist-entries)

-----------------------------------------------------
-----------------------------------------------------

o komplettes review
    werden fehlerwerte korrekt propagiert?
    machen fehlerwerte immer sinn? z.b. in flush_all()
    was passiert mit fehlern beim flushen?
    was passiert mit fehlern in ham_close()?
    o ein paar sachen müssten umbenannt werden:
        o alle statischen funktionen bekommen statt "my_" ein 
            prefix, das ihrem modul entspricht (z.b. "bt_" für btree etc)
        o keys.h/keys.c aufteilen in generische keys (zusammenlegen mit extkeys)
            und btree-spezifischen keys
        o db hat 2 funktionen, die die extended keys löschen - das gehört
            ins backend
    o nochmal schaun ob die ganzen flags so sinn machen
    o TODOs durchgehen

-----------------------------------------------------
-----------------------------------------------------

x bbaum fehlerfrei
x TXN raus (wir können die txn's auch komplett
    für diesen release abschalten... man soll dafür ja ne spezielle version
    kaufen müssen)
x caching
x memory-mapped access
x in memory-datenbanken
x overwrite keys
x extended keys
x mal nachschauen was man nach den GPL-Codingrules noch für 
    dateien braucht -> nix mehr
x performance vergleichbar mit berkeley-db
x erzeugt .dll/.so
x umsteigen auf autoconf/automake
x cursors
x stress-test-tool(s), das ALLE optionen durchprobiert
    mmap
    r/w
    in-memory
    verschiedene pagesizes
    grosse keys
    grosse blobs
o compiliert unter linux, windows, darwin, 32bit und 64bit, läuft auf 
    little- und bigendian
o dokumentation: tutorial, interface, FAQ
o webseite
o admin-tool(s) fuer dump, stats, repair, update, reorg
    o db_dump: 
        o key/daten dumpen
        o header dumpen
o KEINE valgrind-fehler!
o logo
o legal issues

-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------

o c++-api

-----------------------------------------------------
-----------------------------------------------------

o duplicate keys
    jeder key bekommt einen dupcounter; der wird mit unsigned(-1) initialisiert
    beim einfuegen wird rekursiv abgestiegen. im leaf wird dann ein neuer key
    eingefuegt, mit dem dupcounter=existierender ("kleinster") key minus 1.

    ist blöd, weil im key dann 2 (oder 4) byte für jeden key verloren gehen!
    ist auch blöd, denn wie will man mitten in den duplicates einen key
    einfügen? bdb kann das.

    alternative 1: key nur einmal speichern (evtl mit reference-counter), 
    dann eine linked list im blob-bereich -> aufwändig, kann langsam werden

    alternative 2: statt dup-counter nehmen wir ein tupel (key/rid). aber 
    auch das ist nicht eindeutig, denn wenn ein dupe gelöscht und ein anderes
    wieder eingefügt wird, und die freelist die selbe rid vergibt, 
    können wir beide nicht unterscheiden. das selbe passiert wenn der record
    NULL ist oder short.

    -> erstmal bei berkeleydb nachschaun, wie die das machen, und evtl 
    auch bei qdbm u.a. 

-----------------------------------------------------
-----------------------------------------------------

o mehrere datenbanken in einer datei
    (siehe eintrag im notizbuch)

    -> database-environment (ein file fuer mehrere datenbanken, 
        gesharter cache, geshartes file-handle, freelist etc)

-----------------------------------------------------
-----------------------------------------------------

o filter
    generische filter, sowie 2 implementationen davon: ein encryption-codec 
    und ein zlib-codec
    arbeiten sie page- oder blob-basiert? evtl waere page-basiert besser, 
    denn dann koennten auch index-pages (bzw NUR index-pages) gefiltert 
    werden.

    vielleicht müsste man unterscheiden zwischen page- und blob-basierten
    filtern...

    (my_result_t) (*filter)(my_key_t *key, my_data_t *data, int direction);

-----------------------------------------------------
-----------------------------------------------------

o bindings 
    python (auch für python-shelf!)
    perl
    php
    java
    COM
    .NET (Sample)
    C# (Sample)
    VB.NET (Sample)

-----------------------------------------------------
-----------------------------------------------------

o super-COMPRESSED-mode: keine headerpage, und pagesize auf 128 byte ->
    super-mini-datenbanken (für embedded) - möglich ohne Aufwand? wird tricky, 
    weil die page-alloc-funktionen davon ausgehen dass eine adresse 0 ein
    fehler ist

-----------------------------------------------------

o datenbank mit O_EXCL öffnen, bzw mit flock() (und nem wait, falls die 
    Datenbank gelockt ist) -> Möglichkeit für pseudo-concurrent access bei
    kurzen, schnellen Zugriffen (z.b. webseite)

-----------------------------------------------------

o hash-tabelle
    @@@

-----------------------------------------------------
-----------------------------------------------------

o asset-tool
    GUI und library für computerspiele

-----------------------------------------------------
-----------------------------------------------------

o live reorganisation???

-------------------------- literature -----------------------
pB+ Trees prefetching B+ Trees 

[CGM01] Improving Index Performance through Prefetching. S. Chen, P.B. 
Gibbons, and T.C. Mowry. ACM International Conference on Management
of Data (SIGMOD), Santa Barbara, California, May 2001

[GL01] B-Tree Indexes and CPU Caches. G Graefe and P. Larson. International
Conference on Data Engineering (ICDE), Heidelberg, Germany, April 2001.

[RR00] Making B+ Trees Cache Conscious in Main Memory. J. Rao 
and K.A. Ross. ACM International Conference on Management of Data (SIGMOD),
Dallas, Texas, May 2000.

