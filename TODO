I Am Legend:

Items are sorted by priority (highest on top).
o a pending  TODO item (for the current release)
. a pending  TODO item (for future releases)
x a finished TODO item

-----------------------------------------------------------------------------
This Branch Is About Integrating The hamsterdb2 Functionality!!!!!
-----------------------------------------------------------------------------
The big headline is:
As a user i want to run many Transactions in parallel with high performance.
I'm using multiple threads b/c my CPU has multiple cores, and expect hamsterdb
to scale with the number of cores.
==============================================================================

x protobuf is required even if remote code is disabled:
    see richardheath's mail on hamsterdb-user
    -> also seems to be the case in windows

x should database names still be reserved? - yes, i think so. even if they're
    not required right now, they will be required in the future.

x merge Johnathan Conley's patches (3 mails)

x refactoring: get rid of ham_bool_t, replace with bool whenever possible

x version.h: support file version (see topic/freelist)

x all packed structures that are directly mapped to the file
    (BlobPageHeader, BlobHeader and others) should be named
    "PXXX" (for "Persistent" or "Packed")

x Partial read: record->size returns the partial size that was retrieved.
    I think record->size should return the original size, and
    record->partial_size should return the size that was read.
    -- really?? yes, this is much cleaner
    x document this in the header file

x benchmark/prototype new freelist based on discarded one
    x a flat array (std::vector), not sorted
    x reserve 20 entries
    x free_area: append at end, if full then overwrite smallest
    x free_page: traverse all entries, remove if necessary
    x alloc: traverse lineary, pick best fit
    x check_integrity: not sure yet how, but need to implement it
    x run benchmarks

x new option to disable the freelist
    x clean up statistics.h
    x clean up PFreelistPageStatistics
    x clean up runtime_statistics_pagedata_t
    x clean up PFreelistSlotsizeStats
    x clean up freelist_stats_fail, _update, _edit etc
    x clean up freelist_hints_t
        x remove fields that are not required
        x create class FreelistStatistics::Hints, file freelist_stats.h/cc
    x same for freelist_global_hints_t
    x freelist_stats.h has global functions; move into FreelistStatistics
        namespace
    x run performance tests, just to make sure that we did not break anything
    x re-introduce page_manager (has ownership of Freelist, Cache, Pages etc)
    x clean up PageManager::alloc_blob

    x "old" hamsterdb.cc has different method to deal with freelist in header
        page - leave as is
    x split BlobManager into subclasses (in-memory, disk)
        x use ByteArray for "zeroes" when filling partial gaps
    x review unittest Freelist::overflow4 - remove

    x merge freelist and freelist_statistics
    x also rename unittests!
    x new Freelist is called "SimpleFreelist", owned by PageManager
    x rename SimpleFreelist to ReducedFreelist (and rename the files, too)

    x both derive from the same interface

    x EnvironmentStatistics::m_perf_data: move to Freelist

    x new option HAM_PARAM_FREELIST_POLICY
            - 0: FULL
            - 1: REDUCED
        x requires documentation - when to choose which?
        x for ham_env_create_db
        x extend ham_env_get_parameters
        x option is persistent!
            x unittest
        x page_manager dispatches to new freelist if flag is set
        x only create BitmapFreelist if it's really required
        x merge unittests from ~/tmp/hamsterdb
        x alignment is property of freelist:
            FullFreelist::get_blob_alignment() -> DB_CHUNKSIZE;
            ReducedFreelist::get_blob_alignment() -> 1;
            x see 2 x TODO in freelist.cpp unittests
        x extend (and run) the monster tests
        x extend (and run) the performance tests
        x check benchmarks; it feels that the percentages are not
            calculated properly
        x run benchmarks - does it make sense to have this new option??
        x also for Java
        x also for .NET

x BlobManager interface: get rid of Transaction pointer, not required

x get rid of memory allocator, use the new (static) one
    x Memory::release should check for null - clean up usage code
    x use HAVE_TCMALLOC!
    x get rid of the lookaside list
    x need to link in tcmalloc! (monster tests fail with linker errors)
        x clean up other libraries of monster test - don't link against
            libcurl, libprotobuf etc - not necessary; can use libtool
    x run performance tests
    x configure: print warning if tcmalloc is missing

x full_freelist: clean up the code
    x inline the statistics-functions because they require lots of performance
    x then check ./test --duplicate --no-berkeleydb ../../testfiles/4/215.tst

x cache improvements
    x when flushing, sort pages by ID/offset and use writev to flush them
    x use a dynamic hash table (std::vector); if vector becomes too full then
        resize and rehash
        o this needs a test
    --> performance degraded; try to avoid std::vector, use local array 
            on stack instead
    --> still no good; revert

x gcc has some nice attributes
    x __attribute__ ((noreturn))
        for ham_assert/ham_verify
    x __attribute__ ((hot))
        for the compare function

x run clang static analyzer

x really leave reduced freelist? the performance gains are not worth the
    additional complexity and we would introduce lots of technical debt
    -> remove it...

x refactor unittests, use same framework as hamsterdb-cluster

x we need more metrics in the monster tests:
    x create new module Metrics, with structure and API in hamsterdb_int.h
    x retrieve the following metrics
        x Memory::Metrics
        x track page fetch (page_manager)
        x track page flush (page_manager)
        x number of index pages (page_manager)
        x number of blob pages (page_manager)
        x number of freelist pages (page_manager)
        x number of freelist hits (freelist)
        x number of freelist misses (freelist)
        x track cache hits (cache)
        x track cache misses (cache)
        x track number of blobs written (blob)
        x track direct I/O blob reads (blob)
        x track direct I/O blob writes (blob)
    x use in monster test
    x compare in performance test (show 3 columns: old, new, diff %)

o win32: get rid of boost_thread

. run a performance test clang++ vs g++

. boost: configure script should make sure that only boost v 1.46 (or newer)
    is accepted
    -> also test with older versions, but 1.33 definitely does not work
    issue #17: https://github.com/cruppstahl/hamsterdb/issues/17




o AES encryption
    AES encryption with libcrypto (for 2.1.2):
    http://saju.net.in/code/misc/openssl_aes.c.txt

    Windows compilation:
    http://www.ski-epic.com/2007_notes_on_openssl/index.html
    http://developer.covenanteyes.com/building-openssl-for-visual-studio/
    http://wiki.openuru.org/index.php?title=Build_OpenSSL_with_MS_Visual_C%2B%2B
    http://eran.geek.co.il/wp/archives/3897

o improve client/server performance
    currently client/server is 10 times slower than standalone; can we improve
    this, i.e. by using keepalive/open connections?
    o use libevent2 on server side, get rid of mongoose
    o use boost sockets on client side, get rid of libcurl
    o use Pickle module, get rid of protocol buffers

. reduce the file size if freelist adds page at end of file
    (maybe cache the filesize in the device, to avoid frequent calls
    to os_get_filesize(); but compare both if HAM_DEBUG == 1)
    o only do this in ham_env_close and ham_env_flush
    o attention: if a file is truncated then recovery can re-create pages
        that are "outside" of the file boundaries! (we could do this only
        when the log is empty?!)
    o for reduced freelist we might have to make sure that we store free blobs
        if they are at the end of the file

. pre-allocate index
    o see roadmap document for more information

. can we perform better with O_DIRECT? run some benchmarks

------------------- release 2.1.1 -----------------------------------------











o collect file format incompatibilities
    o for the new Btree code
    o persistent freelist statistics
    o get rid of the statistics-structures
    o reduce the PBlobHeader (remove flags, alloc_size)
    o what else?

o BtreeCursor: use memory arena for uncoupling the key

. also remove locking from C# and Java APIs

o split Transaction into local and remote class (really?)
    hamsterdb.cc directly calls into Transaction class instead of Environment
    o create PoolAllocator based on ByteArray
    o keep in mind that sooner or later the BtreeNode will expect
        template arguments; can we do something similar with the
        TransactionNode?
    o try to cleanup the flow; move more code from db.cc to txn.cc,
        reorg TransactionIndex similar to BtreeIndex
    o try to get the methods/design analoguous to the Btree
    o TransactionIndex:
        o TransactionIndex: use std::set<OperationNode> instead of rb.h?? Not
            sure if this is worth the troubles
        x check how/if std::multimap can replace rb.h - yes, seems to work
        o replaces the TransactionTree
        o one TransactionIndex per Database (always created)
        o txn_opnode_t -> TransactionOperation
        o try to move code from db.cc into TransactionIndex, i.e. to check
            conflicts etc
    o try to replace some of the linked lists with boost::intrusive_list
    o document the tree structure in the header file

o split Cursor into local and remote class (really?)
    o hamsterdb: directly call into Cursor class (instead of Database)

o is the recovery working if there's a crash during ham_db_close
    or ham_env_close?

o allow transactions w/o journal

o allow transactions w/o recovery

o move the whole configuration (key sizes, parameters, page size, etc) into a
    separate class which is instantiated by the env

o when recovering, give users the choice if active transactions should be
    aborted (default behavior) or re-created
    o needs a function to enumerate them

o fully (!) automize the whole release process for unix; the result (on
    success) are the following files:
    o tar-ball
    o the README
    o the documentation
    o the Changelog
    o the release notes (a template)
    o move monster test to ec2?
    o the output of the monster tests and the performance test
    o windows-packages

o update documentation
    x in header file
    o in the wiki
        o don't forget to list all functions that are currently disabled
            w/ txn's -> sorting dupes, approx. matching, ...
        o transactional behavior/conflicts of duplicate keys
    o in the wiki: start with internal documentation
        o transactions
        o architecture
        o btree
        o journal/log
        o cache
        o I/O
        o unittests
        o cursor(s)
        o monstertests - how to use them?





------------------- idea soup ---------------------------------------------

o changeset: instead of simply adding pages to the changeset, the caller
    could already specify whether this page needs logging or not;
    i.e. after freelist rewrite, the blob pages do not need logging if a
    blob is deleted  

o is there a way to group all changeset flushes of a Transaction into one
    changeset, and batch-commit multiple commits? that way we would avoid the
    frequent syncs and performance would be improved
    o would have to remove all of assert(changeset.is_empty())
    o but we can use that assert prior to txn_begin

o BtreeFindAction: always use a cursor, and when doing approx matching
    then simply move left or right with that cursor

. track additional metrics
    o cache misses
    o cache hits
    o ...

o flush in background (asynchronously)
    o need new flag file HAM_DISABLE_ASYNCHRONOUS_FLUSH
    o if in-memory database: disable async flush
    o if transactions are disabled: disable async flush
    o if enabled: create background thread, wait for signal
    o ham_env_flush: if txn are enabled then try to flush them to disk
    o how to deal with an error in the background thread???
        o store in Environment, then return in every exported function
    o default: async flush is OFF!

    o extend monster tests
        o with async flush
        o without async flush
        o extend/run performance test
        o run monster tests

    o documentation
        o tutorial
        o faq

o need a function to get the txn of a conflict (same as in v2)
    ham_status_t ham_txn_get_conflicting_txn(ham_txn_t *txn, ham_txn_t **other);
        oder: txn-id zurückgeben? sonst gibt's ne race condition wenn ein anderer
        thread "other" committed/aborted
    o also add to c++ API
    o add documentation (header file)
    o add documentation (wiki)

. new test case for cursors
    insert (1, a)
    insert (1, b) (duplicate of 1)
    move (last) (-> 1, b)
    insert (1, c)
    move (last) (-> 1, c)? is the dupecache updated correctly?

. there are a couple of areas where a btree cursor is uncoupled, just to
    retrieve the key and to couple the txn-key. that's not efficient
        db.c:__btree_cursor_points_to
        db.c:__compare_cursors
        txn_cursor.c:cursor_sync
        txn_cursor.c:cursor_overwrite
    o move to a separate function
    o try to optimize

. add tests to verify that the cursor is not modified if an operation fails!
    (in cursor.cpp:LongTxnCursorTest are some wrapper functions to move or
    insert the cursor; that's a good starting point)

. new flag for transactions: HAM_TXN_WILL_COMMIT
    if this flag is set, then write all records directly to the file, not
    to the log. the log will only contain the rid.
    o in case of an abort: move the record to the freelist
    -> this affects all temporary ham_insert-transactions
    (not sure if this should get high priority)

. if memory consumption in the txn-tree is too high: flush records to disk
    (not sure if this should get high priority)

o ham_get_count: could be atomically updated with every journal entry

