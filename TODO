 
I Am Legend:

Items are sorted by priority (highest on top).
o a pending  TODO item (for the current release)
. a pending  TODO item (for future releases)
x a finished TODO item

-----------------------------------------------------------------------------
This Branch Is About Integrating The hamsterdb2 Functionality!!!!!
-----------------------------------------------------------------------------

As a user i want to run many Transactions in parallel with high performance.
I'm not interested in multiple threads (yet), although i may use several 
threads (but then i'll use synchronization in my own code).
==============================================================================

x new code is only active if HAM_ENABLE_TRANSACTIONS is specified; 
    otherwise everything stays as is
    x allow more than one txn in parallel
    x don't need DO_NOT_NUKE_PAGE_STATS as flag for txn_abort/commit
    x env_flush_committed_txns() - must clear txn from list
    x rewrite auto-abort/auto-commit

x manage all transactions
    x integrate existing rb-tree code from hamsterdb2
        x rb.h
        x txns are linked lists (chronological) 
        x this tree stores operations for each key
            x create txn_op structure
            x create insert(update) and erase operations
            x each op is stored chronologically in the txn AND in the rb-node
        x each database has such a tree
    x remove the whole transaction handling from the low-level page
        i/o routines
        x also remove refcounts in the pages, replace with
            page_lock
            page_unlock
            page_is_locked
        x remove PAGE_LIST_TXN
    x remove env_get_txn, env_get_txn_id
        distinguish: on high level, we have multiple txns
        on low level, we use the lsn for file-io routines
            x extkeys.c - extkey_set_txn_id: replace with lsn
            x keys.c: move page_get_btree_node functions to btree.c; can we
                move everything else into util.c?
            x make sure that page_get_btree_node() is only called in
                btree_*.c 
                key_compare_pub_to_int
                key_compare_int_to_int
            x btree_close_cursors - actually in use? - yes
            x db.h - cleanup high level i/o interface
            x util.h - cleanup 
            x blob.h - cleanup interface if possible
            x page.h - cleanup 
            x rename int_key_t to btree_key_t
            x rename statistics.c to btree_stats.c (and rename the functions)

    x rewrite ham_insert
        x need functions to create trees/nodes/ops
                tree=txn_tree_get_or_create(db)
                node=txn_node_get_or_create(tree, key)
                op=txn_op_create(node, flags, record) -> store the full record!
                    -> all ops are in two linked lists!
        x if transactions are disabled: immediately write to disk, no
            temp transactions are needed
        x each modified database gets its own txn tree when its modified
            in a transaction
        x for now do not write the blob to disk but keep it in memory
        x otherwise insert into transaction tree
        x need a new error code HAM_TXN_CONFLICT
        x check for transaction conflicts (similar to ham2)

    x txn_free: discard the tree and everything that's allocated

    x implement env_flush_committed_txns()

    x add unittests for all the stuff I did so far
        x structure test: txn
        x structure test: txn_tree
        x structure test: txn_node
        x structure test: txn_op
        x allow multiple txn's in parallel and make sure that they
            are linked correctly
        x create a txn-tree for a txn/db twice and make sure that it's
            only created once
        x create multiple trees and make sure that they 
            are linked correctly
        x create a txn-node for a txn/db/key twice and make sure that it's
            only created once
        x create multiple nodes and make sure that they 
            are linked correctly
        x create an op for a txn-node
        x create multiple ops and make sure that they 
            are linked correctly in the node
        x test all potential conflict scenarios

    x tree is property of db, not of env (-> O(1))
        optree->_next really needed? - no
    x when op is deleted: update the node structure (op_next_in_node)
    x when op is deleted and node is empty: remove node from tree
    x when node is removed and tree is empty: remove tree from db
        or better: remove tree when db is closed
    x fix all unittests/memleaks
    x some structural changes -> need unittests
        txn_op_t previous_in_txn
        txn_op_t previous_in_node
        txn_op_t node
        txn_optree_node_t tree
    x who allocs/frees the key in the node? - streamline

    x rename txn_optree_node_t to txn_opnode_t (consistent with txn_optree_t)

    x rewrite ham_find
        x if transactions are disabled: immediately read from disk
        x otherwise go through transaction trees
        x add unittests

    x do not conflict if the same transaction already modified the key!

    x rewrite ham_erase
        x each modified database gets its own txn tree when its modified
            in a transaction
        x if transactions are disabled: immediately write to disk, no
            temp transactions are needed
        x otherwise go through transaction trees
        x add unittests

    x add new unittests

    x review page.h - anything that we do not need? (i.e. dirty_txn?) - no

    x ham_find: when retrieving a record, do not copy the original 
        record-pointer; we need a deep copy instead because this record
        pointer may be flushed and become invalid.
        -> db.c:1953

    x more pending cleanups
        x rename env_get_txn to env_get_flushed_txn, and set the 
            pointer in env.c(flush_txn)

    x txn.cpp 1171 - why does ham_insert succeed? it's inserting a duplicate!
        -> currently, HighLevelTxnTest::getKeyCountTest() crashes
        seems that the problem is in the rb enumeration (txn_tree_enumerate)
        where tree and tree->root are ok, but the first/next functions
        return bogus pointers

    x rewrite enumeration code
        x some just need to enumerate over btree
            x _fun_enumerate(free_inmemory_blobs_cb)
        x but others need to enumerate over txns as well
            x _fun_enumerate(my_calc_keys_cb)
                x implement db.c:db_get_key_count_txn(); needs to iterate
                    over all nodes in the tree!
                x need unittest: without txn's
                x need unittest: with txn's (aborted)
                x need unittest: with txn's (committed)
                x need unittest: with txn's (erased key)
                x need unittest: with txn's (dupes, with/without DUPE flag)
                x need unittest: with txn's (overwritten keys)

x db.c: all functions which begin a local_txn should be reviewed;
    a local_txn should only be started if transactions are enabled!

    x db.c:_local_fun_get_key_count: is local_txn really needed?
    x db.c:_local_fun_check_integrity: is local_txn really needed?
    x db.c:_get_incremented_lsn: fix TODO

x ham_get_key_count does not return correct results if there are duplicate
   keys (or overwritten keys) in a txn AND in the btree. In these cases, bite
   the sour apple and check if the keys also exist in the btree. Incorrect
   results have to be avoided!
    x when overwriting keys - 1 key in btree, the other in txn
        x add unittest
        x fix them
    x with duplicate keys - 1 key in btree, the other in txn
        x add unittest w/ duplicate counting
        x add unittest w/o duplicate counting
        x fix them

x make sure all unittests are running (with exception of logging)

x rewrite cache purging/page locking
    x do we still need to distinguish between env_fetch_page 
        and db_fetch_page? - not really, but it looks nicer
    x purge: move function to cache.h/.c, remove from db.c
    x whenever a function allocates/fetches: purge cache before backend
        function is called
    x unittest HamsterdbTest should run fine now
    x remove page locking - not required anymore
    x CacheTest::strictTest fails

x merge bugfixes of 1.1.8

o logging: currently, logging for txn_begin and txn_commit/abort 
    is not implemented
    -> we have to distinguish between txn logging (the WAL journal which
    records everything transactional) and the physical logging of the modified
    database pages (when flushing a txn). both can not be mixed; the latter
    we want to remove as soon as possible.
    -> how to continue? Use the journal from v2, and reduce the physical log
    for the single operations. we only have to store the last single operation,
    and we do not need undo information.
    
    x disable all broken tests in log.cpp
    x introduce a logical journal (based on same routines as before)
        with log-file switching
        x implement in journal.h/journal.c
        x unittest for switching back/forth and everything else
    x env: create journal
        x unittest
    x env: close journal
        x unittest
    x logical journal: add txn begin/commit/abort/insert/erase
        x remove the -prewrite logging, since we do not need undo information
            (be careful with allocated pages - they need special treatment
            when they're "redone")
        x write the functions in journal.c
        x need unittests for each operation
            x txn_begin
            x txn_commit
            x txn_abort
            x insert
            x erase
            x erase for cursors (different duplicate behavior!)
    o db.c/env.c: (logical) log begin/commit/abort/insert/erase
        x use the functions from journal.c
            x ham_txn_begin
            x ham_txn_commit
            x ham_txn_abort
            x ham_insert
            x ham_cursor_insert
            x ham_erase (delete ALL duplicates!)
            x ham_cursor_erase (duplicate handling!)
        o need unittests
            o ham_txn_begin
            o ham_txn_commit
            o ham_txn_abort
            o ham_insert
            o ham_cursor_insert
            o ham_erase (delete ALL duplicates!)
            o ham_cursor_erase (duplicate handling!)

    x new flag for ham_erase: HAM_ERASE_ALL_DUPLICATES
        x replace old BLOB_FREE_ALL_DUPES
        x unittest!

    x refactor log.h, rename ham_log_t to log_t (and others as well)
        x open/create functions similar to journal.h
        x log_flush needed externally? fileops are flushed automatically
        x disable log-file switching for physical log
        x remove all unrequired functions - txn_abort, commit, checkpoint etc
        x do not need undo information and undo functions
            x remove log_add_page_before
            x remove log_append_flush_page
            x rename log_add_page_after to log_append_page
        x ham_log_get_entry() currently reads from back to front, but we 
            need it vice versa! - no, it's fine
    x decrease default journal threshhold (16?)
    x remove page_set_before_img_lsn()?

    x os_close: assert that fd>=3 (on linux)

    x we have to flush pages after they're modified (search for db_fetch_page
        and db_alloc_page); however, what if multiple pages are modified (i.e.
        during an SMO)? - we have to first physlog all modified pages, and then
        flush them all together; this way we minimize chances for corruption.
        same regarding SMOs - first wait till all modifications are done (in
        the cache), then flush the pages (or discard them if the operation
        failed for whatever reason)
        x re-introduce a structure similar to the old transaction list
            ("changeset"); don't forget to update my_verify_page()!
            x need unittests
        x add a changeset to the environment
        x when fetching a page, first check this list
        x when fetching or allocating, insert page in this list
        x when purging cache - do not delete this page (but i think this 
            anyway cannot happen since we never purge while an operation is
            in progress - true)
        x make sure that the changeset is empty when closing the Env
        x before each create/update/erase op:
                1. assert that the list is empty
                2. assert that the log is empty
                3. proceed with the operation
                4. on success: flush the list -> txn_commit
                5. always clear the list -> txn_commit, txn_abort
                6. clear the logfile -> txn_commit, txn_abort (?)
            x insert
            x erase
            x cursor_insert
            x cursor_erase
            x cursor_overwrite
            x env_create_db 
            x changeset_flush: what happens if writing data to the log fails?
                in that case the log is incomplete, and recovering from it
                would break everything -> on failure, clear the log
            x env_create -- same as above
            x every other function which modifies the header page MUST
                flush it afterwards!
            x if logging is enabled: also set HAM_WRITE_THROUGH
        x do we need a changeset if recovery/logging is disabled? - no, not
            required; add assert in changeset_add_page that it's not used
            if logging is disabled
        x what about the freelist - is it also part of the changeset? - yes,
            definitely! - but currently i do not see it in the debugger

        x do not use changeset if logging is disabled!!

        x disable logfile switching in log.c
            x update unittests

        x do we still need PAGE_DONT_LOG_CONTENT? - no, remove it

    x who manages the lsn? currently, the journal and env.h manage both their
        own lsn; and it's not propagated down to the physlog
    x if recovery is enabled: store the lsn in the header of the journal and
        also of the log file
        x journal header stores the lsn
            x need unittests
        x when the journal is cleared: write the highest lsn to file 0
            (write lsn 0 to file 1)
            x need unittests
        x when opening the journal: read the lsn from the header (or from the
            newest entry)
            x need unittests

        x the log has its own lsn 
            x need unittests
        x when the log is cleared: write the lsn to the header
            x need unittests
        x when opening the log: read the lsn from the header
            x need unittests

    x journal and log: flush file after it's written (at least in log AND
        in journal after abort/commit)

    o implement the recovery
        o if the log is not empty: re-apply it (it is idempotent), then
            clear it (but get the lsn from its header)
            o need unittests
        o then re-apply the journal, continuing from the entry with this lsn
            o make sure that the txn Id is persisted in the log and
                then re-assigned to the new transaction
            o make sure that he new operations are not written to the journal
            o need unittests
        o then clear the journal
            o need unittests

    o recovery: auto-aborts all non-committed transactions (same behavior 
            as now)
        o need unittests
    o recovery: re-apply all committed (but not fully flushed) transactions
        o need unittests

    o when creating a db (env_create_db) all pages are written to the log
        with lsn 0; is this correct? yes, but make sure that recovery works
        in all possible scenarios; or should we assign a lsn != 0?

    o the journal and the log are now in use - create more unittests 
        (HighLevelJournalTests) which verify that both are used correctly
        o add high level logfile unittests
            o with freelist
            o with header page modifications
            o with small blobs
            o with large blobs
            o with allocations
        o add high level journal unittests
    o re-enable logging tests in log.cpp or remove them

o implement partial reads through transaction tree - will have to 
    consolidate them
    o check if partial r/w works if the record size is <= 8

o implement approx. matching through transaction tree - will have to 
    consolidate rb-tree and btree to look for the "closest" key

o implement direct access - how, if the transaction tree is flushed??
    (but in-memory access w/ transactions is anyway not yet supported -
    write unittest to assert that it doesn't work)
    later: return error if DIRECT_ACCESS && IN_MEMORY && ENABLE_TXN

o support cursors!!!
    o separate cursor logic into btree and txn; in db.c, consolidate the
        two cursors
    o move first: use the cursor which is smaller
    o move right: use the cursor which is larger
    o move prev: use the cursor which is closer to the current one
    o move next: use the cursor which is closer to the current one
    o when flushing a transaction, and a cursor is pointing into the txn
        node: uncouple the cursor! (or delete it?)
    o db.c: do we need local_txn in the cursor functions?

o run monster tests

XXXXXXXXXXXXXXXXXXXXX release first version, merge with master XXXXXXXXXXXXXXX

o if recovery is enabled: before flushing the changeset, patch the lsn in
    the page header (it fits in 8 free bytes). in the previous release we 
    stored the lsn in the log file header. this can be removed; use he 
    lsn in the page header for recovery.

o each operation writes a journal entry (however, we still keep the logical
        journal in parallel, otherwise the unittests will fail completely)
        o write entry for db_find
        o write entry for db_insert
        o write entry for db_erase
    o api function to get a list of pending transactions
    o recovery: recreate all pending transactions (if requested)
    o unittests

o ham_txn_begin receives Environment handle, not Database handle
    o need a new parameter (reserved) for parent txn
    o need a new parameter for txn name (string)
    o update unittests/add new tests
    o update C++ API
    o rewrite auto-abort/auto-commit -> move to env
    o what happens if a database is closed, but it's modified by a txn
        that is still active? -> error (verify this!)

o new API to retrieve the currently active transactions
    o already exists in v2
    o needs unittests

. extkeys: don't use txn_id for the 'age', use lsn instead

. opnode: use key instead of key* (pointer) - this saves one allocation 
    per node

. rename ham_bt_cursor_t to btree_cursor_t

. cache-garbagelist no longer used - remove it?

. log_entry_t: txn_id still needed?

. log_t: allocator _alloc still needed? we have the Env pointer

. should the changeset become part of the log? it would make sense

. do some profiling - i am afraid that changeset_get_page() is not efficient
    enough; maybe a hash table is better?

o continue as described in integrate-ham2.txt...

