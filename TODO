


x 220.tst: schlägt fehl im release-build!

    Lese Spezifikationen von /usr/lib/gcc/x86_64-pc-linux-gnu/3.4.5/specs
    Konfiguriert mit: /var/tmp/portage/gcc-3.4.5/work/gcc-3.4.5/configure
    --prefix=/usr --bindir=/usr/x86_64-pc-linux-gnu/gcc-bin/3.4.5
    --includedir=/usr/lib/gcc/x86_64-pc-linux-gnu/3.4.5/include
    --datadir=/usr/share/gcc-data/x86_64-pc-linux-gnu/3.4.5
    --mandir=/usr/share/gcc-data/x86_64-pc-linux-gnu/3.4.5/man
    --infodir=/usr/share/gcc-data/x86_64-pc-linux-gnu/3.4.5/info
    --with-gxx-include-dir=/usr/lib/gcc/x86_64-pc-linux-gnu/3.4.5/include/g++-v3
    --host=x86_64-pc-linux-gnu --build=x86_64-pc-linux-gnu --disable-altivec
    --enable-nls --without-included-gettext --with-system-zlib --disable-checking
    --disable-werror --disable-libunwind-exceptions --enable-multilib
    --disable-libgcj --enable-languages=c,c++,f77 --enable-shared
    --enable-threads=posix --enable-__cxa_atexit --enable-clocale=gnu
    Thread-Modell: posix
    gcc-Version 3.4.5 (Gentoo 3.4.5, ssp-3.4.5-1.0, pie-8.7.9)
    
-----------------------------------------------------
-----------------------------------------------------

x cache: bucketgrösse in ham_config.h verschieben, eine #define-konstante
    draus machen

x default prefix comparison funktion hinzufügen (schon vorhanden?)

x prefix comparison testen

o endianness testen

o port to ms windows
    x win32: sourcen portieren - mmap fehlt noch!
    o mit mingw, bcc, watcom, msvc, icc...
    o projekt-umgebungen für visual studio 6 und .NET
    o define HAM_EXPORT DECLSPEC _dllexport for DLLs und .so
    o kein makefile, aber einfache batch-files zum compilieren
    o monster.sh!

o automake: mit -Wall compilieren!
    dnl Only use -Wall if we have gcc
    if test "x$GCC" = "xyes"; then
        if test -z "`echo "$CFLAGS" | grep "\-Wall" 2> /dev/null`" ; then
            CFLAGS="$CFLAGS -Wall"
        fi
    fi

o vorsicht - in /usr/local/include liegt eine Makefile.am aus der hamsterdb-
    installation. nur ein versehen, oder wird sie bei jedem 'make install'
    reinkopiert? ausprobieren.

-----------------------------------------------------
-----------------------------------------------------

o logo!!

-----------------------------------------------------

x siehe aufzeichnung: es kann nur eine transaktion geben - also eine 
    globale txn (db_set_txn, db_get_txn), und dann brauchen wir 
    den txn-pointer nirgendwo mehr als parameter übergeben, sondern
    nur noch die db

x cursors 
    x inmemory testen
    x performance bei insert und erase?
    x mit valgrind testen 
      x cursors, overwrite, inmemory
      x cursors, overwrite, reopen
      x cursors, inmemory
      x cursors, reopen
      x cursors, overwrite, extkeys, reopen
      x cursors, overwrite, extkeys, inmemory
      x cursors, extkeys, inmemory
      x cursors, extkeys, reopen

x ham_flush sollte einen (ungenutzen) flags-parameter bekommen

x samples umbenennen: aus simple wird db1.c 

o default-cachesize auf 256kb ausbauen? das ist auch die default-grösse bei 
    berkeleydb (dann auch die cache-hashtable vergrössern)

o in-memory-db: finden wir ne möglichkeit, normale datenbanken in 
    in-memory zu importieren und umgekehrt wieder zu exportieren? 
    das wäre genial. müsste aber nicht in die API, sondern einfach 
    ein sample: "append db1 to db2" (db2.c)
    --> geht mit cursors 
        cursor from=db1.begin()
        while (from)
            db2.append(from)
            from.next()

o siehe aufzeichnungen - noch ein paar änderungen im db-format für
    environments und duplicate keys...

o nächsten release machen!
    o release-regeln ändern: vor einem release auch die tests 2/3/4 
        machen! (auch wenn's lang dauert...)??????
        ne, das dauert ja ne woche!! zumindest die tests in 2 ausdünnen...
    o monster.sh erweitern für --test-cursors=1
    o monster.sh ausführen...

-----------------------------------------------------
-----------------------------------------------------

o portieren auf windows

o testscript in perl umschreiben, damit's auch auf windows läuft. 
    oder so lassen? sollte in cygwin eigentlich funktionieren

o tools
    o ham_dump
        erzeugt einen cursor auf den ersten eintrag, dumpt den 
        key und die daten (zumindest einen teil davon)
        --key-format=char|short|long|longlong|string|binary
        --key-length=<n>
        --data-format=char|short|long|longlong|string|binary
        --data-length=<n>
    o ham_info
        gibt alle infos aus dem header aus, sowie die anzahl der elemente,
        average key size, average data size, min/max etc
    o ham_recover
        holt die header-page, dann die root-page, und geht runter zum 
        ersten leaf. läuft dann alle index-pages ab, schreibt die keys 
        und die daten raus 

-----------------------------------------------------
-----------------------------------------------------

Version 0.1.0 - first release!!

o komplettes review
    werden fehlerwerte korrekt propagiert?
    machen fehlerwerte immer sinn? z.b. in flush_all()
    was passiert mit fehlern beim flushen?
    was passiert mit fehlern in ham_close()?
    o ein paar sachen müssten umbenannt werden:
        o alle statischen funktionen bekommen statt "my_" ein 
            prefix, das ihrem modul entspricht (z.b. "bt_" für btree etc)
        o keys.h/keys.c aufteilen in generische keys (zusammenlegen mit extkeys)
            und btree-spezifischen keys
        o db hat 2 funktionen, die die extended keys löschen - das gehört
            ins backend
    o nochmal schaun ob die ganzen flags so sinn machen
    o TODOs durchgehen

-----------------------------------------------------
-----------------------------------------------------

o doku
    o tutorial/sample in die online-hilfe einbeziehen
    o FAQ mit häufig gestellten fragen, tips zu optimierungen
    o Dokumentation in den header-dateien überarbeiten
    o webseite
    o mailing list
    o überarbeiten
    o interne doku schreiben
        o db-handle, pageverwaltung
        o backend-aufbau
        o freelist
        o cache
        o cursors

-----------------------------------------------------

x bbaum fehlerfrei
x TXN raus (wir können die txn's auch komplett
    für diesen release abschalten... man soll dafür ja ne spezielle version
    kaufen müssen)
x caching
x memory-mapped access
x in memory-datenbanken
x overwrite keys
x extended keys
x mal nachschauen was man nach den GPL-Codingrules noch für 
    dateien braucht -> nix mehr
x performance vergleichbar mit berkeley-db
x erzeugt .dll/.so
x umsteigen auf autoconf/automake
o compiliert unter linux, windows, darwin, 32bit und 64bit, läuft auf 
    little- und bigendian
o cursors
o logo
o legal issues
o dokumentation: tutorial, interface, FAQ (auch zu unittests)
o webseite
    news
    releases
    download
    faq
    documentation
    tutorial
    mailingliste
x stress-test-tool(s), das ALLE optionen durchprobiert
    mmap
    r/w
    in-memory
    verschiedene pagesizes
    grosse keys
    grosse blobs
o admin-tool(s) fuer dump, stats, repair
    o db_dump: 
        o key/daten dumpen
        o header dumpen
o KEINE valgrind-fehler!

-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------

o duplicate keys (nicht in version 0.1.0, sondern 0.1.1)
    jeder key bekommt einen dupcounter; der wird mit unsigned(-1) initialisiert
    beim einfuegen wird rekursiv abgestiegen. im leaf wird dann ein neuer key
    eingefuegt, mit dem dupcounter=existierender ("kleinster") key minus 1.

-----------------------------------------------------

o mehrere datenbanken in einer datei
    (siehe eintrag im notizbuch)

    -> database-environment (ein file fuer mehrere datenbanken, 
        gesharter cache, geshartes file-handle, freelist etc)

-----------------------------------------------------
-----------------------------------------------------

o c++-api: 

namespace ham {
  class key {
  public:
    key(void *data=0, int length=0, int flags=0);
    void *get_data();
    int get_length();
    int get_flags();
  };

  class record {
    record(void *data=0, int length=0, int flags=0);
    void *get_data();
    int get_length();
    int get_flags();
  };

  class cursor {
  public:
    cursor(db *db);
    cursor &clone();

    // this is a bi-directional iterator!
    operator++(); 
    operator--(); 
    operator bool();  // isnull?

    ham_status_t first(int flags=0);
    ham_status_t last(int flags=0);
    ham_status_t next(int flags=0);
    ham_status_t previous(int flags=0);
    
  private:
    cursor(cursor &other); // forbid copy constructor
  };

  class db {
  public:
    db();
    ~db();

    ham_status_t create(const char *filename, int flags=0);
    ham_status_t open(const char *filename, int flags=0);
    ham_status_t close(); // implizit im destruktor

    ham_status_t insert(key *key, record *record, int flags=0);
    // erase, find...
    
    // operators
    const record &operator[](const key &key);
    record operator[](const key &key);

  private:
    db(db &other); // forbid copy constructor
  };
};

-----------------------------------------------------
-----------------------------------------------------

o statistics
    will wissen wie viele freelist-hits/misses und cache-hits/misses es gab,
    auch im extkey-cache

o statistics
    get generic getter/setter for statistical value, i.e. 
        enum { CACHEHITS, CACHEMISSES, PAGES, FREEPAGES, ... };
        ham_u64_t statistics[8];
    set_stats_value(db, which, value): db->statistics[which]=ham_h2db32(value)
    ATTENTION: some of those values are specific for each backend, others
        are global; therefore we need two functions: 
        ham_get_global_statistics(stat)
        ham_get_index_statistics(index, stat)

-----------------------------------------------------
-----------------------------------------------------

o super-COMPRESSED-mode: keine headerpage, und pagesize auf 128 byte ->
    super-mini-datenbanken (für embedded) - möglich ohne Aufwand? wird tricky, 
    weil die page-alloc-funktionen davon ausgehen dass eine adresse 0 ein
    fehler ist

-----------------------------------------------------

o datenbank mit O_EXCL öffnen, bzw mit flock() (und nem wait, falls die 
    Datenbank gelockt ist) -> Möglichkeit für pseudo-concurrent access bei
    kurzen, schnellen Zugriffen (z.b. webseite)

-----------------------------------------------------
o backend
    o darauf hinarbeiten dass später mal mehrere backends in einer datei
        sind, nicht nur eines

o blob
    o neu: header in jeder page mit blobid
    o header auch im verify prüfen

o debug
    o im debug-modus output wie gehabt; bei non-debug: statt file- und line
        nur "hamsterdb: " ausgeben

o filter
    generische filter, sowie 2 implementationen davon: ein encryption-codec 
    und ein zlib-codec
    arbeiten sie page- oder blob-basiert? evtl waere page-basiert besser, 
    denn dann koennten auch index-pages (bzw NUR index-pages) gefiltert 
    werden.
    (my_result_t) (*filter)(my_key_t *key, my_data_t *data, int direction);

o hash-tabelle
    @@@

o bindings 
    c++-wrapper (ähnlich stl? müsste möglich sein, aber
    schwer), python-db-modul, perl, java (alle swig?)

o asset-tool
    GUI und library für computerspiele

-----------------------------------------------------
-----------------------------------------------------

Version 0.2.0

o duplicate keys
o bindings: C++, Python, Perl, PHP (mit online-demo!)
o filter: encryption
o filter: compression

-----------------------------------------------------

Version 0.3.0

o database-environment (ein file fuer mehrere datenbanken, gesharter cache,
    geshartes file-handle, freelist etc)
    etc)
o hash-tabelle
o live reorganisation???

-------------------------- literature -----------------------
pB+ Trees prefetching B+ Trees 
[CGM01] Improving Index Performance through Prefetching. S. Chen, P.B. 
Gibbons, and T.C. Mowry. ACM International Conference on Management
of Data (SIGMOD), Santa Barbara, California, May 2001
[GL01] B-Tree Indexes and CPU Caches. G Graefe and P. Larson. International
Conference on Data Engineering (ICDE), Heidelberg, Germany, April 2001.
[RR00] Making B+ Trees Cache Conscious in Main Memory. J. Rao 
and K.A. Ross. ACM International Conference on Management of Data (SIGMOD),
Dallas, Texas, May 2000.

