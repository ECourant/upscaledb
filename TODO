I Am Legend:

Items are sorted by priority (highest on top).
o a pending  TODO item (for the current release)
. a pending  TODO item (for future releases)
x a finished TODO item

-----------------------------------------------------------------------------
This Branch Is About Integrating The hamsterdb2 Functionality!!!!!
-----------------------------------------------------------------------------
The big headline is:
As a user i want to run many Transactions in parallel with high performance.
I'm using multiple threads b/c my CPU has multiple cores, and expect hamsterdb
to scale with the number of cores.
==============================================================================

x protobuf is required even if remote code is disabled:
    see richardheath's mail on hamsterdb-user
    -> also seems to be the case in windows

x should database names still be reserved? - yes, i think so. even if they're
    not required right now, they will be required in the future.

x merge Johnathan Conley's patches (3 mails)

x refactoring: get rid of ham_bool_t, replace with bool whenever possible

x version.h: support file version (see topic/freelist)

x all packed structures that are directly mapped to the file
    (BlobPageHeader, BlobHeader and others) should be named
    "PXXX" (for "Persistent" or "Packed")

o benchmark/prototype new freelist based on discarded one
    x a flat array (std::vector), not sorted
    x reserve 20 entries
    x free_area: append at end, if full then overwrite smallest
    x free_page: traverse all entries, remove if necessary
    x alloc: traverse lineary, pick best fit
    x check_integrity: not sure yet how, but need to implement it
    o run benchmarks

o new option to disable the freelist
    x clean up statistics.h
    x clean up PFreelistPageStatistics
    x clean up runtime_statistics_pagedata_t
    x clean up PFreelistSlotsizeStats
    x clean up freelist_stats_fail, _update, _edit etc
    x clean up freelist_hints_t
        x remove fields that are not required
        x create class FreelistStatistics::Hints, file freelist_stats.h/cc
    x same for freelist_global_hints_t
    o freelist_stats.h has global functions; move into FreelistStatistics
        namespace
    o run performance tests, just to make sure that we did not break anything
    o EnvironmentStatistics::m_perf_data: move to Freelist

    x re-introduce page_manager (has ownership of Freelist, Cache, Pages etc)
    o clean up PageManager::alloc_blob

    o review unittest Freelist::overflow4
    o "old" hamsterdb.cc has different method to deal with freelist in header
        page
    x split BlobManager into subclasses (in-memory, disk)
        x use ByteArray for "zeroes" when filling partial gaps

    o review unittest Freelist::overflow4
    o "old" hamsterdb.cc has different method to deal with freelist in header
        page - unify (or leave as is? no need to change it)
    o merge freelist and freelist_statistics, if it makes sense

    o new option HAM_PARAM_DISABLE_FREELIST
        o alte Feelist umbenennen in BitmapFreelist
        o erzeugt neue Freelist SimpleFreelist *nur für diese Datenbank*
        o neue freelist speichert nur die 20 größten freien slots, keine
            persistenz (auch mit mehr slots testen - bis zu 500)
        o slots sind nach größe sortiert
        o blobs müssen nicht DB_CHUNKSIZE-aligned sein
        o Freelist::mark_free(...overwrite) never used, same about set_bits()
        o alignment ist property d. freelist
            BitmapFreelist::get_aligned() -> DB_CHUNKSIZE;
            SimpleFreelist::get_aligned() -> 1;
        o page_manager dispatcht an bitmap-freelist oder neue implementierung
        o globale (bitmap) freelist nur erzeugen wenn sie wirklich
            gebraucht wird!
        o komplett freie pages werden an die bitmap weitergegeben, but only
            if the bitmap freelist exists (really??)
        o increase file version if this new freelist is used
        o do not log Freelist pages in the changeset
        o run benchmarks with different number of slots (up to 1024)
    o also for Java
    o also for .NET

    o "old" freelist branch has optimization in btree_cursor.cc and
        duplicates.cc for fetching duplicates
    o "old" freelist branch does not use Transaction in blob_manager.cc

o reduce file size if freelist adds page at end of file:
    o not possible if freelist is disabled
    o just test the freelist bitmap if the last N bits are free
    o if yes: truncate the file, but also truncate the freelist!

o Partial read: record->size returns the partial size that was retrieved.
    I think record->size should return the original size, and
    record->partial_size should return the size that was read.
    -- really?? yes, this is much cleaner

o cache improvements
    o when flushing, sort pages by ID/offset and use writev to flush them
    o give priority to index pages
    o introduce new cache policy "USE_AS_MUCH_AS_YOU_WANT": keeps all index
        pages in memory and cache some of the blob pages
    o should this become the new default?
    o add to monster tests

o win32: get rid of boost_thread

. boost: configure script should make sure that only boost v 1.46 (or newer)
    is accepted
    -> also test with older versions, but 1.33 definitely does not work
    issue #17: https://github.com/cruppstahl/hamsterdb/issues/17




o improve client/server performance
    currently client/server is 10 times slower than standalone; can we improve
    this, i.e. by using keepalive/open connections?
    o use libevent2 on server side, get rid of mongoose
    o use boost sockets on client side, get rid of libcurl

o reduce the file size if freelist adds page at end of file
    (maybe cache the filesize in the device, to avoid frequent calls
    to os_get_filesize(); but compare both if HAM_DEBUG == 1)
    o only do this in in Freelist::write_to_disk
    o ... which should be called during ham_env_flush
    o ... and also when the Environment is closed
    o attention: if a file is truncated then recovery can re-create pages
        that are "outside" of the file boundaries!

o AES encryption

. pre-allocate index
    o see roadmap document for more information

. can we perform better with O_DIRECT? run some benchmarks

------------------- release 2.1.1 -----------------------------------------











o collect file format incompatibilities
    o for the new Btree code
    o get rid of the statistics-structures
    o reduce the PBlobHeader (remove flags, alloc_size)
    o what else?

o DiskBlobManager::write_internal: only uses direct I/O if blob is at the
    beginning of the page. Fix this and also use direct I/O when writing blobs
    in the middle. In this case we have to read/modify/write the
    PBlobPageHeader structure, though

. also remove locking from C# and Java APIs

o refactor unittests, use boost unittest framework
    http://www.boost.org/doc/libs/1_35_0/libs/test/doc/components/utf/index.html
    http://www.beroux.com/english/articles/boost_unit_testing/
    http://www.alittlemadness.com/2009/03/31/c-unit-testing-with-boosttest/

o BtreeCursor: use memory arena for uncoupling the key

o split Transaction into local and remote class
    o keep in mind that sooner or later the BtreeNode will expect template arguments;
        can we do something similar with the TransactionNode?
    o hamsterdb.cc directly calls into Transaction class instead of Environment
    o try to cleanup the flow; move more code from db.cc to txn.cc,
        reorg TransactionIndex similar to BtreeIndex
    o try to get the methods/design analoguous to the Btree
    o TransactionIndex:
        o TransactionIndex: use std::set<OperationNode> instead of rb.h?? Not
            sure if this is worth the troubles
        x check how/if std::multimap can replace rb.h - yes, seems to work
        o replaces the TransactionTree
        o one TransactionIndex per Database (always created)
        o txn_opnode_t -> TransactionOperation
        o try to move code from db.cc into TransactionIndex, i.e. to check
            conflicts etc
    o try to replace some of the linked lists with boost::intrusive_list
    o document the tree structure in the header file

o split Cursor into local and remote class
    o hamsterdb: directly call into Cursor class (instead of Database)

o is the recovery working if there's a crash during ham_db_close or ham_env_close?

o allow transactions w/o journal

o allow transactions w/o recovery

o move the whole configuration (key sizes, parameters, page size, etc) into a
    separate class which is instantiated by the env

o when recovering, give users the choice if active transactions should be
    aborted (default behavior) or re-created
    o needs a function to enumerate them

o fully (!) automize the whole release process for unix; the result (on
    success) are the following files:
    o tar-ball
    o the README
    o the documentation
    o the Changelog
    o the release notes (a template)
    o move monster test to ec2?
    o the output of the monster tests and the performance test
    o windows-packages

o when flushing a changeset: sort by offset, use writev()

o update documentation
    x in header file
    o in the wiki
        o don't forget to list all functions that are currently disabled
            w/ txn's -> sorting dupes, approx. matching, ...
        o transactional behavior/conflicts of duplicate keys
    o in the wiki: start with internal documentation
        o transactions
        o architecture
        o btree
        o journal/log
        o cache
        o I/O
        o unittests
        o cursor(s)
        o monstertests - how to use them?





------------------- web page ----------------------------------------------

o look for a nice wordpress template
o integrate the blog (hamsterdb.com/blog)
o crupp.de just forwards to hamsterdb.com/blog
o have regular backups to remote storage

------------------- idea soup ---------------------------------------------

o changeset: instead of simply adding pages to the changeset, the caller
    could already specify whether this page needs logging or not;
    i.e. after freelist rewrite, the blob pages do not need logging if a
    blob is deleted  

o is there a way to group all changeset flushes of a Transaction into one
    changeset, and batch-commit multiple commits? that way we would avoid the
    frequent syncs and performance would be improved
    o would have to remove all of assert(changeset.is_empty())
    o but we can use that assert prior to txn_begin

o BtreeFindAction: always use a cursor, and when doing approx matching
    then simply move left or right with that cursor

. track additional metrics
    o cache misses
    o cache hits
    o ...

o flush in background (asynchronously)
    o need new flag file HAM_DISABLE_ASYNCHRONOUS_FLUSH
    o if in-memory database: disable async flush
    o if transactions are disabled: disable async flush
    o if enabled: create background thread, wait for signal
    o ham_env_flush: if txn are enabled then try to flush them to disk
    o how to deal with an error in the background thread???
        o store in Environment, then return in every exported function
    o default: async flush is OFF!

    o extend monster tests
        o with async flush
        o without async flush
        o extend/run performance test
        o run monster tests

    o documentation
        o tutorial
        o faq

o need a function to get the txn of a conflict (same as in v2)
    ham_status_t ham_txn_get_conflicting_txn(ham_txn_t *txn, ham_txn_t **other);
        oder: txn-id zurückgeben? sonst gibt's ne race condition wenn ein anderer
        thread "other" committed/aborted
    o also add to c++ API
    o add documentation (header file)
    o add documentation (wiki)

. new test case for cursors
    insert (1, a)
    insert (1, b) (duplicate of 1)
    move (last) (-> 1, b)
    insert (1, c)
    move (last) (-> 1, c)? is the dupecache updated correctly?

. there are a couple of areas where a btree cursor is uncoupled, just to
    retrieve the key and to couple the txn-key. that's not efficient
        db.c:__btree_cursor_points_to
        db.c:__compare_cursors
        txn_cursor.c:cursor_sync
        txn_cursor.c:cursor_overwrite
    o move to a separate function
    o try to optimize

. add tests to verify that the cursor is not modified if an operation fails!
    (in cursor.cpp:LongTxnCursorTest are some wrapper functions to move or
    insert the cursor; that's a good starting point)

. new flag for transactions: HAM_TXN_WILL_COMMIT
    if this flag is set, then write all records directly to the file, not
    to the log. the log will only contain the rid.
    o in case of an abort: move the record to the freelist
    -> this affects all temporary ham_insert-transactions
    (not sure if this should get high priority)

. if memory consumption in the txn-tree is too high: flush records to disk
    (not sure if this should get high priority)

o ham_get_count: could be atomically updated with every journal entry

