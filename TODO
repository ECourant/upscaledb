


x 220.tst: schlägt fehl im release-build!

    Lese Spezifikationen von /usr/lib/gcc/x86_64-pc-linux-gnu/3.4.5/specs
    Konfiguriert mit: /var/tmp/portage/gcc-3.4.5/work/gcc-3.4.5/configure
    --prefix=/usr --bindir=/usr/x86_64-pc-linux-gnu/gcc-bin/3.4.5
    --includedir=/usr/lib/gcc/x86_64-pc-linux-gnu/3.4.5/include
    --datadir=/usr/share/gcc-data/x86_64-pc-linux-gnu/3.4.5
    --mandir=/usr/share/gcc-data/x86_64-pc-linux-gnu/3.4.5/man
    --infodir=/usr/share/gcc-data/x86_64-pc-linux-gnu/3.4.5/info
    --with-gxx-include-dir=/usr/lib/gcc/x86_64-pc-linux-gnu/3.4.5/include/g++-v3
    --host=x86_64-pc-linux-gnu --build=x86_64-pc-linux-gnu --disable-altivec
    --enable-nls --without-included-gettext --with-system-zlib --disable-checking
    --disable-werror --disable-libunwind-exceptions --enable-multilib
    --disable-libgcj --enable-languages=c,c++,f77 --enable-shared
    --enable-threads=posix --enable-__cxa_atexit --enable-clocale=gnu
    Thread-Modell: posix
    gcc-Version 3.4.5 (Gentoo 3.4.5, ssp-3.4.5-1.0, pie-8.7.9)
    
-----------------------------------------------------
-----------------------------------------------------

x auf autoconf/automake umstellen
    x in blog-artikel dokumentieren
    x --enable-debug
    x --enable-profile
    x hamsterdb versions-string aus src/version.h extrahieren
        (wie in expat)
    x config.h im source benutzen: HAVE_MMAP, HAVE_MUNMAP, HAVE_PREAD,
            HAVE_PWRITE
    x welche dateien müssen wir ausliefern, welche nicht? -> make distclean
            räumt automatisch auf
    x disable optimization in gcc < 4.1.1

    x test auch noch umbauen
        x nur noch die db.c, die anderen optionen (-c etc) können raus
        x umbauen für configure
        x verschieben in das test-verzeichnis? - bin eher dagegen...
                lizenztechnisch ist das testprogramm unter der GPL, 
                und die ist kompatibel mit bdb. deshalb sollte es so passen.
        x ein beispiel-sample im test-verzeichnis einchecken
        x eine readme.txt
        x valgrind-checks gehen momentan nicht, weil ./test ein shell-skript 
                ist und nicht die binary
        x testen

    x dokumentation machen

    x installation testen
        x vorsicht: sample soll nicht installiert werden!
        x vorsicht: test soll nicht installiert werden!
        x erzeugte bibliothek heisst libhamsterdb.so.0.0.0

o auf windows portieren
    o kein makefile, aber einfache batch-files zum compilieren
    o sourcen portieren - mmap fehlt noch!
    o monster.sh!

-----------------------------------------------------

o nächsten release machen!

o VORSICHT! am besten ein skript schreiben - make-release.sh
    1. version.h hochzählen (auch in src/Makefile.am!)
    2. README überarbeiten, versionsnummer und datum hochzählen
    3. CHANGELOG überarbeiten, release reinschreiben
    4. einchecken
    5. taggen bzw. copy in release-trunk in hamsterdb-v.v.v
    6. einchecken
    7. export vom release-verzeichnis
    8. tar/gzip
    9. upload
   10. die 8 windows-libs erzeugen, testen
   11. freshmeat-eintrag, blog-kommentar

o Regelwerk für releases schreiben, z.b.
    1. alle tests (auch 2-4) durchlaufen (monster.sh)
    2. ausgewählte tests mit valgrind (valgrind.sh)
    3. die releases für windows machen (8 stück)
    4. tests unter windows machen
    5. sicherstellen dass alles eingecheckt ist
    6. changelog updaten
    7. make-release.sh

-----------------------------------------------------

o cache: bucketgrösse in ham_config.h verschieben, eine #define-konstante
    draus machen

o prefix comparison hinzufügen (schon vorhanden?)

o prefix comparison testen

o stress test mit zufällig fehlschlagenden io-funktionen und zufälligen
    OUT_OF_MEMORYs

o endianness testen

o port to ms windows
    o mit mingw, bcc, watcom, msvc, icc...
    o projekt-umgebungen für visual studio 6 und .NET
    o define HAM_EXPORT DECLSPEC _dllexport for DLLs und .so

o nächsten release machen!

-----------------------------------------------------
-----------------------------------------------------

o iteratoren 
    o sind schon designt (siehe iterators.txt im rechner auf arbeit)

    o in-memory-db: finden wir ne möglichkeit, normale datenbanken in 
        in-memory zu importieren und umgekehrt wieder zu exportieren? 
        das wäre genial
        --> geht mit iteratoren (erst release 2.0!):
            iterator from=db1.begin()
            while (from)
                db2.append(from)
                from.next()
        --> geht auch mit der enum-funktion, die jetzt schon drin ist

o nächsten release machen!

-----------------------------------------------------
-----------------------------------------------------

o tools
    o ham_dump
    o ham_info
    o ham_recover

-----------------------------------------------------
-----------------------------------------------------

Version 0.1.0 - first release!!

o komplettes review
    werden fehlerwerte korrekt propagiert?
    machen fehlerwerte immer sinn? z.b. in flush_all()
    was passiert mit fehlern beim flushen?
    was passiert mit fehlern in ham_close()?
    o ein paar sachen müssten umbenannt werden:
        o alle statischen funktionen bekommen statt "my_" ein 
            prefix, das ihrem modul entspricht (z.b. "bt_" für btree etc)
        o keys.h/keys.c aufteilen in generische keys (zusammenlegen mit extkeys)
            und btree-spezifischen keys
        o db hat 2 funktionen, die die extended keys löschen - das gehört
            ins backend
    o nochmal schaun ob die ganzen flags so sinn machen

-----------------------------------------------------
-----------------------------------------------------

o doku
    o tutorial/sample in die online-hilfe einbeziehen
    o FAQ mit häufig gestellten fragen, tips zu optimierungen
    o Dokumentation in den header-dateien überarbeiten
    o webseite
    o mailing list
    o überarbeiten

-----------------------------------------------------

x bbaum fehlerfrei
x TXN raus (wir können die txn's auch komplett
    für diesen release abschalten... man soll dafür ja ne spezielle version
    kaufen müssen)
x caching
x memory-mapped access
x in memory-datenbanken
x overwrite keys
x extended keys
x mal nachschauen was man nach den GPL-Codingrules noch für 
    dateien braucht -> nix mehr
x performance vergleichbar mit berkeley-db
o erzeugt .dll/.so
o compiliert unter linux, windows, darwin, 32bit und 64bit, unter windows
    mit mingw, icc, msvc, borland, watcom; läuft auf little- und bigendian
o iteratoren
o legal issues
o dokumentation: tutorial, interface, FAQ (auch zu unittests)
o webseite
    news
    releases
    download
    faq
    documentation
    tutorial
    mailingliste
x stress-test-tool(s), das ALLE optionen durchprobiert
    mmap
    r/w
    in-memory
    verschiedene pagesizes
    grosse keys
    grosse blobs
o admin-tool(s) fuer dump, stats, repair
    o db_dump: 
        o key/daten dumpen
        o header dumpen
o KEINE valgrind-fehler!

-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------

o duplicate keys (nicht in version 0.1.0, sondern 0.1.1)
    jeder key bekommt einen dupcounter; der wird mit unsigned(-1) initialisiert
    beim einfuegen wird rekursiv abgestiegen. im leaf wird dann ein neuer key
    eingefuegt, mit dem dupcounter=existierender ("kleinster") key minus 1.

-----------------------------------------------------

o mehrere datenbanken in einer datei
    (siehe eintrag im notizbuch)

    -> database-environment (ein file fuer mehrere datenbanken, 
        gesharter cache, geshartes file-handle, freelist etc)

-----------------------------------------------------
-----------------------------------------------------

o statistics
    will wissen wie viele freelist-hits/misses und cache-hits/misses es gab,
    auch im extkey-cache

o statistics
    get generic getter/setter for statistical value, i.e. 
        enum { CACHEHITS, CACHEMISSES, PAGES, FREEPAGES, ... };
        ham_u64_t statistics[8];
    set_stats_value(db, which, value): db->statistics[which]=ham_h2db32(value)
    ATTENTION: some of those values are specific for each backend, others
        are global; therefore we need two functions: 
        ham_get_global_statistics(stat)
        ham_get_index_statistics(index, stat)

-----------------------------------------------------
-----------------------------------------------------

o super-COMPRESSED-mode: keine headerpage, und pagesize auf 128 byte ->
    super-mini-datenbanken (für embedded) - möglich ohne Aufwand? wird tricky, 
    weil die page-alloc-funktionen davon ausgehen dass eine adresse 0 ein
    fehler ist

-----------------------------------------------------

o datenbank mit O_EXCL öffnen, bzw mit flock() (und nem wait, falls die 
    Datenbank gelockt ist) -> Möglichkeit für pseudo-concurrent access bei
    kurzen, schnellen Zugriffen (z.b. webseite)

-----------------------------------------------------
o backend
    o darauf hinarbeiten dass später mal mehrere backends in einer datei
        sind, nicht nur eines

o blob
    o neu: header in jeder page mit blobid
    o header auch im verify prüfen

o debug
    o im debug-modus output wie gehabt; bei non-debug: statt file- und line
        nur "hamsterdb: " ausgeben

o filter
    generische filter, sowie 2 implementationen davon: ein encryption-codec 
    und ein zlib-codec
    arbeiten sie page- oder blob-basiert? evtl waere page-basiert besser, 
    denn dann koennten auch index-pages (bzw NUR index-pages) gefiltert 
    werden.
    (my_result_t) (*filter)(my_key_t *key, my_data_t *data, int direction);

o hash-tabelle
    @@@

o bindings 
    c++-wrapper (ähnlich stl? müsste möglich sein, aber
    schwer), python-db-modul, perl, java (alle swig?)

o asset-tool
    GUI und library für computerspiele

-----------------------------------------------------
-----------------------------------------------------

Version 0.2.0

o duplicate keys
o iteratoren
o bindings: C++, Python, Perl, PHP (mit online-demo!)
o filter: encryption
o filter: compression

-----------------------------------------------------

Version 0.3.0

o database-environment (ein file fuer mehrere datenbanken, gesharter cache,
    geshartes file-handle, freelist etc)
    etc)
o hash-tabelle
o live reorganisation???

-------------------------- literature -----------------------
pB+ Trees prefetching B+ Trees 
[CGM01] Improving Index Performance through Prefetching. S. Chen, P.B. 
Gibbons, and T.C. Mowry. ACM International Conference on Management
of Data (SIGMOD), Santa Barbara, California, May 2001
[GL01] B-Tree Indexes and CPU Caches. G Graefe and P. Larson. International
Conference on Data Engineering (ICDE), Heidelberg, Germany, April 2001.
[RR00] Making B+ Trees Cache Conscious in Main Memory. J. Rao 
and K.A. Ross. ACM International Conference on Management of Data (SIGMOD),
Dallas, Texas, May 2000.

