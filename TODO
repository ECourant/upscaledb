
x release 0.4.5

x support GPL3
    x change all source headers -> GPL 2.0 *or later*
    x rename COPYING to COPYING.GPL2
    x add GPL3 license file (COPYING.GPL3)

x create a new repository for hamsterdb-meta

x unittests - check for leaks!
    x replace big record with tiny
    x replace big record with null
    x replace tiny record with null
    x replace tiny record with big

x recno: keys lassen sich nicht überschreiben
    x für ham_insert fixen
        x unittest
    x für ham_cursor_insert fixen
        x unittest

x rename ham_cursor_replace to ham_cursor_overwrite (and all other instances
    of "replace" with "overwrite")
    x hamsterdb.h 
    x replace sources
    x fix unittests
    x tutorial

o support for duplicate keys
    x make sure that EXTENDED_BLOB flag is always set if blob>=8 byte 
        (check unittests!)
        -> not needed - TINY_BLOB or SMALL_BLOB are enough
    x test if everything runs fine if blobs are always allocated

    x ham_create needs flag HAM_ENABLE_DUPLICATES
        x persistent flag -> unittest

    x don't allow insert(HAM_DUPLICATE|HAM_OVERWRITE)
        x fix in code
        x documentation!
        x unittest

    x modify db_free_page; also delete the duplicates
    x modify my_free_cb

    x need a list of all cursors
        x add cursor_next, cursor_previous
        x add cursor *ham_db_t::_cursor_list
        x btree_cursor_create: prepend new cursor to the list
        x btree_cursor_destroy: delete cursor from the list
        x unittest: check if links are correct
            x also with cloned cursors!

    x when freeing in-memory pages/blobs: also free the duplicates (otherwise
        we have memory leaks)
        x unittest

===========================

    x remove the old crap
        x and the unittests!

    x new flag KEY_DUPLICATE (alternatively to TINY, NULL)
        x must not appear in internal keys

    x cursor: dupe_id is the offset in the dupe_table
        x type is ham_size_t
        x always starts with zero

    x create a blob_duplicate_t structure
        x the structures
        x getters
        x setters
        x unittest for the structure

    x a new function
        key_set_record(int_key_t *key, ham_record_t *record, 
            flags=0|OVERWRITE|DUPLICATE[_position]);
        -> remove duplicated code in btree_cursor.c and btree_insert.c

        x blob_duplicate_insert(dupe_table_id, position, flags, 
            [flags, rid]+);
            -> returns the new rid; only inserts at the end of the table

        x ham_find: returns the first item
            x unittest

        x ham_insert(OVERWRITE) overwrites the first dupe
            x unittest

    x enhance cursor_move for next/previous/first/last
        x unittest for first/next
        x unittest for last/previous

    o blob_duplicate_erase(dupe_table_id, position)
        (does not yet shrink the duplicate table)
        o ham_cursor_erase: only delete the item at the duplicate position
            o unittest
        o ham_erase: delete all duplicates
            o unittest

    o blob_duplicate_overwrite(dupe_table_id, position, [flags, rid]);

    o key_set_record does not always need to dirty the page (i.e. when
        appending duplicates) -> don't set page dirty in the caller

    o cursor_overwrite/cursor_insert: 
        currently, the cursor_dupe_cache is deleted, but we don't have to
        also, in cursor_move there are some optimizations regarding the
        cache (search for TODO)
        also, cursor is placed on inserted dupe - unittest

    o insert
        o new dupes are appended at the END of the list (add documentation!)
        o change the unittests

    o cursor_insert
        o duplicate_insert_after
        o duplicate_insert_before
        o duplicate_insert_first
        o duplicate_insert_last (default)
        o don't allow these flags in ham_insert -> unittest!

    o erase -> deletes ALL duplicates!
        -> must NIL all cursors which are coupled to this key!

    o cursor_erase
        -> must NIL all cursors which are coupled to this duplicate!

    o cursor_overwrite
        -> must replace all cursors which are coupled to this duplicate!

    o ham_get_duplicate_count (???)
        x blob_duplicate_get_count(dupe_table_id);
        o unittests



===========================

    o modify acceptance test for --duplicate=1 (berkdb and hamster)
        o --duplicate-position="before"|"after"|"first"(default)|"last"
        o new acceptance tests with many, many duplicates
        o fullcheck=reverse - uses back-to-front order for fullcheck
    o update documentation
    o update tutorial
    o new sample, read all words from stdin, insert them with line information;
        also, insert the same word in a second db, with a word-counter
        then dump all words with the line information, and how often they
        were used
    . modify sample env1, to create a 1:n relationship between orders
        and customers (or create a new sample)

    o endian-tests

o check ham_txn_abort in btree_cursor.c
    this call never appears in hamsterdb.c, but quite frequently in the
    cursor routines; is this a problem?

o be more careful when uncoupling cursors - especially when inserting 
    or deleting items, uncoupling is often not necessary
    o definitely no need to uncouple if overwriting or adding a duplicate

o more ideas for unittests
    o unittests: insert NULL/TINY/SMALL blobs, then create linked lists
    o unittests: insert NULL/TINY/SMALL as duplicates
    o unittests: insert NULL, then replace with TINY, then with SMALL, 
        then with big, then SMALL, TINY, NULL
    o unittests: 
        o create cursor -> must be NIL
        o insert item   -> must be NIL
        o move cursor to item
        o insert item2 < item -> cursor is uncoupled
        o move cursor to item
        o insert duplicate of item -> cursor is still coupled
        o insert item2 > item -> cursor is still coupled

o ham_close with flag HAM_AUTO_CLOSE_CURSORS
    o unittests

o ham_env_close with flag HAM_AUTO_CLOSE_DATABASES
    o unittests

o webpage
    o update web page about license change (GPL2 or GPL3)
    o rename "Features" to "About"
    o update roadmap
    . move to cakephp framework
    . frontpage: resize hamster picture; remove text -> more space below
        (for 3 colums: news, main features, articles/testimonials/link cloud)

o btree_insert:421 - why is the extkey deleted??

o protect users against uninitialized ham_key_t and ham_record_t structures
    o check if key->flags is 0 or USER_ALLOC
    o check if key->_rid is 0
    o check if record->flags is 0 or USER_ALLOC
    o check all other private flags
    o unittests!

o create a new repository for hamsterdb-alien for all dependencies 
    in source and precompiled (static/non-debug - cppunit and berkeleydb)
    x linux64-le
    x linux32-le
    o cygwin32
    o win32
    o win64
    o wince-x86
    o ppc32-be

o currently, there's no "cheap" way to get the number of duplicates of a key
    o is this needed? use cases?
    o could always add the number to the very first blob; if the first
        blob is deleted, the number moves to the next first blob

o record numbers should not be reused
    currently, if the last record is deleted, and then the database is
    reopened, this record number is reused
    persistently cache the number of elements in the database - we need 
    this information anyway.
    o insert: set record->_rid to 0, to make things easier
    o add a new function ham_get_count()

o record numbers don't check endianess in ham_find/ham_cursor_find:
    the key parameter coming from the user must be endian-translated!
    
o optimization idea: could use lookaside-list for the last 5/10 
    duplicate tables

