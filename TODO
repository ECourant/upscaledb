I Am Legend:

Items are sorted by priority (highest on top).
o a pending  TODO item (for the current release)
. a pending  TODO item (for future releases)
x a finished TODO item

-----------------------------------------------------------------------------
This Branch Is About Integrating The hamsterdb2 Functionality!!!!!
-----------------------------------------------------------------------------
The big headline is:
As a user i want to run many Transactions in parallel with high performance.
I'm using multiple threads b/c my CPU has multiple cores, and expect hamsterdb
to scale with the number of cores.
==============================================================================

high-level plan for 2.2.0-pre1 (in decreasing priority)
x refactoring of configure.ac -> topic/next
x refactoring of the file format -> topic/next
x make freelist statistics endian clean -> topic/next
o btree understands fixed-size PODs -> topic/next
    o support existing callbacks - everything should work as advertised
    o support binary search only
    o support POD types: int32, uint32, int64, uint64, float, double,
        fixed length blobs, fixed length strings (?)
        (w/o duplicates and extended keys - they always enforce the
        default type based on the callback)
o cache oblivious btree layout (if it makes sense!) -> COMM
o specify timeout for remote client
o monster test can create graphs

-----------------------------------------------------------------------------

high-level plan for 2.2.0-pre1 (in decreasing priority)
x refactoring of configure.ac
x refactoring of the file format
x make freelist statistics endian clean
o btree understands fixed-size PODs
    o support existing callbacks - everything should work as advertised
    o support binary search only
    o support POD types: int32, uint32, int64, uint64, float, double,
        fixed length blobs, fixed length strings (?)
        (w/o duplicates and extended keys - they always enforce the
        default type based on the callback)
o cache oblivious btree layout (if it makes sense!) -> COMM
o specify timeout for remote client
o monster test can create graphs

-----------------------------------------------------------------------------

x collect file format incompatibilities
    x persistent freelist statistics
    x persistent freelist payload
    x page header - reserve space for 32bit crc, 32bit page size
    x for cache-oblivious (pre-allocated) index
        BtreeHeader:
          x start offset of reserved area
          x number of reserved pages
    x for the new Btree code (btree node, database header)
        BtreeHeader:
          x 32 bit flags (fixed size, var size)
          x key size
          x record size (reserved)
        BtreeNode:
          x 32 bit (!) flags
          x 32 bit (!) counter
    x make sure that the file format is extensible for more features while
        still being backwards compatible (but not forward compatible)
        -> should be ok
    x increment file format counter and make sure that older database files
        cannot be read by 2.1.3 (and that 2.1.2 fails to read the newer
        database files)
        x add unittest: load file with version 0 (Hamsterdb/openVersion1.x)
    x document this! Also document the upgrade process.

x rewrite configure.in; look at libuv for a good sample
        x also for bootstrap.sh
    x rename to configure.ac
    x test on MacOS (tcmalloc must be disabled!)
    x also for monster tests

x fix java compiler warnings

x prepare btree rewrite; the goal is to move all node-specific operations
    into the node itself, and ultimately...
    - get rid of BtreeIndex::compare
    - no longer require a status code return value in the compare function
    - ... and same for BtreeIndex::get_slot
    - move record encoding (null, tiny, empty etc) into the node
    - simplify extended keys (no extkey-cache, reduce special handling)
    - simplify duplicate keys (no dupecache in cursor, simplify cursor code)

    There are several general node layouts, depending on the configuration
    of the btree.

    without duplicates, with flags, variable keys and variable records etc:
        |hdr|f0k0r0|f1k1r1|...fnknrn|...|lazy|

    or with duplicates
        |hdr|f0k0c0r0|f1k1c1r1|...fnkncnrn|...|lazy|

    or
        |hdr|f0k0|f1k1|...fnkn|...r0|r1|...rn|...|lazy|

    "lazy" is for lazy updates. To optimize for writes: increase "lazy" space.
    To optimize for reads: decrease it or remove it completely.

    Nodes will get abstracted in the following base classes:
     1. Fixed length keys, fixed records (> 8 || <= 8 && not null),
        no duplicates
        -> uses binary search, does NOT store flags
     2. Fixed length keys, flags, fixed records (> 8) || variable records,
        no duplicates
        -> uses binary search, does NOT store flags, stores flags
     3. Variable length keys (NOT extended!),
        fixed records (> 8 || <= 8 && not null), no duplicates
        -> uses binary search, does NOT store flags
     4. Variable length keys (NOT extended!), flags,
        fixed records (> 8) || variable records, no duplicates
        -> uses binary search, does NOT store flags, stores flags
     3. Variable length keys without duplicates OR any key WITH duplicates
        -> uses linear search, CAN keep skip list

    When inserting a new duplicate then directly insert the record in the
    record list. If the record list becomes too big and the new record
    does not fit in: split the page. If it still grows and there's only
    one key with that many records, allocate an overflow page/blob and
    move all records to this page. (Same behavior for extended keys.)

    For each lookup operation/traversal: if lazy space contains data
    then insert it before searching the node!

    For inserts: split when going "down", this makes things easier, esp.
    with concurrency to come, and saves a compare!

    For the Future: internal nodes can have a different layout, and it's
    sufficient if they only store prefixes!

    x When the database is created: store the following flags in the header
        x Extended keys yes/no - make HAM_ENABLE_EXTENDED_KEYS persistent
        x Duplicate keys yes/no - make HAM_ENABLE_DUPLICATES persistent
            x make the flag persistent
            x rename to HAM_ENABLE_DUPLICATE_KEYS
                x also for java
                x and .NET
        x Fixed keys yes/no - needs HAM_DISABLE_VARIABLE_KEYS;
            x rename HAM_DISABLE_VAR_KEYLEN
                x also for java
                x and .NET
            x verify flag and size in ham_db_insert
            x verify flag and size in ham_cursor_insert
        x Fixed length of records (integer) - currently always 0
        x needs a unittest which verifies that all these settings are stored
        x add documentation

    x Baseclass BtreeNodeProxy, which is then derived and
        implemented with template parameters. The BtreeNodeProxy will
        have all the additional logic for the PBtreeNode (which will
        not be modified).
    x Need a factory for BtreeNodeProxy objects; The generated pointer is
        stored in the Page object 
        x delete it when the page is moved to the freelist
    x The factory creates a BtreeNodeProxy which is configured with
        template parameters/policies, i.e.
        - variable keys (NOT extended) with maximum key size
        - no duplicate keys
        - variable length records
        -> corresponds to
            |hdr|f0k0|f1k1|...fnkn|...r0|r1|...rn|...|lazy|
        - Has a KeyProxy template parameter (handles extkeys)
        - Has a RecordProxy template parameter (handles tiny, normal keys)
        - Has a Comparator template parameter, default is std::less<>,
            but will refer to the callback function for now
        x create Proxies for all options described in the header file

    x Rewrite BtreeEnumAction
        x create NodeLayout as template parameter with a Key as an iterator
            and proxy to access the key/record pair. The iterator has a very
            short lifespan and can point directly into the node. The node will
            not be modified during the iterator's lifetime.
        x modify "enumerate"
        x modify "release"
    x Rewrite BtreeCheckIntegrityAction
        x default compare uses database compare function
        x move compare function into BtreeNodeProxy (Comparator templ. param)
        x requires BtreeNodeProxy::compare(ByteArray *lhs, ByteArray *rhs);
                (Keys can be in different nodes)
        x requires BtreeNodeProxy::get_full_key(int index, ByteArray *dest)
                -> also resolves extended keys!
    x Rewrite BtreeInsertAction
        x BtreeNodeProxy::initialize
        x split(Page *other, int pivot)
        x find_in_internal
        x insert
        x requires_split(key) -> not yet used, but will be required later
    x BtreeNodeFactory::get does not require the 'db' parameter
    x Rewrite BtreeFindAction
    x Rewrite BtreeEraseAction
    x Rewrite BtreeCursor
    x Rewrite BtreeIndex
    x Rewrite/clean up btree_node.h - nothing to do
    x Rewrite/clean up btree_key.h, .cc
    x ... what else? Search for PBtreeKey, PBtreeNode - nothing, we're done
    x fix valgrind errors/leaks

    x clean up compare function(s)
        x default compare function must load extended keys! - it does!
        x LocalDatabase::compare_keys() no longer required (or directly
            calls into Btree comparator)
        x Transaction compare function should also use the btree template
        x use hardcoded comparator for fixed-size keys (memcmp)
            -> get rid of default_compare()
        x use hardcoded comparator for variable-size keys (memcmp)
        x use callback-comparator only if callback-function is installed
        x use hardcoded comparator for extended keys (memcmp with
            extkey-cache, prefix!?)
        x prefix-comparator no longer required, but increase extkey-cache-size
            (and age)?
        x record-number comparator no longer required, create POD comparator

    x rename PBtreeNode::*ptr_left* to *ptr_down*
    x rename PBtreeKey::*et_ptr to *et_record_id*

    x run performance tests

    x After the implementation, the following rules apply:
        x The database compare callback will not be used if the POD type
            was selected
        x PBtreeNode::m_entries is only used by BtreeNodeProxy
        x PBtreeKey is only used in BtreeNodeProxy
        x PBtreeNode::from_page is only used in BtreeNodeProxy
        x BtreeIndex::prepare_key_for_compare is gone
        x Split handling from records from handling of keys; this will make
            the next features easier to implement (i.e. for PAX storage)
        x The Btree code is a low-level module, ONLY accessing
            x Utils
            x Error
            x BlobManager
            x PageManager
            x DuplicateManager

x btree_node_proxy: has naming inconsistencies of 'slot' vs 'index'
x monster-test: always enables extended keys if keys are not numeric
x btree_insert: make sure that record numbers really pick pivots at the
    end of the page! - yes, this is fine
x btree_key: has Transaction pointer for certain operations -> not required!
x btree_erase: merge_page: if a page is merged, it has to be deleted. but
    it seems that it's not moved to the freelist. double-check!
    -> use BtreeEraseFixture::shiftFromLeftTest for testing
    -> currently implemented, will see how it goes
x btree metrics: count SMOs (page splits, merges, shifts)
    (and print them in monster test)

x fix naming consistencies - HAM_PARAM_CONST_KEY_SIZE but HAM_PARAM_PAGESIZE,
    etc
    x deprecate the old versions

x relax requirements from shift_keys
    x reduce "minkeys" from 50% to 20%
    x only shift if the number of shifted keys ("c") exceeds a certain
        threshold
    x run performance tests

x hamsterdb.com performance improvements
    x remove facebook/twitter/etc widgets from all pages except
        the frontpage
    x do not load presentation.css (or at least remove the fontfaces)

o new monster test requirements
    -> the current test is difficult to modify when introducing new features
    like the btree layout; in addition, it would be nice to have different
    distributions (random insert/erase, zipfian etc).
    -> tests are generated on the fly with identical outcome, based on the
    seed and the parameters
    -> the old files should still be working; they're good and uncovered many
    issues
    -> new interface: ./test <options> <source>
    x ./configure: specify directory of hamsterdb installation
    x get rid of prepare.sh
    x move the logs to hamsterdb-meta
    x refactor the current code; it should follow the same standards as the
        regular hamsterdb code
    x implement the new features (see above)
        x create the infrastructure for a test-generator based on
            various distributions OR existing test files
        x --distribution (random, zipfian, ascending, descending)
          - http://www.cse.usf.edu/~christen/tools/toolpage.html
          - http://coderepos.org/share/browser/lang/cplusplus/boost-supplement/trunk/boost_supplement/random/zipf_distribution.hpp?rev=5908
        x clean up existing flags, improve consistency
            x --reopen: allow -r, move to top in "help" screen
            x --cache=unlimited|<size>, remove --cacheunlimited
            x --duplicate=first|last
            x --enable-remote -> --use-remote
            x --key=uint8|uint16|...|binary
            x --fullcheck=forward|find|reverse
            x --use-encryption
            x --inmemory
            x --overwrite
            x --hints
            x --no-mmap
            x --use-writethrough -> --use-fsync
            x --use-recovery
            x --no-hamsterdb: disable hamsterdb (default: enabled)
            x --no-berkeleydb: disable berkeleydb (default: enabled)
            x --no-progress: disable progress bar (default: enabled)
            x --erase-pct=0
            x --find-pct=0
            x --stop-time=time
            x --stop-size=size
            x --stop-ops=ops
        x --key (u32, u64, string, binary; rename "numeric" to "u32")
        x --keysize (only valid for string, binary)
        x --record ('fixed', 'variable')
        x --record-size (is either the fixed or the variable size)
        x --tee (writes the test script to a file)
        x --seed

    x always print the whole configuration at startup (even if --quiet was set);
        include the seed, otherwise tests cannot be repeated!

    x need to print FAIL if the test fails - how to find out?
        x bad configuration settings
        x create/open/close/begin_txn/abort_txn/commit_txn are failing
        x insert returns unexpected error (!= DUPLICATE_KEY)
        x find returns unexpected error (!= KEY_NOT_FOUND)
        x erase returns unexpected error (!= KEY_NOT_FOUND)

    x support extended keys - how?
        -> new parameter --btree-keysize; if not set then make it equal to
            --keysize. if < --keysize: set ENABLE_EXTENDED_KEYS

    x --duplicate is currently ignored (--overwrite works, though)

    x track metrics
        x elapsed time
        x avg throughput (insert ops/bytes per sec, find ops/bytes per sec,
                    total ops per sec)
        x latency (avg, min, max) for insert, find, erase, txn_begin,
            txn_commit, txn_abort
        x extended metrics (hamsterdb) are printed on request (have to be
            fetched prior to reopen!)
            (--metrics=none|default|all)
        x add file size (after closing!)

    x berkeleydb: set cache size
    x berkeleydb: set page size (if possible)

    x create sandbox
        x singlethreaded if bdb is disabled and threading is off
            - disable fullcheck!
        x singlethreaded if hamsterdb is disabled and threading is off
            - disable fullcheck!
        x default: *only* hamsterdb is running (single-threaded)
            -> needs --with-berkeleydb instead of --no-berkeleydb
        x singlethreaded with hamsterdb and bdb, including fullcheck
            x create 2 generators, run both and print metrics
            x don't run fullcheck if --fullcheck=none
            x "reopen" should also trigger fullcheck
            x implement fullcheck
            x after "find" compare the records
            x fullcheck every "n" operations
        x multiple hamsterdb threads (without bdb)
            x no synchronization and no fullcheck
            x with "remote" all threads access the same server with
                their own connection!
            x have to "add up" the metrics of all the threads

    x fails: --distribution=ascending --stop-ops=10000
    x test with --use-cursor are currently failing (bdb)
    x at startup, print copyright, configuration and hamsterdb version
        (unless 'quiet')
    x how to open an existing file, i.e. to perform reads (find-pct=100)?
    x bdb: do not use hardcoded include/library paths; if it's not installed
        then compile without it
    x tests with zipfian distribution are very slow - currently don't see
        a way to solve this

    x ParserGenerator: reads and executes existing test files
        x test with multiple threads
        x implement "reopen"
        x test vs bdb
        x test vs bdb and --open
        x "fullcheck" must be handled by caller

    x monster.sh: should become a perl script (monster.pl)
        x add switch --dryrun to just test the configuration parameters
        x make sure all tests are running with monster.pl
        x have option to run tests with valgrind
        x make sure tests are run against bdb (currently not the case)
        x have option to call run_directory($dir, $options) directly
            from command line
        x valgrind tests need to check for memleaks and other issues

    x update perftest.pl
        x print ALL metrics
        x compare the metrics

    x clean up the 'env' directories, rename to 'sandbox'; do not differentiate
        between posix and win32; get rid of common (it's replaced by the perl
        script)

    x generate performance graphs (latencies for insert/erase/find/txn_commit)
        and maybe map additional events in the graph, like cache flushes
        x store insert latencies
        x store find latencies
        x store erase latencies
        x store txn_commit latencies
        x only for hamsterdb, not for berkeleydb
        x also should show "inserts/erase/find/commit per second" graphs
        x call gnuplot to generate the graph

x move virtual inheritance one level "up" into the BtreeIndex
    x the BtreeProxyFactory now creates BtreeIndex objects
    x the BtreeNodeProxy is created by the BtreeIndex
    x rewrite BtreeIndex::compare_keys and directly use a Comparator
        object
    x introduce HAM_PARAM_KEY_TYPE = HAM_KEY_TYPE_BINARY, HAM_KEY_TYPE_CUSTOM,
            HAM_KEY_TYPE_UINT32
        x BINARY: uses builtin memcmp comparator
        x BINARY is the default!
        x add documentation to header file
        x store persistently in database
            x unittest
        x return in ham_db_get_parameters
            x documentation
            x unittest
        x disallow ham_db_set_compare_func if type != CUSTOM
            x documentation
            x unittest
        x add to Changelog!
    x remove BtreeNodeFactory
    x move existing layout to btree_node_legacy.h (include btree_key.h)
        x move PBtreeKey-enum (kExtendedKey etc) somewhere else
        x PBtreeKey and btree_key.h should no longer be used!
    x need monster test for key type "custom"
        x set type CUSTOM if a callback compare is required
        x set type CUSTOM if --keytype=custom was selected
        x add this to monster.lst, performance test and valgrind.lst

x move the monster tool to the main hamsterdb repository; then it's
    automatically tagged and updated, and easier for everyone to
    find it. testfiles and the tests for the monster binary can be
    stored in a separate repository (hamsterdb-tests), as well as
    the whole sandbox with the additional stuff.
    x if test is run in debug mode then print a fat warning!
    x need a better name - ham_bench?
    x link statically
    x make bdb disabled by default, enable it with configure-switch
    x should also compile/run if remote is disabled
    x clean up monster test suite

x ham_bench fixes
    x --help does not work
    x perftest.pl: also test transactions with inmemorydb
    x add new operation "table-scan", option "table-scan-pct"
        x also for parser!
    x parser-generator still has many TODOs
    x parser-generator ignores NUMERIC_KEY flag
    x the zipfian distribution is unusable because it is so slow; can we
        somehow mitigate this? otherwise get rid of it (or do not document it)
    x msvc/win32 project files
    x wiki: 1 page for benchmarking
    x wiki: 1 page for running the tests

x search hamsterdb.cc for this: "re-enable this after 2.1.1, when the"...
    and fix it

x use parameterized btree for fix sized POD types
    x if performance is fine: rebase/merge with v2
    x use HAM_TYPE_UINT64 for record numbers (WITH endian conversion!)
    x support these types in the new monster test
    x legacy-layout:284: allocates m_arena on stack, should be member
        to avoid frequent re-allocations
    x support float (REAL32) and double (REAL64) type
        x have 1 unittest per type
        x support new types in ham_bench
        x extend monster tests
        x extend valgrind tests
        x extend performance tests
    x fixed length keys: disallow flag HAM_ENABLE_EXTENDED_KEYS
    x enforce correkt key size in ham_db_insert, ham_cursor_insert
    x once more review the code, esp. the "compare" should be in a really tight
        loop without branches

    x ham_info must show type information
    x ham_export/ham_import must create the correct databases
    x ham_dump must print the correctly formatted values

    x Introduce HAM_PARAM_KEY_TYPE == HAM_TYPE_UINT32 and create
        a new BtreeNodeProxy in the factory; add a new comparator and
        reimplement everything for a 32bit integer
        x need header flag and documentation in the header file
        x no endian conversion - document this!
        x needs its own custom compare object
        x use HAM_TYPE_BINARY with variable length is the default
            (uses legacy layout for now)
        x use PAX style storage in the node (flags, keys, records) and
            separate flags, keys (fixed length only - for now) and records
            x implement new template class for the layout (btree_node_pax.h)
            x iterator is a simple integer index with constant key size
            x calculate layout when creating the node (the layout is fixed,
                since all sizes are fixed)
            x does not require 2 bytes for key size
            x update BtreeIndex::calc_maxkeys - should be calculated by node
                layout/proxy
                x unittest: verify keysize for uint32-type
                x unittest: verify max. keys per page for uint32-type
                x unittest: verify keysize for binary/custom
                x unittest: verify max. keys per page for binary/custom
            x implement all remaining functions
        x unittest: need to check whether the correct template parameters
            are picked, i.e. by having the BtreeIndex return a string of its
            class name (how to do that?)
            http://gcc.gnu.org/onlinedocs/libstdc++/manual/ext_demangling.html
        x test and verify
            x key types must work with berkeleydb
            x requires new monster tests (esp. with small pages)
                x make sure NUMERIC_KEYS tests still work and use the new type
                x do not reopen inmemorydb files
                x ./ham_bench ../testfiles/1/220.tst fails
                x ./ham_bench ../testfiles/1/45.tst fails
                x ./ham_bench ../testfiles/1/46.tst fails
                x enable EXTENDED_KEYS if filename starts with "ext_"
                x --inmemorydb --use-extended --use-berkeleydb ../testfiles/1/ext_020.tst
                x --inmemorydb --use-extended --use-berkeleydb ../testfiles/1/ext_021.tst

                x new tests should use randomly generated data
                x enable EXTENDED_KEYS if filename starts with "ext_"
                x new tests should use randomly generated data
            x requires new performance tests
            x requires new valgrind tests

    x how can we assure that after opening the file the identical Btree
        templates are selected?? -> done in the tests

    x fix outstanding bugs
        x btree_index_factory has asserts if duplicates are enabled
        x uintXX/duplicates are failing because duplicates enforce
            binary type
        x multithreaded tests are failing b/c berkeleydb is enabled
            -> remove them, they're not worthy
        x monster.pl: also add tests for mixed workloads
            x increase "max" back to 1 mio, but make it overwriteable
                through command line parameter
            x add "--quiet" again
        x monster.pl: add extended key tests for binaries w/ mixed workloads
        x all tests need to run fine

x ham_dump: "tee" does not write FULLCHECKs

x db_local: create extkey-cache in constructor, not on demand (only if extended
    keys are enabled and not inmemory)
    -> remove set_extkey_cache
    -> this cleans up some code

o use pax layout for fixed-size BINARY and CUSTOM
    -> a bit tricky because the current code is based on the fact that
        type T is a POD
    -> create a new Layout class, which reads the key size from a variable?
    -> both Pax layouts could derive from a common base class
    o run performance of pax vs. legacy (also with larger pagesizes)
    o extend unittests
    o extend monster tests
    o extend valgrind tests
    o extend performance tests

o run static code analysis
    o coverity
    o clang

o specify timeout for remote client
    x add new option HAM_PARAM_NETWORK_TIMEOUT_SEC
    x for unix
        struct timeval tv;
        tv.tv_sec = sec;  // 30 Secs Timeout
        tv.tv_usec = 0;
        setsockopt(sockfd, SOL_SOCKET, SO_RCVTIMEO, (char *)&tv, sizeof(tv));
    x for java
    x for dotnet
    x needs a unittest
    x test on MacOS
    o for Windows
        http://msdn.microsoft.com/en-us/library/windows/desktop/ms740476%28v=vs.85%29.aspx

. win32: need a release-v2.pl which fully automates the various release steps

o win32: a few unimportant unittests are failing (2.1.2)

o update the documentation/changelog/README/tutorial
    o the prefix compare function API was removed
    o describe the new flags/options
    o announce the 3 new wiki pages (or better move them to hamsterdb.com?)
    o update the samples and use the new types

------------------- release 2.2.0-pre1 UNSTABLE!!! -----------------------------

high-level plan for 2.2.0-pre2 (unstable)...................................
- remove "shifts" from btree SMOs, only merge
- btree understands variable-sized PODs
    - uses PAX layout with a small (in-memory) skiplist and linear search
        in this skiplist
    - also use linear search with fixed length keys (if max-keys-per-page
        is low enough)
    - when cursors move forward: do not access "by random-access-index" but 
        by incrementing the cursor! (this is not possible for moving backwards,
        therefore both has to be supported)
- completely rewrite handling of extended keys
    If the extended key does not fit into one page: allocate an overflow area,
    move the FULL key into that area. get rid of the prefix compare. compare
    functions no longer need to return errors. get rid of the extkey-cache.
    (really?)
    ==> make sure this does not cause performance regressions
    ==> count number of overflow areas for statistics!
    - monster.pl needs to create variable length extended keys for testing!
- btree stores fixed-length records in the leaf
    also support record length of 0 ("key exists" vs "key does not exist")
    - not for internal nodes! they have a fixed record length of 8!
    - needs to move BtreeIndex::read_record into BtreeNodeProxy
    - if duplicates are disabled AND record size is fix:
        do not store 1 byte flag for each key
    - if page is large enough then store the record in the leaf, even
        if it's > 8 bytes
- replace 3rdparty/json with boost property_tree
- btree can compress keys (strings: prefix, everything: dict) -> COMM
    - needs new ham_bench enhancements to use actual strings instead of
        random garbage - see below
- btree can compress records (prefix, dict, snappy) -> COMM
- use SIMD for fixed-length scans -> COMM
    http://pcl.intel-research.net/publications/palm.pdf

high-level plan for 2.2.0 (unstable).........................................
- completely rewrite handling of duplicate keys
    - store records inline; if there are too many then allocate an overflow
        extend
- lay the groundwork for concurrency -> LSS-streams, finalize the file format
    (every buffer needs stream descriptor, trailer)
- cache-oblivious page distribution? (maybe write the LSS first?)
- security? -> COMM

revisit transaction trees and delta updates..................................
- a transaction update is very similar to a delta update
- both have to be consolidated
- btree can handle delta updates
    - (or postpone till concurrency?)
    - delta updates are merged when there are too many of them, or if a cursor
        traverses the page (only if memcpy/memmove takes too much time)

o ham_bench improvements
    o have more data sources based on dict/words (concatenate, if there are
        not enough or if they are too short)
      o StringRandomSource(max)
      o StringAscendingSource(max)
      o StringDescendingSource(max)
      o StringZipfianSource(max)

o continue with the Btree rewrite
    o support linear search through a node (with skip list?)
    o support variable length types, use linear search (with a skiplist)
        for strings (strcmp), blobs (memcmp)
    o replace extended keys; store them in the leaf unless they're TOO big
        (then either use an overflow area or refuse to store them i.e. if
        they are > 20% of the page - better refuse, then we can also get
        rid of the error code that can be returned by the compare function)
        -- really? wouldn't this be inconvenient for the users?
    ------- release -------
    o replace duplicate keys; this will be difficult because it requires
        rewriting the Cursor consolidation flow
    ------- release -------
    o optionally store fixed length record in leaf (not in internal pages!)
    ------- release -------
    o add column store compression for keys, lightweight compression for
        records (snappy, etc) -> COMM!
    ------- release -------
    o add "functions" and predicate scans, i.e. COUNT() w/ predicates???
    ------- release -------
    o add combined high-level schemas (combinations of various POD types)

o use cache-oblivious b-tree layout
    o see roadmap document for more information
    o run a performance test/prototype if this is worth the effort
        o allocate a fixed number of pages (20) for the index
        o PageManager: when allocating a new page then use the distribution
            function to fetch a page from the reserved storage
    o this feature is *per database*
    o calculate number of reqd pages based on estimated keys from the user
    o make sure that this is not reverted when "reduce file size" feature
        (above) is enabled
    o the new pages are not managed by the freelist! therefore the freelist
        will not need any modifications
    . try to batch allocations; when new pages are required then don't just
        allocate one but multiple pages (if the database is big enough)

o increase libtool version
o increase API version in header file (if there are any incompatibilities)
o clean up API
    o ham_key_t: data pointer should be const
    o ham_key_t: remove all "hidden" members (_flags)
    o ham_record_t: data pointer should be const
    o ham_record_t: remove all "hidden" members (_flags)
    o ham_db_insert: parameters should be const
    o ham_db_find: parameters should be const
    o ... etc

. win32: need a release-v2.pl which fully automates the various release steps
    o delete all generated protobuf files
    o build for msvc 2008
    o run unittests for debug and release
    o run samples
    o delete all generated protobuf files
    o build for msvc 2010
    o run unittests for debug and release
    o run samples
    o build release package

. it would be interesting to know the distribution of changelog "sizes" during
    a test (i.e. how many operations result in changelogs of size 1, 2, 3 etc)
    and how many operations actually require the WAL

. review/rewrite/refactor Transaction class
    keep in mind that sooner or later the BtreeNode will expect template
    arguments; can we do something similar with the TransactionNode?
    x try to get the methods/design analoguous to the Btree - no, that
        does not make too much sense
    x document the tree structure in the header file
    x refactor the code
    o split into multiple files
    o try to cleanup the flow; move more code from db.cc to txn.cc
    . each Transaction should have its own PoolAllocator (based on ByteArray);
        when deleting the whole structure, only the PoolAllocator is freed
        o only do this if memory allocations cost performance
        o problem: a realloc() will not always work because it might move
            the allocated memory, and all existing pointers would be invalid 
. also remove locking from C# and Java APIs

. BtreeCursor: use memory arena for uncoupling the key
    -> better wait till extended keys are gone

. also remove locking from C# and Java APIs






------------------- idea soup ---------------------------------------------

o asynchronous prefetching of pages
    -> see posix_fadvice, libprefetch

o flush transactions in background (when the btree is concurrent)

. remove libjson, use boost::property_tree instead!
    o also on Windows!

o Improve leaf pages caching
    Store start/end key of each leaf page in a separate lookup table in order
    to avoid btree traversals. This could be part of the hinter.
  - one such cache per database
  - should work for insert/find/erase

o allow transactions w/o journal

o allow transactions w/o recovery

o when recovering, give users the choice if active transactions should be
    aborted (default behavior) or re-created
    o needs a function to enumerate them

o when flushing the Changeset: batch ALL changes for the WHOLE transaction,
    then flush all of them together. This way we can "merge" multiple changes
    for the same page.
    Also review the whole flush process - when not to log etc.
    - only 1 page affected: no need to log it because it is idempotent
    - freelist pages are always idempotent
    - more than 1 index page? not idempotent (most likely)
    - more than 1 blob page? not idempotent (maybe)
    o define a few benchmarks
    o be careful: if N operations are modifying the same changelog, and
        then #N+1 aborts then the aborting operation must NOT clear the
        changelog!

o A new transactional mode: read-only transactions can run "in the past" - only
    on committed transactions. therefore they avoid conflicts and will always
    succeed.

o changeset: instead of simply adding pages to the changeset, the caller
    could already specify whether this page needs logging or not;
    i.e. after freelist rewrite, the blob pages do not need logging if a
    blob is deleted  

o is there a way to group all changeset flushes of a Transaction into one
    changeset, and batch-commit multiple commits? that way we would avoid the
    frequent syncs and performance would be improved
    o would have to remove all of assert(changeset.is_empty())
    o but we can use that assert prior to txn_begin

o BtreeFindAction: always use a cursor, and when doing approx matching
    then simply move left or right with that cursor

o flush in background (asynchronously)
    o need new flag file HAM_DISABLE_ASYNCHRONOUS_FLUSH
    o if in-memory database: disable async flush
    o if transactions are disabled: disable async flush
    o if enabled: create background thread, wait for signal
    o ham_env_flush: if txn are enabled then try to flush them to disk
    o how to deal with an error in the background thread???
        o store in Environment, then return in every exported function
    o default: async flush is OFF!

    o extend monster tests
        o with async flush
        o without async flush
        o extend/run performance test
        o run monster tests

    o documentation
        o tutorial
        o faq

o need a function to get the txn of a conflict (same as in v2)
    ham_status_t ham_txn_get_conflicting_txn(ham_txn_t *txn, ham_txn_t **other);
        oder: txn-id zurückgeben? sonst gibt's ne race condition wenn ein anderer
        thread "other" committed/aborted
    o also add to c++ API
    o add documentation (header file)
    o add documentation (wiki)

. new test case for cursors
    insert (1, a)
    insert (1, b) (duplicate of 1)
    move (last) (-> 1, b)
    insert (1, c)
    move (last) (-> 1, c)? is the dupecache updated correctly?

. there are a couple of areas where a btree cursor is uncoupled, just to
    retrieve the key and to couple the txn-key. that's not efficient
        db.c:__btree_cursor_points_to
        db.c:__compare_cursors
        txn_cursor.c:cursor_sync
        txn_cursor.c:cursor_overwrite
    o move to a separate function
    o try to optimize

. add tests to verify that the cursor is not modified if an operation fails!
    (in cursor.cpp:LongTxnCursorTest are some wrapper functions to move or
    insert the cursor; that's a good starting point)

. new flag for transactions: HAM_TXN_WILL_COMMIT
    if this flag is set, then write all records directly to the file, not
    to the log. the log will only contain the rid.
    -> or: make this the default; call the new flag HAM_TXN_MAYBE_WILL_ABORT
    o in case of an abort: move the record to the freelist
    -> this affects all temporary ham_insert-transactions
    (not sure if this should get high priority)

. if memory consumption in the txn-tree is too high: flush records to disk
    (not sure if this should get high priority)

o ham_get_count: could be atomically updated with every journal entry

=======
>>>>>>> Updated TODO
