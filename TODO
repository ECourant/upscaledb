
x release 0.4.5

x support GPL3
    x change all source headers -> GPL 2.0 *or later*
    x rename COPYING to COPYING.GPL2
    x add GPL3 license file (COPYING.GPL3)

x create a new repository for hamsterdb-meta

x unittests - check for leaks!
    x replace big record with tiny
    x replace big record with null
    x replace tiny record with null
    x replace tiny record with big

x recno: keys lassen sich nicht überschreiben
    x für ham_insert fixen
        x unittest
    x für ham_cursor_insert fixen
        x unittest

x rename ham_cursor_replace to ham_cursor_overwrite (and all other instances
    of "replace" with "overwrite")
    x hamsterdb.h 
    x replace sources
    x fix unittests
    x tutorial

o support for duplicate keys
    x make sure that EXTENDED_BLOB flag is always set if blob>=8 byte 
        (check unittests!)
        -> not needed - TINY_BLOB or SMALL_BLOB are enough
    x test if everything runs fine if blobs are always allocated

    x ham_create needs flag HAM_ENABLE_DUPLICATES
        x persistent flag -> unittest

    x don't allow insert(HAM_DUPLICATE|HAM_OVERWRITE)
        x fix in code
        x documentation!
        x unittest

    x modify db_free_page; also delete the duplicates
    x modify my_free_cb

    x need a list of all cursors
        x add cursor_next, cursor_previous
        x add cursor *ham_db_t::_cursor_list
        x btree_cursor_create: prepend new cursor to the list
        x btree_cursor_destroy: delete cursor from the list
        x unittest: check if links are correct
            x also with cloned cursors!

    x when freeing in-memory pages/blobs: also free the duplicates (otherwise
        we have memory leaks)
        x unittest

===========================

    x remove the old crap
        x and the unittests!

    x new flag KEY_DUPLICATE (alternatively to TINY, NULL)
        x must not appear in internal keys

    x cursor: dupe_id is the offset in the dupe_table
        x type is ham_size_t
        x always starts with zero

    x create a blob_duplicate_t structure
        x the structures
        x getters
        x setters
        x unittest for the structure

    o a new function
        key_set_record(int_key_t *key, ham_record_t *record, 
            flags=0|OVERWRITE|DUPLICATE[_position]);
        -> otherwise, there's now duplicate code in btree_cursor.c and
           btree_erase.c und btree_insert.c

    o blob_duplicate_insert(dupe_table_id, position, flags, [flags, rid]+);
        -> returns the new dupe_table_id
    o blob_duplicate_erase(dupe_table_id, position);
    o blob_duplicate_overwrite(dupe_table_id, position, [flags, rid]);
    o blob_duplicate_get_count(dupe_table_id);

    o insert:
        o new dupes are appended at the END of the list (add documentation!)
        o if no duplicate table exists: create one, and immediately append 
            the new record
        o change the unittests





===========================

    x enhance the blob structure for double-linked lists
        x unittest (structure)
    x enhance the cursor structure for the linked list
        x coupled cursor: store blobid of the current duplicate

    x ham_insert: insert duplicate (at the beginning of the list)
        x if blob is SMALL/TINY: create blob structure
        x prepend the new blob, if HAM_DUPLICATE==1
        x unittests; check dupe with ham_find

    x modify cursor->next, cursor->previous to walk over the linked list 
        x flags: HAM_SKIP_DUPLICATES -> don't walk over duplicates
        x !!! currently, only the blob->next pointer is set, not blob->prev
            x need to modify ham_insert
            x need to modify ham_erase
            x unittests!
                x insert dupes, look up, erase them, look up
                x also for in-memory databases!

        x when moving the cursor, always check if the cursor has duplicates
            -> already started in my_move_next(), my_move_prev()
            x implement blob_get_previous_duplicate()
            x implement blob_get_next_duplicate()
                x unittests!

            x ignore dupes if !(db_flags&ENABLE_DUPLICATES) 
                or (flags&SKIP_DUPLICATES)
            x otherwise: always store the current blobid
            x when fetching the record: if (blobid) load blobid; otherwise
                continue as usual

            x unittests w/  SKIP_DUPLICATES
            x unittests w/o SKIP_DUPLICATES

        x couple cursor (bt_cursor_couple):
            x ham_insert: don't uncouple cursors if inserting duplicates
            x unittests w/ coupling, uncoupling

    x ham_cursor_erase: erase the duplicate at the current position
        x ham_erase
            x delete ALL duplicates
            x make sure that all cursors are NILled if they point to
                the deleted item - regardless if there are dupes or not
            x unittest
        x ham_cursor_erase 
            x delete only the selected duplicate
            x if the whole key is deleted: make sure that all cursors are 
                NILled if they point to the deleted item; if just a dupe is
                deleted: only NIL those cursors which point to the dupe
            x unittest!
                x insert 2 dupes, 2 cursors on the first dupe; erase one
                    cursor; the other points to nil. the other dupe is
                    still available
                x insert 2 dupes, 2 cursors (one on the first, the other on
                    the second dupe); erase the first cursor; the second
                    is still valid
                x insert 2 dupes, 2 cursors (one on the first, the other on
                    the second dupe); erase the second cursor; the first 
                    is still valid
                x same as the three above, but uncouple the cursors!
        x document the differences between ham_erase and ham_cursor_erase!

    x ham_cursor_move(LAST) should not ignore duplicate keys
        x unittest

    x new flag HAM_CURSOR_ONLY_DUPLICATES - only walk through duplicates,
        not to the next key
        x unittest

    x unittest for flag HAM_CURSOR_SKIP_DUPLICATES

    x don't allow HAM_CURSOR_SKIP_DUPLICATES|HAM_CURSOR_ONLY_DUPLICATES
        x unittest

    x ./test --file ../../testfiles/1/ext_021.tst --overwrite=1 --verbose=1
        --> broken
        step into insert in line 592

    x cursor: move_previous must move the cursor to the last element in 
        the duplicate list (but not if SKIP_DUPLICATES is set)
        x unittest

    x replace duplicates
        x ham_insert(OVERWRITE) 
            x only overwrite the first item
            x overwrite in a linked list
                x in-place - nothing else to do
                x free/alloc (for resizing) - update all cursors
            x unittests
        x ham_cursor_overwrite
            x overwrite just the duplicate
                x in-place - nothing else to do
                x free/alloc (for resizing) - update all cursors
            x unittests

    o modify cursor->insert - if the cursor is in a linked list, 
        insert a duplicate at the requested position
        x HAM_DUPLICATE_INSERT_AFTER
            o unittests
        x HAM_DUPELICATE_INSERT_LAST
            o unittests
        x HAM_DUPELICATE_INSERT_BEFORE (=HAM_DUPLICATE)
            o unittests
        x HAM_DUPELICATE_INSERT_FIRST
            o unittests

        o don't allow these flags in ham_insert, only in ham_cursor_insert
            o unittest

    o if a cursor is coupled to the very first duplicate, its dupe_id 
        MUST be 0!
        o check all cursor functions
        o everything else should remain as is

    o modify acceptance test for --duplicate=1 (berkdb and hamster)
        o --duplicate-position="before"|"after"|"first"(default)|"last"
        o new acceptance tests with many, many duplicates
    o update documentation
    o update tutorial
    o new sample, read all words from stdin, insert them with line information;
        also, insert the same word in a second db, with a word-counter
        then dump all words with the line information, and how often they
        were used
    . modify sample env1, to create a 1:n relationship between orders
        and customers (or create a new sample)

    o endian-tests

o check ham_txn_abort in btree_cursor.c
    this call never appears in hamsterdb.c, but quite frequently in the
    cursor routines; is this a problem?

o be more careful when uncoupling cursors - especially when inserting 
    or deleting items, uncoupling is often not necessary
    o definitely no need to uncouple if overwriting or adding a duplicate

o more ideas for unittests
    o unittests: insert NULL/TINY/SMALL blobs, then create linked lists
    o unittests: insert NULL/TINY/SMALL as duplicates
    o unittests: 
        o create cursor -> must be NIL
        o insert item   -> must be NIL
        o move cursor to item
        o insert item2 < item -> cursor is uncoupled
        o move cursor to item
        o insert duplicate of item -> cursor is still coupled
        o insert item2 > item -> cursor is still coupled

o ham_close with flag HAM_AUTO_CLOSE_CURSORS
    o unittests

o ham_env_close with flag HAM_AUTO_CLOSE_DATABASES
    o unittests

o webpage
    o update web page about license change (GPL2 or GPL3)
    o rename "Features" to "About"
    o update roadmap
    . move to cakephp framework
    . frontpage: resize hamster picture; remove text -> more space below
        (for 3 colums: news, main features, articles/testimonials/link cloud)

o btree_insert:421 - why is the extkey deleted??

o protect users against uninitialized ham_key_t and ham_record_t structures
    o check if key->flags is 0 or USER_ALLOC
    o check if key->_rid is 0
    o check if record->flags is 0 or USER_ALLOC
    o check all other private flags
    o unittests!

o create a new repository for hamsterdb-alien for all dependencies 
    in source and precompiled (static/non-debug - cppunit and berkeleydb)
    x linux64-le
    x linux32-le
    o cygwin32
    o win32
    o win64
    o wince-x86
    o ppc32-be

o currently, there's no "cheap" way to get the number of duplicates of a key
    o is this needed? use cases?
    o could always add the number to the very first blob; if the first
        blob is deleted, the number moves to the next first blob

o record numbers should not be reused
    currently, if the last record is deleted, and then the database is
    reopened, this record number is reused
    persistently cache the number of elements in the database - we need 
    this information anyway.
    o insert: set record->_rid to 0, to make things easier
    o add a new function ham_get_count()

o record numbers don't check endianess in ham_find/ham_cursor_find:
    the key parameter coming from the user must be endian-translated!
    

