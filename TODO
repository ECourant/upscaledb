


x 220.tst: schlägt fehl im release-build!

    Lese Spezifikationen von /usr/lib/gcc/x86_64-pc-linux-gnu/3.4.5/specs
    Konfiguriert mit: /var/tmp/portage/gcc-3.4.5/work/gcc-3.4.5/configure
    --prefix=/usr --bindir=/usr/x86_64-pc-linux-gnu/gcc-bin/3.4.5
    --includedir=/usr/lib/gcc/x86_64-pc-linux-gnu/3.4.5/include
    --datadir=/usr/share/gcc-data/x86_64-pc-linux-gnu/3.4.5
    --mandir=/usr/share/gcc-data/x86_64-pc-linux-gnu/3.4.5/man
    --infodir=/usr/share/gcc-data/x86_64-pc-linux-gnu/3.4.5/info
    --with-gxx-include-dir=/usr/lib/gcc/x86_64-pc-linux-gnu/3.4.5/include/g++-v3
    --host=x86_64-pc-linux-gnu --build=x86_64-pc-linux-gnu --disable-altivec
    --enable-nls --without-included-gettext --with-system-zlib --disable-checking
    --disable-werror --disable-libunwind-exceptions --enable-multilib
    --disable-libgcj --enable-languages=c,c++,f77 --enable-shared
    --enable-threads=posix --enable-__cxa_atexit --enable-clocale=gnu
    Thread-Modell: posix
    gcc-Version 3.4.5 (Gentoo 3.4.5, ssp-3.4.5-1.0, pie-8.7.9)
    
-----------------------------------------------------

o file test.tst hat ein kleines memory leak (blob.c, zeile 409)

x ./dbtest.py ohne argumente sollte IMMER eine filelist nehmen

x die ext-key-tests schlagen bei overwrite=1 fehl

o wenn alle tests laufen: rudimentäres makefile machen, dann neues release!

o auch mit release-version testen!

    zuletzt getestet: --pagesize=1024 --overwrite=1

-----------------------------------------------------

o warum wird die datenbank so verdammt gross? z.b. test 190 mit overwrite=1:
    test-berk.db: 232 kb, test-ham.db: 40 MB!
    
    -> liegt daran dass die datei nicht kleiner wird, wenn einträge mit 
    erase gelöscht werden. wenn man berkeley-db mit strace startet, 
    kommen sicher am schluss viele "negative" truncate()-aufrufe, die 
    die datei schrumpfen lassen.

    -> können wir das auch?? lohnt sich das?

    -> bei der freelist die einträge zusammenlegen, soweit das möglich ist

-----------------------------------------------------

o beim blob_allocate und blob_read brauchen wir die pages nicht zu 
    cachen; -> die hdr-page wird gecacht und in der txn verwaltet,
    aber der rest könnte direkt geschrieben bzw. gelesen 
    werden (os_read/os_mmap, os_write)

o overwrite: wenn der blob gleich gross ist, muss er nicht gelöscht 
    sondern kann direkt überschrieben werden. es kommt in der praxis
    sicher häufig vor, dass die datensätze gleich gross sind. also 
    würde sich eine solche optimierung lohnen.

-----------------------------------------------------

o mit noch grösseren blobs und datenbanken testen 

o Datei > 2GB erzeugen

-----------------------------------------------------

o profiling! aber mit der release-version...

    o binary search statt linear search

    o statt --profile ab sofort:
        o --profile=all - wie bisher
        o --profile=none - ausschalten
        o --profile=insert - nur insert
        o --profile=erase - nur erase
        o --profile=find - nur find
        o etc

    o in-memory-db
    o mmap
    o read/write
    o verschiedene page- und keygrössen
    o nur inserts
    o nur inserts ohne blob
    o nur erase
    o nur lookup
    o auch gegen andere backends (qdbm, itzam)
    o etc etc etc

    o können wir drauf verzichten, beim db_page_alloc ein tell, seek, 
        truncate zu machen? evtl kommen wir ganz ohne resize aus??

o extended keys doch cachen? sind SEHR langsam im vergleich zu bdb...

o können wir die minkey/maxkey-regel relaxen? also später splitten
    und später mergen?
    minkeys=min(4, maxkeys/2)
    etc

o momentan werden alle pages auf null gesetzt (memset(page->pers->payload, 0))
    und zwar evtl sogar mehrmals (freelist!)
    raus damit!

-----------------------------------------------------
-----------------------------------------------------

o tests
    o test mit freelist
    o test mit mmap, verschiedene pagesizes
    o test mit read, verschiedene pagesizes
    o test mit in-memory-db, verschiedene pagesizes
    o in-memory-database testen
    o verschiedene pagesizes/keysizes für
        o in-memory-db
        o os_mmap
        o read(2)

o stress test mit zufällig fehlschlagenden io-funktionen und zufälligen
    OUT_OF_MEMORYs

o endianness testen

o auf 32bit-rechner testen; können wir die datenbank-dateien
    hin- und herkopieren?

o stress-test-tool(s), das ALLE optionen durchprobiert
    mmap
    r/w
    in-memory
    verschiedene pagesizes
    grosse keys
    grosse blobs
    dauertests (mehrere stunden)

-----------------------------------------------------

o doku
    o tutorial/sample in die online-hilfe einbeziehen
    o FAQ mit häufig gestellten fragen, tips zu optimierungen
    o Dokumentation in den header-dateien überarbeiten
    o überarbeiten

-----------------------------------------------------

o statistics
    will wissen wie viele freelist-hits/misses und cache-hits/misses es gab

    brauche bei den statistik-feldern die anzahl der aktuellen Keys in der
    Datenbank

    wird im sql gebraucht für AUTO_INCREMENT vom index und für eine schnelle
    Berechnung
    von MAX() über die ganze tabelle.

    allerdings wird das etwas tricky, sobald transaktionen dazu kommen - erst
    beim commit der transaktion muss der zähler inkrementiert/dekrementiert und
    auf platte geschrieben werden. erst sobald der erhöhte zähler wirklich auf
    platte geschrieben wurde, ist die transaktion abgeschlossen.

    jedoch ist das blöd, weil es dann immer einen zusätzlichen
    schreibzugriff gibt, sobald ein insert oder erase stattfindet. eher 
    sollte nach dem start geprüft werden, ob es einen absturz gab - 
    falls ja, werden die statistiken gelöscht, und on demand wieder 
    initialisiert. (diese ganze problematik kommt erst, wenn wir sql brauchen).

    Die MAX-Berechnung sollte recht simpel sein. Alle anderen Statistiken (z.b.
    total size von allen Datensätzen) werden teuer - die sollten nicht immer
    up-to-date gehalten werden, sondern nur on-demand vom cli-tool "ham_stats"
    ausgegeben werden).

o statistics
    get generic getter/setter for statistical value, i.e. 
        enum { CACHEHITS, CACHEMISSES, PAGES, FREEPAGES, ... };
        ham_u64_t statistics[8];
    set_stats_value(db, which, value): db->statistics[which]=ham_h2db32(value)
    ATTENTION: some of those values are specific for each backend, others
        are global; therefore we need two functions: 
        ham_get_global_statistics(stat)
        ham_get_index_statistics(index, stat)

-----------------------------------------------------

o ein ganz einfaches makefile, das einen release-build baut?? 
    damit man kein scons braucht

-----------------------------------------------------
-----------------------------------------------------

o tools
    o ham_dump
    o ham_stats

-----------------------------------------------------

o super-COMPRESSED-mode: keine headerpage, und pagesize auf 128 byte ->
    super-mini-datenbanken (für embedded) - möglich ohne Aufwand? wird tricky, 
    weil die page-alloc-funktionen davon ausgehen dass eine adresse 0 ein
    fehler ist

-----------------------------------------------------

o datenbank mit O_EXCL öffnen, bzw mit flock() (und nem wait, falls die 
    Datenbank gelockt ist) -> Möglichkeit für pseudo-concurrent access bei
    kurzen, schnellen Zugriffen (z.b. webseite)

-----------------------------------------------------

o cache: bucketgrösse in ham_config.h verschieben, eine #define-konstante
    draus machen

-----------------------------------------------------

o documentation -> texinfo? doxygen?
    merge the documentation with doxygen-docs

o define HAM_EXPORT DECLSPEC _dllexport
    compile a shared library

-----------------------------------------------------

o iteratoren 
    o sind schon designt (siehe iterators.txt im rechner auf arbeit)

    o in-memory-db: finden wir ne möglichkeit, normale datenbanken in 
        in-memory zu importieren und umgekehrt wieder zu exportieren? 
        das wäre genial
        --> geht mit iteratoren (erst release 2.0!):
            iterator from=db1.begin()
            while (from)
                db2.append(from)
                from.next()
        --> geht auch mit der enum-funktion, die jetzt schon drin ist

-----------------------------------------------------

o duplicate keys (nicht in version 0.1.0, sondern 0.1.1)
    jeder key bekommt einen dupcounter; der wird mit unsigned(-1) initialisiert
    beim einfuegen wird rekursiv abgestiegen. im leaf wird dann ein neuer key
    eingefuegt, mit dem dupcounter=existierender ("kleinster") key minus 1.

-----------------------------------------------------

Version 0.1.0 - first release!!

o komplettes review
    werden fehlerwerte korrekt propagiert?
    machen fehlerwerte immer sinn? z.b. in flush_all()
    was passiert mit fehlern beim flushen?
    was passiert mit fehlern in ham_close()?

x bbaum fehlerfrei
x TXN raus (wir können die txn's auch komplett
    für diesen release abschalten... man soll dafür ja ne spezielle version
    kaufen müssen)
x caching
x memory-mapped access
x in memory-datenbanken
x overwrite keys
x extended keys
x erzeugt .dll/.so
x mal nachschauen was man nach den GPL-Codingrules noch für 
    dateien braucht -> nix mehr
o performance vergleichbar mit berkeley-db
o iteratoren
o compiliert unter linux, windows, darwin, 32bit und 64bit, unter windows
    mit mingw, icc, msvc, borland, watcom
o legal issues
o dokumentation: tutorial, interface, FAQ (auch zu unittests)
o webseite
    news
    releases
    download
    faq
    documentation
    tutorial
    mailingliste
o stress-test-tool(s), das ALLE optionen durchprobiert
    mmap
    r/w
    in-memory
    verschiedene pagesizes
    grosse keys
    grosse blobs
o admin-tool(s) fuer dump, stats, repair
    o db_dump: 
        o key/daten dumpen
        o header dumpen
o KEINE valgrind-fehler!

VORSICHT! am besten ein skript schreiben - make-release.sh
    1. version.h hochzählen
    2. einchecken
    3. taggen bzw. copy in release-trunk in hamsterdb-v.v.v
    4. einchecken
    5. export vom release-verzeichnis
    6. tar/gzip
    7. upload

    freshmeat
    alle anderen linklisten
    blog-eintrag (pingen!)

-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------

o extended keys
    o hash-table zum cachen der extended keys
        o insert
        o erase
        o replace
        o find
        o purge

o backend
    o darauf hinarbeiten dass später mal mehrere backends in einer datei
        sind, nicht nur eines

o blob
    o neu: header in jeder page mit blobid
    o header auch im verify prüfen

o debug
    o im debug-modus output wie gehabt; bei non-debug: statt file- und line
        nur "hamsterdb: " ausgeben

o filter
    generische filter, sowie 2 implementationen davon: ein encryption-codec 
    und ein zlib-codec
    arbeiten sie page- oder blob-basiert? evtl waere page-basiert besser, 
    denn dann koennten auch index-pages (bzw NUR index-pages) gefiltert 
    werden.
    (my_result_t) (*filter)(my_key_t *key, my_data_t *data, int direction);

o hash-tabelle
    @@@

o bindings 
    c++-wrapper (ähnlich stl? müsste möglich sein, aber
    schwer), python-db-modul, perl, java (alle swig?)

o asset-tool
    GUI und library für computerspiele

-----------------------------------------------------
-----------------------------------------------------

Version 0.2.0

o duplicate keys
o iteratoren
o bindings: C++, Python, Perl, PHP (mit online-demo!)
o filter: encryption
o filter: compression

-----------------------------------------------------

Version 0.3.0

o database-environment (ein file fuer mehrere datenbanken, gesharter cache,
    geshartes file-handle, freelist etc)
    etc)
o hash-tabelle
o live reorganisation???

-------------------------- literature -----------------------
pB+ Trees prefetching B+ Trees 
[CGM01] Improving Index Performance through Prefetching. S. Chen, P.B. 
Gibbons, and T.C. Mowry. ACM International Conference on Management
of Data (SIGMOD), Santa Barbara, California, May 2001
[GL01] B-Tree Indexes and CPU Caches. G Graefe and P. Larson. International
Conference on Data Engineering (ICDE), Heidelberg, Germany, April 2001.
[RR00] Making B+ Trees Cache Conscious in Main Memory. J. Rao 
and K.A. Ross. ACM International Conference on Management of Data (SIGMOD),
Dallas, Texas, May 2000.

