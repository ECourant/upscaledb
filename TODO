


o in-memory-database
    x parameter für test-programm
    x implementieren
    x test 220 crasht noch (OHNE in-memory-db!)
    x test 45 crasht noch, an der selben stelle
    x test 220 crasht bei in_memory_db in ham_close (enumerieren und 
       freigeben der blobs) 

    o 220.tst: 2 memory-leaks, 45.tst ist ok
        by 0x406B71: _ham_mem_malloc (mem.c:17)
        by 0x406170: db_alloc_page_struct (db.c:192)
        by 0x405EF6: my_alloc_page (db.c:111)
        by 0x40687C: db_alloc_page (db.c:559)
        by 0x409FB9: my_insert_split (btree_insert.c:418)
        by 0x409CD2: my_insert_in_page (btree_insert.c:271)
        by 0x409AC5: my_insert_recursive (btree_insert.c:195)
        by 0x409B30: my_insert_recursive (btree_insert.c:206)
        by 0x4098EA: btree_insert (btree_insert.c:131)
        by 0x4056C1: ham_insert (hamsterdb.c:615)
        by 0x402D85: my_execute_insert (db.c:656)


-----------------------------------------------------

o dbtest.py erweitern, dass alle argv-argumente an ./test weiter-
    gegeben werden (für --inmemorydb, --profile, --dump etc)
    o automatisch valgrind aufrufen und nach fehlern checken
    o wenn valgrind ein memory-leak angibt, dann mit --leak-check=full 
        und --show-reachable=yes testen, den output speichern

-----------------------------------------------------

o sicherstellen dass die freelist wirklich benutzt wird - bin mir da 
    nicht so sicher...

-----------------------------------------------------

o test 45 hat 2 memory leaks
    tritt der fehler nur beim pagesplit auf? evtl ist es einfacher, den 
    fehler zu provozieren, wenn wir maxkeys auf 3 oder 4 setzen

    valgrind --show-reachable=yes --tool=memcheck --leak-check=full ./test  --db
    ../../../hamsterdb-tests/trunk/testfiles/db/45.tst --backend2=none
    ==7536== Memcheck, a memory error detector.
    ==7536== Copyright (C) 2002-2005, and GNU GPL'd, by Julian Seward et al.
    ==7536== Using LibVEX rev 1471, a library for dynamic binary translation.
    ==7536== Copyright (C) 2004-2005, and GNU GPL'd, by OpenWorks LLP.
    ==7536== Using valgrind-3.1.0, a dynamic binary instrumentation framework.
    ==7536== Copyright (C) 2000-2005, and GNU GPL'd, by Julian Seward et al.
    ==7536== For more details, rerun with: -v
    ==7536==
    getopt: db test, file is ../../../hamsterdb-tests/trunk/testfiles/db/45.tst
    ==7536==
    ==7536== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 5 from 1)
    ==7536== malloc/free: in use at exit: 13,248 bytes in 138 blocks.
    ==7536== malloc/free: 14,031 allocs, 13,893 frees, 1,161,949 bytes allocated.
    ==7536== For counts of detected errors, rerun with: -v
    ==7536== searching for pointers to 138 not-freed blocks.
    ==7536== checked 647,304 bytes.
    ==7536==
    ==7536== 13,248 (576 direct, 12,672 indirect) bytes in 6 blocks are definitely
    lost in loss record 1 of 2
    ==7536==    at 0x4A1AAC6: malloc (vg_replace_malloc.c:149)
    ==7536==    by 0x4068CD: _ham_mem_malloc (mem.c:17)
    ==7536==    by 0x405E70: db_alloc_page_struct (db.c:180)
    ==7536==    by 0x405C6E: my_alloc_page (db.c:111)
    ==7536==    by 0x4065D9: db_alloc_page (db.c:558)
    ==7536==    by 0x408F7E: my_fun_create (btree.c:128)
    ==7536==    by 0x405062: ham_create_ex (hamsterdb.c:378)
    ==7536==    by 0x404D39: ham_create (hamsterdb.c:271)
    ==7536==    by 0x401CE4: my_execute_create (db.c:384)
    ==7536==    by 0x403465: my_execute (db.c:797)
    ==7536==    by 0x40386E: test_db (db.c:905)
    ==7536==    by 0x403AB5: my_test_db (main.c:56)
    ==7536==
    ==7536==
    ==7536== 12,672 bytes in 132 blocks are indirectly lost in loss record 2 of 2
    ==7536==    at 0x4A1AAC6: malloc (vg_replace_malloc.c:149)
    ==7536==    by 0x4068CD: _ham_mem_malloc (mem.c:17)
    ==7536==    by 0x405E70: db_alloc_page_struct (db.c:180)
    ==7536==    by 0x405C6E: my_alloc_page (db.c:111)
    ==7536==    by 0x4065D9: db_alloc_page (db.c:558)
    ==7536==    by 0x4067D5: db_alloc_area (db.c:629)
    ==7536==    by 0x407883: my_allocate_header (blob.c:36)
    ==7536==    by 0x407B1C: blob_allocate (blob.c:127)
    ==7536==    by 0x40991A: my_insert_nosplit (btree_insert.c:345)
    ==7536==    by 0x4096F3: my_insert_in_page (btree_insert.c:259)
    ==7536==    by 0x40957B: my_insert_recursive (btree_insert.c:200)
    ==7536==    by 0x40939E: btree_insert (btree_insert.c:131)
    ==7536==
    ==7536== LEAK SUMMARY:
    ==7536==    definitely lost: 576 bytes in 6 blocks.
    ==7536==    indirectly lost: 12,672 bytes in 132 blocks.
    ==7536==      possibly lost: 0 bytes in 0 blocks.
    ==7536==    still reachable: 0 bytes in 0 blocks.
    ==7536==         suppressed: 0 bytes in 0 blocks.

-----------------------------------------------------

o bei ham_open kann man keine cachesize angeben...
    evtl sollte es auch ein ham_open_ex geben

-----------------------------------------------------

o replace/overwrite keys
    o implementieren
    o neue testreihen erstellen!!

-----------------------------------------------------

o profiling! aber mit der release-version...
    o in-memory-db
    o os_mmap
    o read
    o verschiedene page- und keygrössen
    o nur inserts
    o nur inserts ohne blob
    o nur erase
    o nur lookup
    o auch gegen andere backends (qdbm, sqlite, ...)
    o etc etc etc

    o können wir die minkeys/maxkeys hochsetzen? bzw. später splitten 
    und später mergen?
        o pagesplits/merges in bdb zählen
        o bdb: wie gross sind ihre pages? 
        o bdb: wie gross sind ihre keys? 

-----------------------------------------------------
-----------------------------------------------------

o extended keys
    o store_key(ham_key_t *key, internal_key_t *intkey);
    o load_key(internal_key_t *intkey, ham_key_t *key);
    o shift/insert/remove ext. keys (wie in btree.c)
    o wie verhält sich der default-comparator (bei ungleichen keygrössen)?
        1. memcmp auf prefix
        2. identisch? wenn ein key kürzer ist als der andere, und vollständig
            vorliegt: kurzer key ist "vorher"
        3. sonst keys nachladen, wie bei 2) weiter

    o eventuell wäre es gut, wenn die gebufferten extended keys global 
        gespeichert werden, nicht bei der page; dadurch müssen wir keine
        shifts/moves machen; nur wenn eine page komplett (aus dem
        cache oder der datei) gelöscht wird, müssen die keys raus; oder 
        wenn ein key-eintrag gelöscht wird. sonst gibt's keine weiteren
        operationen, und evtl können wir die geschwindigkeit halbwegs 
        schnell kriegen (hash-tabelle).
        o extkey_get(name, extkey *) - lädt notfalls key von der platte
        o extkey_remove(extkey *)
        o extkey_put(extkey *, name)

-----------------------------------------------------

o iteratoren (nicht in version 0.10)
    o in-memory-db: finden wir ne möglichkeit, normale datenbanken in 
        in-memory zu importieren und umgekehrt wieder zu exportieren? 
        das wäre genial
        --> geht mit iteratoren (erst release 2.0!):
            iterator from=db1.begin()
            while (from)
                db2.append(from)
                from.next()
        --> geht auch mit der enum-funktion, die jetzt schon drin ist

-----------------------------------------------------

o duplicate keys (nicht in version 0.10)
    jeder key bekommt einen dupcounter; der wird mit unsigned(-1) initialisiert
    beim einfuegen wird rekursiv abgestiegen. im leaf wird dann ein neuer key
    eingefuegt, mit dem dupcounter=existierender ("kleinster") key minus 1.

-----------------------------------------------------
-----------------------------------------------------

o tests
    o test mit freelist
    o test mit mmap, verschiedene pagesizes
    o test mit read, verschiedene pagesizes
    o test mit in-memory-db, verschiedene pagesizes
    o in-memory-database testen
    o verschiedene pagesizes/keysizes für
        o in-memory-db
        o os_mmap
        o read(2)

-----------------------------------------------------

o momentan werden alle pages auf null gesetzt (memset(page->pers->payload, 0))
    und zwar evtl sogar mehrmals (freelist!)
    raus damit!

-----------------------------------------------------

o doku
    o überarbeiten
    o erweitern

-----------------------------------------------------

o statistics
    will wissen wie viele freelist-hits/misses und cache-hits/misses es gab

    brauche bei den statistik-feldern die anzahl der aktuellen Keys in der
    Datenbank

    wird im sql gebraucht für AUTO_INCREMENT vom index und für eine schnelle
    Berechnung
    von MAX() über die ganze tabelle.

    allerdings wird das etwas tricky, sobald transaktionen dazu kommen - erst
    beim commit der transaktion muss der zähler inkrementiert/dekrementiert und
    auf platte geschrieben werden. erst sobald der erhöhte zähler wirklich auf
    platte geschrieben wurde, ist die transaktion abgeschlossen.

    jedoch ist das blöd, weil es dann immer einen zusätzlichen
    schreibzugriff gibt, sobald ein insert oder erase stattfindet. eher 
    sollte nach dem start geprüft werden, ob es einen absturz gab - 
    falls ja, werden die statistiken gelöscht, und on demand wieder 
    initialisiert. (diese ganze problematik kommt erst, wenn wir sql brauchen).

    Die MAX-Berechnung sollte recht simpel sein. Alle anderen Statistiken (z.b.
    total size von allen Datensätzen) werden teuer - die sollten nicht immer
    up-to-date gehalten werden, sondern nur on-demand vom cli-tool "ham_stats"
    ausgegeben werden).

o statistics
    get generic getter/setter for statistical value, i.e. 
        enum { CACHEHITS, CACHEMISSES, PAGES, FREEPAGES, ... };
        ham_u64_t statistics[8];
    set_stats_value(db, which, value): db->statistics[which]=ham_h2db32(value)
    ATTENTION: some of those values are specific for each backend, others
        are global; therefore we need two functions: 
        ham_get_global_statistics(stat)
        ham_get_index_statistics(index, stat)

-----------------------------------------------------

o get hamster version
    gibt's ne möglichkeit, die version der
    library abzufragen? klar - sie steht in einer header-datei
    aber die ist privat und kann nicht "von aussen" abgefragt werden. 
    evtl wäre eine exportierte funktion besser:
    
    ham_status_t ham_get_version(ham_u32_t *major,
            ham_u32_t *minor, ham_u32_t *revision)

-----------------------------------------------------
-----------------------------------------------------

o tools
    o ham_dump
    o ham_stats

-----------------------------------------------------

o configuration management: HAM_32BIT/HAM_64BIT, HAM_OS_POSIX/HAM_OS_WINDOWS
    automatisch während des build-prozesses erkennen; momentan 
    werden sie in ham/config.h gesetzt

o stress test mit zufällig fehlschlagenden io-funktionen und zufälligen
    OUT_OF_MEMORYs

--------------

o cache: bucketgrösse in ham_config.h verschieben, eine #define-konstante
    draus machen

--------------

o new flag for create/open: USE_FLOCK calls flock() around insert/erase 
        (makes mostly sense if cachesize==0)

o profiling: if a page is allocated, allocate more pages, then we have only
    one disk access (???)

--------------

o documentation -> texinfo? doxygen?
    merge the documentation with doxygen-docs

o define HAM_EXPORT DECLSPEC _dllexport
    compile a shared library

--------------

Version 0.1.0 - first release!!

o komplettes review
    werden fehlerwerte korrekt propagiert?
    machen fehlerwerte immer sinn? z.b. in flush_all()
    was passiert mit fehlern beim flushen?
    was passiert mit fehlern in ham_close()?

x bbaum fehlerfrei
x TXN raus (wir können die txn's auch komplett
    für diesen release abschalten... man soll dafür ja ne spezielle version
    kaufen müssen)
x caching
x memory-mapped access
o in memory-datenbanken
o performance vergleichbar mit berkeley-db
o overwrite keys
o extended keys
o erzeugt .dll/.so
o compiliert unter linux, windows, darwin, 32bit und 64bit, unter windows
    mit mingw, icc, msvc, borland, watcom
o legal issues
o dokumentation: tutorial, interface, FAQ
o webseite
o stress-test-tool(s), das ALLE optionen durchprobiert
o admin-tool(s) fuer dump, stats, reorg
    o db_dump: 
        o key/daten dumpen
        o header dumpen
o KEINE valgrind-fehler!

-----------------------------------------------------

o backend
    o darauf hinarbeiten dass später mal mehrere backends in einer datei
        sind, nicht nur eines

o blob
    o neu: header in jeder page mit blobid
    o header auch im verify prüfen

o debug
    o im debug-modus output wie gehabt; bei non-debug: statt file- und line
        nur "hamsterdb: " ausgeben

o filter
    generische filter, sowie 2 implementationen davon: ein encryption-codec 
    und ein zlib-codec
    arbeiten sie page- oder blob-basiert? evtl waere page-basiert besser, 
    denn dann koennten auch index-pages (bzw NUR index-pages) gefiltert 
    werden.
    (my_result_t) (*filter)(my_key_t *key, my_data_t *data, int direction);

o hash-tabelle
    @@@

o bindings 
    c++-wrapper (ähnlich stl? müsste möglich sein, aber
    schwer), python-db-modul, perl, java (alle swig?)

o asset-tool
    GUI und library für computerspiele

-----------------------------------------------------
-----------------------------------------------------

Version 0.2.0

o duplicate keys
o iteratoren
o bindings: C++, Python, Perl, PHP
o filter: encryption
o filter: compression

-----------------------------------------------------

Version 0.3.0

o database-environment (ein file fuer mehrere datenbanken, gesharter cache,
    geshartes file-handle, freelist etc)
    etc)
o hash-tabelle
o live reorganisation???

-------------------------- literature -----------------------
pB+ Trees prefetching B+ Trees 
[CGM01] Improving Index Performance through Prefetching. S. Chen, P.B. 
Gibbons, and T.C. Mowry. ACM International Conference on Management
of Data (SIGMOD), Santa Barbara, California, May 2001
[GL01] B-Tree Indexes and CPU Caches. G Graefe and P. Larson. International
Conference on Data Engineering (ICDE), Heidelberg, Germany, April 2001.
[RR00] Making B+ Trees Cache Conscious in Main Memory. J. Rao 
and K.A. Ross. ACM International Conference on Management of Data (SIGMOD),
Dallas, Texas, May 2000.

