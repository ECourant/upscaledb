
./test.exe --test-cursors=1 --overwrite=1 --mmap=0 --reopen=1 --cachesize=50
--file ../../../hamsterdb-tests/trunk/testfiles/1/ext_021.tst --verbose=1

o port to ms windows
    x win32: sourcen portieren - mmap fehlt noch!
    o mit mingw, bcc, watcom, msvc, icc...
    o projekt-umgebungen für visual studio 6
    o define HAM_EXPORT DECLSPEC _dllexport for DLLs und .so
    o monster.sh!

o endianness testen - schlägt fehl! 

o logo!!

o webseite
    http://nitrosecurity.com/
    http://www.opf3.com/Opf3/Default.aspx
    http://www.pixelmedia.com/
    x grund-layout und php-framework erstellen
    x doxygen in webseite integrieren
    o hamsterdb.h überarbeiten, dokumentieren
    o inhalte
        x frontseite
        o frontseite: hamster-bild einbetten
        x features
        o download
        o legal/impressum
        o sitemap
        o GPL/Verweise auf GPL
        o roadmap
        o links
        o doku bzgl installation, compilieren, portieren
        o sidebars
    o korrigieren lassen

o können wir problemlos 32bit-filepointer nehmen?

o 1 writer, multiple reader - wie lässt sich das machen?
    alle ohne caching, alle mit read-through/write-through?
    testen, evtl brauchen wir noch ein exclusive locking
    
o es ist noch ein kleiner valgrind-bug drin:
    valgrind --tool=memcheck --leak-check=full --show-reachable=yes
    .libs/lt-test --file ../../../hamsterdb-tests/trunk/testfiles/1/ext_060.tst
    --inmemorydb=1 --verbose=1

o nächsten release machen

-----------------------------------------------------
-----------------------------------------------------

o doku
    o tutorial/sample in die online-hilfe einbeziehen
    o FAQ mit häufig gestellten fragen, tips zu optimierungen
    o Dokumentation in den header-dateien überarbeiten
    o webseite
    o mailing list
    o überarbeiten
    o interne doku schreiben
        o db-handle, pageverwaltung
        o backend-aufbau
        o freelist
        o cache
        o cursors
    o header-file überarbeiten

-----------------------------------------------------
-----------------------------------------------------

o tools
    o ham_dump
        erzeugt einen cursor auf den ersten eintrag, dumpt den 
        key und die daten (zumindest einen teil davon)
        --key-format=char|short|long|longlong|string|binary
        --key-length=<n>
        --data-format=char|short|long|longlong|string|binary
        --data-length=<n>
    o ham_info
        gibt alle infos aus dem header aus, sowie die anzahl der elemente,
        average key size, average data size, min/max etc
    o ham_recover
        holt die header-page, dann die root-page, und geht runter zum 
        ersten leaf. läuft dann alle index-pages ab, schreibt die keys 
        und die daten raus 
    o ham_check
        macht einen check_integrity auf die datenbank
    o ham_reorg
        macht eine reorg (im grunde nur ein neues schreiben der datenbank
        mit gleichzeitigem minimieren der freelist-entries)

-----------------------------------------------------
-----------------------------------------------------

o komplettes review
    werden fehlerwerte korrekt propagiert?
    machen fehlerwerte immer sinn? z.b. in flush_all()
    was passiert mit fehlern beim flushen?
    was passiert mit fehlern in ham_close()?
    o ein paar sachen müssten umbenannt werden:
        o alle statischen funktionen bekommen statt "my_" ein 
            prefix, das ihrem modul entspricht (z.b. "bt_" für btree etc)
        o keys.h/keys.c aufteilen in generische keys (zusammenlegen mit extkeys)
            und btree-spezifischen keys
        o db hat 2 funktionen, die die extended keys löschen - das gehört
            ins backend
    o nochmal schaun ob die ganzen flags so sinn machen
    o TODOs durchgehen

-----------------------------------------------------
-----------------------------------------------------

x bbaum fehlerfrei
x TXN raus (wir können die txn's auch komplett
    für diesen release abschalten... man soll dafür ja ne spezielle version
    kaufen müssen)
x caching
x memory-mapped access
x in memory-datenbanken
x overwrite keys
x extended keys
x mal nachschauen was man nach den GPL-Codingrules noch für 
    dateien braucht -> nix mehr
x performance vergleichbar mit berkeley-db
x erzeugt .dll/.so
x umsteigen auf autoconf/automake
x cursors
x stress-test-tool(s), das ALLE optionen durchprobiert
    mmap
    r/w
    in-memory
    verschiedene pagesizes
    grosse keys
    grosse blobs
o compiliert unter linux, windows, darwin, 32bit und 64bit, läuft auf 
    little- und bigendian
o logo
o legal issues
o dokumentation: tutorial, interface, FAQ (auch zu unittests)
o webseite
o documentation
o admin-tool(s) fuer dump, stats, repair, update, reorg
    o db_dump: 
        o key/daten dumpen
        o header dumpen
o KEINE valgrind-fehler!

-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------
-----------------------------------------------------

o duplicate keys
    jeder key bekommt einen dupcounter; der wird mit unsigned(-1) initialisiert
    beim einfuegen wird rekursiv abgestiegen. im leaf wird dann ein neuer key
    eingefuegt, mit dem dupcounter=existierender ("kleinster") key minus 1.

-----------------------------------------------------
-----------------------------------------------------

o mehrere datenbanken in einer datei
    (siehe eintrag im notizbuch)

    -> database-environment (ein file fuer mehrere datenbanken, 
        gesharter cache, geshartes file-handle, freelist etc)

-----------------------------------------------------
-----------------------------------------------------

o filter
    generische filter, sowie 2 implementationen davon: ein encryption-codec 
    und ein zlib-codec
    arbeiten sie page- oder blob-basiert? evtl waere page-basiert besser, 
    denn dann koennten auch index-pages (bzw NUR index-pages) gefiltert 
    werden.
    (my_result_t) (*filter)(my_key_t *key, my_data_t *data, int direction);

-----------------------------------------------------
-----------------------------------------------------

o c++-api

-----------------------------------------------------
-----------------------------------------------------

o statistics
    will wissen wie viele freelist-hits/misses und cache-hits/misses es gab,
    auch im extkey-cache

o statistics
    get generic getter/setter for statistical value, i.e. 
        enum { CACHEHITS, CACHEMISSES, PAGES, FREEPAGES, ... };
        ham_u64_t statistics[8];
    set_stats_value(db, which, value): db->statistics[which]=ham_h2db32(value)
    ATTENTION: some of those values are specific for each backend, others
        are global; therefore we need two functions: 
        ham_get_global_statistics(stat)
        ham_get_index_statistics(index, stat)
    max elements in einer datenbank

-----------------------------------------------------
-----------------------------------------------------

o bindings 
    python (auch für python-shelf!)
    perl
    php
    java
    COM
    .NET (Sample)
    C# (Sample)
    VB.NET (Sample)

-----------------------------------------------------
-----------------------------------------------------

o super-COMPRESSED-mode: keine headerpage, und pagesize auf 128 byte ->
    super-mini-datenbanken (für embedded) - möglich ohne Aufwand? wird tricky, 
    weil die page-alloc-funktionen davon ausgehen dass eine adresse 0 ein
    fehler ist

-----------------------------------------------------

o datenbank mit O_EXCL öffnen, bzw mit flock() (und nem wait, falls die 
    Datenbank gelockt ist) -> Möglichkeit für pseudo-concurrent access bei
    kurzen, schnellen Zugriffen (z.b. webseite)

-----------------------------------------------------

o hash-tabelle
    @@@

-----------------------------------------------------
-----------------------------------------------------

o asset-tool
    GUI und library für computerspiele

-----------------------------------------------------
-----------------------------------------------------

o live reorganisation???

-------------------------- literature -----------------------
pB+ Trees prefetching B+ Trees 
[CGM01] Improving Index Performance through Prefetching. S. Chen, P.B. 
Gibbons, and T.C. Mowry. ACM International Conference on Management
of Data (SIGMOD), Santa Barbara, California, May 2001
[GL01] B-Tree Indexes and CPU Caches. G Graefe and P. Larson. International
Conference on Data Engineering (ICDE), Heidelberg, Germany, April 2001.
[RR00] Making B+ Trees Cache Conscious in Main Memory. J. Rao 
and K.A. Ross. ACM International Conference on Management of Data (SIGMOD),
Dallas, Texas, May 2000.

